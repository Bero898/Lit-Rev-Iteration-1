"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Publication Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",Funding Information,PDF Link,"Author Keywords","IEEE Terms","Mesh_Terms",Article Citation Count,Patent Citation Count,"Reference Count","License",Online Date,Issue Date,"Meeting Date","Publisher",Document Identifier
"Data Evolution Governance for Ontology-Based Digital Twin Product Lifecycle Management","Z. Ren; J. Shi; M. Imran","School of Mechanical and Automotive Engineering, South China University of Technology, Guangzhou, China; School of Mechanical and Electrical Engineering, Shanxi Datong University, Datong, China; Institute of Innovation, Science and Sustainability, Federation University, Brisbane, QLD, Australia",IEEE Transactions on Industrial Informatics,"15 Dec 2022","2023","19","2","1791","1802","Product lifecycle management (PLM) is an effective method for enhancing the market competitiveness of modern manufacturing industries. The digital twin is characterized by a profound integration of physics and information systems, which provides a technical means for integrating multisource information and breaking the time and space barrier of communication at each link of the lifecycle. Currently, however, the application of this technology focuses primarily on the product itself and “service-oriented” application results. There is a lack of focus on twin data and its internal evolutionary mechanisms separately. In the management of global data resources, the benefits of digital twin technology cannot be fully realized. This article applies ontology technology in an innovative manner to the field of the digital twin to increase the reusability of twin data. Initially, a four-layered ontology-based twin data management architecture is presented. Then, a three-dimensional and three-granularity unified evolution model of full lifecycle twin data is proposed, as well as its ontology model. Then, the service mode of data components at each stage of the lifecycle is defined, a knowledge-sharing plane is established in the digital twin, and a data governance method based on ontology reasoning using data components on the shared plane is proposed. The ICandyBox simulation platform is then used to demonstrate the concept of the proposed method, and future research directions are proposed.","1941-0050","","10.1109/TII.2022.3187715","Key Areas Research and Development Program of Guangdong Province, China(grant numbers:2019B010150002); Open Fund of the Aerospace Servo Drive and Transmission Technology Laboratory(grant numbers:LASAT-2021-01); Natural Science Foundation of Guangdong Province(grant numbers:2021A1515011946); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9813407","Digital twin;metamodel;ontology reasoning;product lifecycle management (PLM);unified data modeling","Data models;Digital twins;Ontologies;Informatics;Solid modeling;Predictive models;Metadata","","17","","28","IEEE","1 Jul 2022","","","IEEE","IEEE Journals"
"An Intelligent Product-Driven Manufacturing System Using Data Distribution Service","C. -T. Lin; H. -J. Lu","Department of Mechanical Engineering, National Central University, Taoyuan, Taiwan; Department of Mechanical Engineering, National Central University, Taoyuan, Taiwan",IEEE Access,"5 Feb 2024","2024","12","","16447","16461","As key components of smart factories, intelligent production machines are gradually becoming a major capital asset of companies in the market, offering connectivity, interoperability, and services. However, due to commercial and technological constraints, production machines rarely provide enough information for customers to develop data-driven applications. Therefore, this research proposes that intelligence be built into them to assist in production control and allow relevant data to be collected and made available for future use. In order to realize this proposal, an operational paradigm for such systems is first outlined in this paper. Then, the states of workpieces in a production environment are classified, and the methods of generation, operation, and transfer of instances are described. The next step is to build an intelligent product-driven manufacturing system using Data Distribution Service (DDS). Intelligent workpieces and machines collaborate to complete production tasks in such a system. During this collaborative process, an intelligent workpiece continuously collects relevant data and packages it together for the customer on its transformation into a final product. The feasibility of this intelligent product-driven manufacturing system is examined by upgrading a classic manufacturing factory. In addition, the study explores the system architecture, the implementation of a classic system upgrade, the production data collection, and the intellectualization of data assets. In conclusion, the results of this study will help machine builders expand their business models, providing customers with production machines that carry data for advanced data-driven applications.","2169-3536","","10.1109/ACCESS.2024.3359228","Ministry of Science and Technology Council(grant numbers:NSTC 112-2218-E-008-010); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10415431","Data distribution service;intelligent product;manufacturing system;product life cycle;industry 4.0;industrial automation","Manufacturing systems;Production facilities;Fourth Industrial Revolution;Distributed databases;Data processing;Information exchange;Product lifecycle management","","","","60","CCBY","29 Jan 2024","","","IEEE","IEEE Journals"
"A System-Level Modeling Methodology for Performance-Driven Component Selection in Multicore Architectures","A. Agarwal; G. L. Hamza-Lup; T. M. Khoshgoftaar","Department of Computer and Electrical Engineering and Computer Science, Florida Atlantic University, Boca Raton, FL, USA; Department of Computer and Electrical Engineering and Computer Science, Florida Atlantic University, Boca Raton, FL, USA; Department of Computer and Electrical Engineering and Computer Science, Florida Atlantic University, Boca Raton, FL, USA",IEEE Systems Journal,"22 May 2012","2012","6","2","317","328","System complexity, driven by both increasing transistor count and customer need for more and more savvy applications, has increased so dramatically that system design and integration can no longer be an after-thought. With this increasing complexity of the system design, it has become very critical to enhance system design productivity to meet the time-to-market demands and reduce product development cost. Realtime embedded system designers are facing extreme challenges in the underlying architectural design selection. This involves the selection of a programmable, concurrent, heterogeneous multiprocessor architecture platform. Such a multiprocessor-system-on-chip platform has set innovative trends for the realtime systems and system-on-chip designers. The consequences of this trend imply a shift in concern from computation and sequential algorithms to modeling concurrency, synchronization, and communication in every aspect of hardware and software codesign and development. Therefore, there is a need for a high level methodology that can provide a complete system modeling and architecture/component selection platform. The proposed six-step system modeling methodology provides a process for performance driven component selection, to avoid costly iterative system design re-spins, thereby enhancing system design productivity. We demonstrate our methodology by applying it onto a network-on-chip architecture for selecting its components given certain system specification and system-level performance requirements.","1937-9234","","10.1109/JSYST.2011.2173614","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6197694","Component based design;component selection;concurrency modeling;embedded systems;performance evaluation;system level design;system modeling","Concurrent computing;Computational modeling;System performance;Libraries;Computer architecture","","5","2","50","IEEE","9 May 2012","","","IEEE","IEEE Journals"
"Overcoming Conflicts of Objectives Between Sensory and Mechanical Domain in the Development of Sensor-Integrating Machine Elements Using the Example of Bolts","J. Peters; N. Mirbach; F. Herbst; D. Riehl; M. Kupnik; K. Hofmann; S. Matthiesen","Institute of Product Engineering, Karlsruhe Institute of Technology (KIT), Karlsruhe, Germany; Institute of Product Engineering, Karlsruhe Institute of Technology (KIT), Karlsruhe, Germany; Institute of Product Engineering, Karlsruhe Institute of Technology (KIT), Karlsruhe, Germany; Integrated Electronic Systems Laboratory, Technische Universität Darmstadt, Darmstadt, Germany; Measurement and Sensor Technology Group, Technische Universität Darmstadt, Darmstadt, Germany; Integrated Electronic Systems Laboratory, Technische Universität Darmstadt, Darmstadt, Germany; Institute of Product Engineering, Karlsruhe Institute of Technology (KIT), Karlsruhe, Germany",IEEE Access,"11 Jul 2024","2024","12","","93975","93992","Comprehensive data on machines is essential for digitization in the industry. Since standardized machine elements are used in most machines, integrating them with sensors provides the opportunity to acquire data comprehensively from in-situ. The sensor integration must not change the element’s core function and the standardized mechanical interfaces. Hence, sensors must be fully integrated and self-sufficient. Regarding bolts as widely used machine element, a solution that combines all the aforementioned requirements does not yet exist. A main problem in developing sensor-integrating machine elements and especially bolts is to overcome the conflicting objectives in defining design space for mechanical and sensory functions. There is a lack of an approach to model the effects of the design space parameters on the mechanical and sensory functions. This paper proposes an optimization function to aid mechanical and electrical engineers in resolving conflicting objectives by balancing function fulfillment when determining design space parameters. Therefore, the effects of the parameters on the mechanical and sensory functions are modelled using FE-analysis and composing an optimization function with weights. This function provides optimal design space parameters. With respect to mountability boundary conditions the optimum for equal weights is at diameters 13.2mm both, increasing v. Mises stress by 29% and strain at sensor position by 80%. The location of the optimum is very dependent on proper weighting, which resembles a prioritization of the mechanical versus the sensory function fulfillment. This enables engineers to find optimal parameters by balancing the mechanical and the sensory function fulfillment.","2169-3536","","10.1109/ACCESS.2024.3423674","Deutsche Forschungsgemeinschaft (DFG, German Research Foundation)(grant numbers:466650813); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10584525","Bolt;conflicting objectives;design space;finite element analysis;mechanical domain;optimization;sensing;sensor;sensory domain;sensor integration;strain gauges","Sensors;Mechanical sensors;Strain measurement;Finite element analysis;Mathematical models;Finite element analysis;Stress control;Digital systems;Machinery","","1","","47","CCBYNCND","4 Jul 2024","","","IEEE","IEEE Journals"
"Building Families of Software Products for e-Learning Platforms: A Case Study","P. S. Barreiro; D. García-Saiz; M. E. Z. Pantaleón","Department of Mathematics, Statistics and Computation, University of Cantabria, Cantabria, Spain; Department of Mathematics, Statistics and Computation, University of Cantabria, Cantabria, Spain; Department of Mathematics, Statistics and Computation, University of Cantabria, Cantabria, Spain",IEEE Revista Iberoamericana de Tecnologias del Aprendizaje,"20 May 2017","2014","9","2","64","71","Applications for e-learning platforms must deal with certain variability inherent to their domain. For example, these applications must be adapted to the variations of each teaching-learning process. Thus, they must be changed manually, according to the particular environment in which they will be deployed. This manual adaptation process is costly and error-prone. Our hypothesis is that software product line (SPL) engineering, whose goal is the effective production of similar software systems, can help to alleviate this problem. This paper illustrates this idea by refactoring an e-learning application named E-Learning Web Miner in a SPL. The benefits obtained are highlighted and analyzed.","1932-8540","","10.1109/RITA.2014.2317531","University of Cantabria; TIN2008-01942/TIN Project through the Spanish Science and Technology Ministry; TIC-5131 Regional Project through the Junta de Andalucía; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6799220","Software product line;refactoring;e-learning;data mining","Electronic learning;Data mining;Computer architecture;Software systems;Software development;HTML;Education courses","","5","","32","IEEE","16 Apr 2014","","","IEEE","IEEE Journals"
"Optimization of Scatter Network Architectures and Bank Allocations for Sparse CNN Accelerators","S. Kim; S. Park; C. S. Park","Department of Electrical and Electronics Engineering, Konkuk University, Seoul, South Korea; Department of Electronics Engineering, Pusan National University, Pusan, South Korea; Department of Electrical and Electronics Engineering, Konkuk University, Seoul, South Korea",IEEE Access,"19 Aug 2022","2022","10","","85864","85879","Sparse convolutional neural network (SCNN) accelerators eliminate unnecessary computations and memory access by exploiting zero-valued activation pixels and filter weights. However, data movement between the multiplier array and accumulator buffer tends to be a performance bottleneck. Specifically, the scatter network, which is the core block of SCNN accelerators, delivers Cartesian products to the accumulator buffer, and certain products are not immediately delivered owing to bus contention. A previous SCNN-based architecture eliminates bus contention and improves the performance significantly by making use of different dataflows. However, it relies only on weight sparsity, and its performance is highly dependent on the workload. In this paper, we propose a novel scatter network architecture for SCNN accelerators. First, we propose network topologies (such as window and split queuing), which define the connection between the FIFOs and crossbar buses in the scatter network. Second, we investigate arbitration algorithms (such as fixed priority, round-robin, and longest-queue-first), which define the priorities of the products delivered to the accumulator buffer. However, the optimization of the scatter network architecture alone may not be able to provide sufficient performance gain since it does not help to reduce bus contention itself. In this paper, we propose a cubic-constrained bank allocation for the accumulator buffer, which reduces bus contention without any increase in the hardware area. Based on the results of cycle-accurate simulation, register-transfer-level (RTL) design, and logic synthesis, this study investigates the trade-off between the performance and complexity of SCNN accelerators. In detail, it is verified that, when the optimized SCNN accelerators are applied to AlexNet, the proposed scatter network architecture can remove most of the performance degradation due to bus contention, thereby improving the accelerator performance by 72%, with an area increase of 18%. It is also shown that the proposed bank allocation provides an additional performance gain of up to 31% when it is applied to SqueezeNet. The proposed scatter network architectures and bank allocation can eliminate bus contention in most Cartesian product-based accelerators, regardless of the workload, without changing accelerator components other than the scatter network.","2169-3536","","10.1109/ACCESS.2022.3199010","Samsung Research Funding and Incubation Center of Samsung Electronics(grant numbers:SRFC-IT1802-10); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9857922","Accelerator;convolutional neural networks (CNNs);cycle-accurate simulator;data compression;dataflow;network on a chip (NoC)","Resource management;Network architecture;Accelerators;Convolutional neural networks;Data compression;Computer architecture;System-on-chip","","1","","37","CCBYNCND","16 Aug 2022","","","IEEE","IEEE Journals"
"Classification-based Mining of Reusable Components on Software Product Lines","M. Arias; A. DeRenzis; A. Buccella; A. Flores; A. Cechich","Universidad Nacional del Comahue, Neuquen, NeuquÃ©n, AR; Universidad Nacional del Comahue, Neuquen, NeuquÃ©n, AR; Universidad Nacional del Comahue, Neuquen, NeuquÃ©n, AR; Universidad Nacional del Comahue, Neuquen, NeuquÃ©n, AR; Universidad Nacional del Comahue, Neuquen, NeuquÃ©n, AR",IEEE Latin America Transactions,"21 Mar 2016","2016","14","2","870","876","Software Product Lines and Component-based systems can be combined to maximize reuse in a predictable and opportunistic manner. When a product line is built for a certain subdomain within a more generic domain, future needs from a closely subdomain may be fulfilled by mining the line's internal components to build a new product line. In this work, we present an approach to classify internal and external (third party) reusable components into a repository, by applying a K-Nearest Neighbors strategy, as a support for building new product lines. Natural language techniques and the WordNet lexical database is also used to process information from software components. We validate the approach with an experiment based in a dataset of external third-party components and reusable components from a product line that we built in the geographic subdomain of marine ecology.","1548-0992","","10.1109/TLA.2016.7437234","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7437234","K-Nearest Neighbors;Software Components;Software Product Lines;Software Reuse","Software;Software product lines;Data mining;Java;ISO Standards;Geographic information systems;Component architectures","","1","","","IEEE","21 Mar 2016","","","IEEE","IEEE Journals"
"IoT-Based Configurable Information Service Platform for Product Lifecycle Management","H. Cai; L. D. Xu; B. Xu; C. Xie; S. Qin; L. Jiang","School of Software, Shanghai Jiao Tong University, Shanghai, China; Chinese Academy of Sciences, Institute of Computing Technology, Beijing, China; Shanghai Jiao Tong University, Shanghai, China; Shanghai Jiao Tong University, Shanghai, China; School of Software, Shanghai Jiao Tong University, Shanghai, China; School of Software, Shanghai Jiao Tong University, Shanghai, China",IEEE Transactions on Industrial Informatics,"2 May 2014","2014","10","2","1558","1567","Internet of Things (IoT) software is required not only to dispose of huge volumes of real-time and heterogeneous data, but also to support different complex applications for business purposes. Using an ontology approach, a Configurable Information Service Platform is proposed for the development of IoT-based application. Based on an abstract information model, information encapsulating, composing, discomposing, transferring, tracing, and interacting in Product Lifecycle Management could be carried out. Combining ontology and representational state transfer (REST)-ful service, the platform provides an information support base both for data integration and intelligent interaction. A case study is given to verify the platform. It is shown that the platform provides a promising way to realize IoT application in semantic level.","1941-0050","","10.1109/TII.2014.2306391","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6742607","Internet of things (IoT);ontology;product lifecycle management;resource-oriented architecture","Business;Ontologies;Solid modeling;Data models;Software;Semantics;Educational institutions","","129","","47","IEEE","17 Feb 2014","","","IEEE","IEEE Journals"
"An architecture for customer experience management based on the Internet of Things","J. Jamison; C. Snow",NA; NA,IBM Journal of Research and Development,"21 Nov 2014","2014","58","5/6","15:1","15:11","In this paper, we propose a commerce-related architecture, the Smarter Commerce Customer Engagement Architecture (SCCEA). This architecture involves a new definition of the commerce lifecycle and an alternative metric for calculating customer experience and benefit, called customer lifetime benefit (CLB). Traditionally, commerce-related architectures have enabled the direct involvement and interaction between customers and companies from a purchasing, customer support center, or marketing perspective. These systems typically help measure financial success through the customer lifetime value (CLV) metric. SCCEA represents a shift in approaches from these architectures to one focused on the interactions with the products customers own and on how those products are operating. SCCEA analyzes the data gathered directly from the operations of products to make a determination of what actions can be taken to positively influence customer experience. SCCEA is realized through combining three foundational domains: Smarter Commerce™, Internet of Things, and Customer Engagement. The paper begins with a definition of the commerce lifecycle, followed by an overview of the three foundational domains. With this foundation established, the authors describe the SCCEA architecture, subsystems, and functional components. Finally, to help clarify the feasibility of the SCCEA approach, a representative scenario from the healthcare industry is presented.","0018-8646","","10.1147/JRD.2014.2346593","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6964873","","Internet of things;Network architecture;Electronic commerce;Market research;Consumer behavior;Consumer products;Customer services;Investments","","1","","43","IBM","21 Nov 2014","","","IBM","IBM Journals"
"Software Architecture Social Debt: Managing the Incommunicability Factor","D. A. Tamburri","Jheronimus Academy of Data Science, Technische Universiteit Eindhoven, Eindhoven, The Netherlands",IEEE Transactions on Computational Social Systems,"13 Feb 2019","2019","6","1","20","37","Architectural technical debt is the additional project cost connected to technical issues nested in software architectures. Similarly, many practitioners have already experienced that there exists within software architectures a form of social debt, that is, the additional project cost connected to sociotechnical and organizational issues evident in or related to software architectures. This paper illustrates four recurrent antipatterns or community smells connected to such architectural social debt and outlines a means to measure the additional project cost connected to their underlying cause: decision incommunicability. Evaluating the results in multiple focus groups, this paper concludes that studying social debt and community smells at the architecture level may prove vital to rid software development communities of critical organizational flaws incurring considerable additional cost.","2329-924X","","10.1109/TCSS.2018.2886433","European Commission(grant numbers:0421); European Commission (H2020), ANITA(grant numbers:787061); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8613009","Social debt;social debt cost estimation;social debt in software architecting;technical debt","Software architecture;Software;Computer architecture;Green products;Interviews;Europe;Documentation","","20","","61","IEEE","15 Jan 2019","","","IEEE","IEEE Journals"
"CNNP-v2: A Memory-Centric Architecture for Low-Power CNN Processor on Domain-Specific Mobile Devices","S. Choi; K. Bong; D. Han; H. -J. Yoo","School of Electrical Engineering, Korea Advanced Institute of Science and Technology, Daejeon, South Korea; School of Electrical Engineering, Korea Advanced Institute of Science and Technology, Daejeon, South Korea; School of Electrical Engineering, Korea Advanced Institute of Science and Technology, Daejeon, South Korea; School of Electrical Engineering, Korea Advanced Institute of Science and Technology, Daejeon, South Korea",IEEE Journal on Emerging and Selected Topics in Circuits and Systems,"11 Dec 2019","2019","9","4","598","611","An energy-efficient memory-centric convolutional neural network (CNN) processor architecture is proposed for smart devices such as wearable devices or the internet of things (IoT) devices. To achieve energy-efficient processing, it has two key features: First, 1-D shift convolution PEs with fully distributed memory architecture achieve 1.5TOPS/W energy efficiency, and it can be boosted up equivalent 3.1TOPS/W energy efficiency with separable filter approximation and transpose-read SRAM. Compared with conventional architecture, even though it has massively parallel 1024 MAC units, it achieves high energy efficiency by scaling down the voltage to 0.46V due to its fully local routed design. Second, fully configurable 2-D mesh core-tocore interconnection support the various size of input features to maximize utilization. The proposed architecture is evaluated 16mm2 chip, which is fabricated with a 65nm CMOS process. As a result, it performs real-time face recognition with the only 68.9mW at 40MHz and 0.6V.","2156-3365","","10.1109/JETCAS.2019.2952457","Institute for Information and communications Technology Promotion; Korean Government “Development of Fundamental Technology of Core Components for Augmented and Virtual Reality Devices”(grant numbers:2017-0-01803); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8894459","Convolutional neural network (CNN);memory-centric architecture;low-power image processing;energy-efficient digital circuit","Memory architecture;Digital circuits;Energy efficiency;Integrated circuit interconnections;Convolutional neural networks;Face recognition","","4","","25","IEEE","8 Nov 2019","","","IEEE","IEEE Journals"
"Techniques to Improve Reliability in an IoT Architecture Framework for Intelligent Products","C. M. Coman; G. D’amico; A. V. Coman; A. Florescu","Tesagon International SRL, Ploiesti, Romania; Focus Innovazione srl, Fasano, Italy; RID International Center SRL, Targu Mures, Romania; Faculty of Electronics, Telecommunications and Information Technology, Politehnica University of Bucharest, Bucuresti, Romania",IEEE Access,"16 Apr 2021","2021","9","","56940","56954","Sensor-Cloud Systems (SCS) are designed to link sensor networks and cloud applications, in order to gather and process information. While this is a hot topic for both academia and industry, with a large number of implementations, not much effort was put towards analysing the reliability of these systems. This article presents an experimental implementation of a system in the field of intelligent products and explores reliability improving techniques in five main areas of the SCS: network communication performance, auto recovery, local backup, automated software testing and system security. They all play an important role in determining the level of reliability of the novel Internet of Things (IoT) architecture framework for intelligent products presented in the article. A new formula is proposed for assessing the reliability of a SCS based on metrics from each of the five areas. Metrics used to assess the system reliability are presented, along with comparisons between operating with improvement techniques and without them. The results show that the reliability of the implemented SCS is improved considerably by implementing a deliberate reliability policy using an original five level tiered approach.","2169-3536","","10.1109/ACCESS.2021.3072168","MANUNET through the Executive Unit for Financing Higher Education, Research, Development and Innovation (UEFISCDI)(grant numbers:COFUND-ERANET MANUNET III-POKET); Apulia Region POR FESR-FSE 2014-2020 - Priority Axis 1 - Research, Technological Development, Innovation - Action 1.6 (Interventions for Strengthening the Regional and National Innovation System and Increasing Collaboration Between Companies and Research Structures and Their Enhancement)(grant numbers:MNET18/ICT-3415); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9399420","Knowledge based systems;Internet of Things;reliability;sensor systems;sustainable development","Reliability;Cloud computing;Wireless sensor networks;Security;Software reliability;Monitoring;Media","","8","","49","CCBYNCND","9 Apr 2021","","","IEEE","IEEE Journals"
"Digital Transformation in Complex Systems","N. Lakemond; G. Holmberg; A. Pettersson","Department of Management and Engineering, Linköping University, Linköping, Sweden; Department of Management and Engineering, Linköping University, Linköping, Sweden; SAAB Aeronautics, Linköping, Sweden",IEEE Transactions on Engineering Management,"1 Dec 2023","2024","71","","192","204","Complex systems increasingly include embedded digital technologies that interact with and are constrained by physical components and systems. Although these systems play a central role in our society, they have only been scarcely addressed in contemporary research on digital transformation and the organization of innovation. This article explores the digital transformation in complex products and systems and its consequences for organizational design. A longitudinal study of avionics development since the 1950s uncovers the application of digital technologies, first as a sequence of initial experiments, followed by the use as add-on functionality, then as an integral part of achieving critical functionality in systems, and currently combining add-on and critical functionalities enabling generativity. The findings emphasize the evolution of the intricate relationships between the systems architecture and organizational approaches when digital technology enables and enforces increased complexity, expanded functionality, increased systems integration, and continuous development. These nested dependencies are accentuated by the complexity that has emerged beyond human cognition, where increasingly sophisticated boundary objects based on modeling, simulation, and data play an important role in the organization's ability. Boundary objects relate and decouple the multifacetted dynamic relation between organization and architecture. The results also extend existing perspectives on platform strategies by outlining the importance of generativity in combination with criticality control, rather than market control. Criticality control in combination with generativity has become imperative not least as generative digital technologies have become central in achieving critical properties such as safety. Several avenues for further research are outlined.","1558-0040","","10.1109/TEM.2021.3118203","Marianne and Marcus Wallenberg Foundation(grant numbers:2019-0126); VINNOVA(grant numbers:2018-02921); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9586559","Complex product systems;digital transformation;management of innovation;organization design;product design;systems engineering;technology-based organizations","Technological innovation;Industries;Aerospace electronics;Computer architecture;Complexity theory;System integration;Digital transformation","","19","","81","CCBY","26 Oct 2021","","","IEEE","IEEE Journals"
"A Novel Technique of Synthetic Data Generation for Asset Administration Shells in Industry 4.0 Scenarios","S. De; P. Mitra","Centre for Computational and Data Science, IIT Kharagpur, West Bengal, India; Centre for Computational and Data Science, IIT Kharagpur, West Bengal, India",IEEE Transactions on Artificial Intelligence,"16 Oct 2024","2024","5","10","5258","5266","Manufacturing plants are highly dependent on machines and involve a significant number of equipment to produce a finished product. Industry 4.0 helps structure the processes involved in such setups and enables the functionalities of how the equipment and machines interact with each other. With the advancement of visualizing these types of equipment as digital twins, multiple opportunities have developed for automating processes and optimizing various aspects of the assembly, especially for original equipment manufacturers (OEMs). One problem that concerns a network of manufacturers is the availability of equipment and spare parts data which are sometimes confidential but are required by a new member in the network for several analytical applications. This article looks at this problem statement to turn this into an opportunity by introducing a novel concept of AASGAN that combines the knowledge representation of a digital twin data in the asset administration shell (AAS) and a synthetic data generation technique of generative adversarial network (GAN) to generate fake data that is identical to real data. This article also explains how this concept helps perform analytical operations using industry grade solutions for the automotive industry available for managing digital twins and other scenarios for industrial automation.","2691-4581","","10.1109/TAI.2024.3409516","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10547576","Agent-based simulation;artificial intelligence (AI) in industrial engineering;context analysis;convolutional neural networks;knowledge management;knowledge representation","Digital twins;Standards;Industries;Generative adversarial networks;Synthetic data;Fourth Industrial Revolution;Data models","","","","24","IEEE","4 Jun 2024","","","IEEE","IEEE Journals"
"Extrapolation Method of On-Orbit Soft Error Rates of EDAC SRAM Devices From Accelerator-Based Tests","Z. Zhang; Z. Lei; G. Zhao; Y. Juan; Y. He; C. Peng; Y. Liu; Q. Shi; Y. Huang; Y. En","Science and Technology on Reliability Physics and Application of Electronic Component Laboratory, China Electronic Product Reliability and Environmental Testing Research Institute, Guangzhou, China; Science and Technology on Reliability Physics and Application of Electronic Component Laboratory, China Electronic Product Reliability and Environmental Testing Research Institute, Guangzhou, China; China Electronics Technology Group Corporation No.58 Research Institute, Wuxi, China; China Electronics Technology Group Corporation No.58 Research Institute, Wuxi, China; Science and Technology on Reliability Physics and Application of Electronic Component Laboratory, China Electronic Product Reliability and Environmental Testing Research Institute, Guangzhou, China; Science and Technology on Reliability Physics and Application of Electronic Component Laboratory, China Electronic Product Reliability and Environmental Testing Research Institute, Guangzhou, China; Science and Technology on Reliability Physics and Application of Electronic Component Laboratory, China Electronic Product Reliability and Environmental Testing Research Institute, Guangzhou, China; Science and Technology on Reliability Physics and Application of Electronic Component Laboratory, China Electronic Product Reliability and Environmental Testing Research Institute, Guangzhou, China; Science and Technology on Reliability Physics and Application of Electronic Component Laboratory, China Electronic Product Reliability and Environmental Testing Research Institute, Guangzhou, China; Science and Technology on Reliability Physics and Application of Electronic Component Laboratory, China Electronic Product Reliability and Environmental Testing Research Institute, Guangzhou, China",IEEE Transactions on Nuclear Science,"14 Nov 2018","2018","65","11","2802","2807","Single-event upset sensitivity of 55- and 180-nm SRAM devices with error detection and correction (EDAC) exhibits obvious ion flux and scrubbing time dependence. On-orbit soft error rates (SERs) of EDAC SRAM devices are extrapolated from accelerator heavy-ion data and compared with rectangular parallelepiped-predicted SER, based on an experimentally verified formula. It is found that on-orbit SER of EDAC SRAM is contributed by both the memory array and the EDAC circuitry. This method can guide the optimization of EDAC SRAM hardening strategy and also the on-orbit hardness assurance.","1558-1578","","10.1109/TNS.2018.2875051","National Natural Science Foundation of China(grant numbers:11505033); Science and Technology Research Project of Guangdong, China(grant numbers:2015B090901048,2017B090901068,2015B090912002); Science and Technology Plan Project of Guangzhou, China(grant numbers:201707010186); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8486972","Error detection and correction (EDAC);Hamming code;on-orbit soft error rate (SER);single event upset (SEU)","Random access memory;Error correction;Error analysis;Sensitivity;Radiation effects;Single event upsets;Extrapolation","","5","","16","IEEE","9 Oct 2018","","","IEEE","IEEE Journals"
"Blockchain-Based Process Quality Data Sharing Platform for Aviation Suppliers","P. Cao; G. Duan; J. Tu; Q. Jiang; X. Yang; C. Li","School of Mechanical Engineering and Automation, Beihang University, Beijing, China; School of Mechanical Engineering and Automation, Beihang University, Beijing, China; Jiangxi Changhe Aircraft Industry (Group) Company Ltd., Jingdezhen, China; Jiangxi Changhe Aircraft Industry (Group) Company Ltd., Jingdezhen, China; Jiangxi Changhe Aircraft Industry (Group) Company Ltd., Jingdezhen, China; Jiangxi Changhe Aircraft Industry (Group) Company Ltd., Jingdezhen, China",IEEE Access,"1 Mar 2023","2023","11","","19007","19023","Given the challenge of manufacturing data silos and information credibility issues in traditional aviation suppliers’ result-oriented management approach, this paper proposes a blockchain-based aviation supplier manufacturing process quality data-sharing platform. Firstly, the paper introduces the possibility of integrating manufacturing supply chain quality management with blockchain technology. Secondly, the quality and data sharing platform architecture of the production process of new aviation suppliers is presented based on quality state and island kinds of aviation suppliers. Then, a detailed method for the implementation of quality and data security sharing is proposed to support the sharing platform’s real-time and orderly operation. Build critical technologies such as manufacturing quality data block packaging models, data storage security sharing, and supplier assessment models on this foundation. Finally, depending on data collection of supplier product production processes to shared application practices based on a specific aircraft industrial park under the supervision of the platform architecture and technology. The application platform integrates the data supply and request components, providing practical and intelligent sharing solutions for airlines’ product quality data.","2169-3536","","10.1109/ACCESS.2023.3246984","basic research project(grant numbers:JCKY2020205C013); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10049436","Blockchain;supplier management;data sharing;evaluation mechanism;data information management","Blockchains;Supply chains;Quality management;Manufacturing;Security;Quality assessment;Product design","","3","","40","CCBYNCND","22 Feb 2023","","","IEEE","IEEE Journals"
"Green Crowdfunding: An Empirical Study of Success Factors","F. Corsini; F. P. Appio; M. Frey","Interdisciplinary Research Center on Sustainability and Climate, Scuola Superiore Sant'Anna di Pisa, Pisa, Italy; Paris School of Business, Paris, France; Interdisciplinary Research Center on Sustainability and Climate, Scuola Superiore Sant'Anna di Pisa, Pisa, Italy",IEEE Transactions on Engineering Management,"10 Apr 2024","2024","71","","7654","7668","Despite the growing body of research on crowdfunding, there is still a critical need to clarify the essential elements of its connection to sustainability. This study explores how various constructs, such as green product codesign, green market insight, environmental legitimacy, and the stage of product development, bear on the success of crowdfunding endeavors intended to finance eco-friendly products. We employed a questionnaire to gather insights from 113 campaign initiators, deviating from the predominant focus on web-based data collection found in much of the existing literature. The collected data were then examined through the application of structural equation modeling techniques. The findings indicate that, with the exception of environmental legitimacy, all the examined constructs exhibited a positive effect on the campaign's success. Furthermore, it was observed that the stage of development subtly diminishes the positive relationship between green product codesign practices and the success of a crowdfunding campaign. Our study offers valuable theoretical insights in light of these findings. In addition, the article proffers pragmatic suggestions for more effective crowdfunding of sustainable products.","1558-0040","","10.1109/TEM.2024.3381437","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10478988","Green crowdfunding;legitimacy theory;new product development (NPD);success factors;sustainability","Crowdfunding;Green products;Sustainable development;Product development;Investment;Companies;Technological innovation","","2","","130","CCBYNCND","25 Mar 2024","","","IEEE","IEEE Journals"
"Variable Binding for Sparse Distributed Representations: Theory and Applications","E. P. Frady; D. Kleyko; F. T. Sommer","Neuromorphic Computing Lab, Intel Labs, Santa Clara, CA, USA; Redwood Center for Theoretical Neuroscience, University of California, Berkeley, CA, USA; Neuromorphic Computing Lab, Intel Labs, Santa Clara, CA, USA",IEEE Transactions on Neural Networks and Learning Systems,"2 May 2023","2023","34","5","2191","2204","Variable binding is a cornerstone of symbolic reasoning and cognition. But how binding can be implemented in connectionist models has puzzled neuroscientists, cognitive psychologists, and neural network researchers for many decades. One type of connectionist model that naturally includes a binding operation is vector symbolic architectures (VSAs). In contrast to other proposals for variable binding, the binding operation in VSAs is dimensionality-preserving, which enables representing complex hierarchical data structures, such as trees, while avoiding a combinatoric expansion of dimensionality. Classical VSAs encode symbols by dense randomized vectors, in which information is distributed throughout the entire neuron population. By contrast, in the brain, features are encoded more locally, by the activity of single neurons or small groups of neurons, often forming sparse vectors of neural activation. Following Laiho et al. (2015), we explore symbolic reasoning with a special case of sparse distributed representations. Using techniques from compressed sensing, we first show that variable binding in classical VSAs is mathematically equivalent to tensor product binding between sparse feature vectors, another well-known binding operation which increases dimensionality. This theoretical result motivates us to study two dimensionality-preserving binding methods that include a reduction of the tensor matrix into a single sparse vector. One binding method for general sparse vectors uses random projections, the other, block-local circular convolution, is defined for sparse vectors with block structure, sparse block-codes. Our experiments reveal that block-local circular convolution binding has ideal properties, whereas random projection based binding also works, but is lossy. We demonstrate in example applications that a VSA with block-local circular convolution and sparse block-codes reaches similar performance as classical VSAs. Finally, we discuss our results in the context of neuroscience and neural networks.","2162-2388","","10.1109/TNNLS.2021.3105949","European Union’s Horizon 2020 Research and Innovation Program under the Marie Skłodowska-Curie Individual Fellowship(grant numbers:839179); DARPA’s Virtual Intelligence Processing (VIP) (Super-HD Project) and Artificial Intelligence Exploration (AIE) (HyDDENN Project) programs; NIH(grant numbers:R01-EB026955); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9528907","Classification;cognitive reasoning;compressed sensing (CS);sparse block-codes;sparse distributed representations;tensor product variable binding;vector symbolic architectures (VSAs)","Data structures;Neurons;Cognition;Tensors;Convolution;Compounds;Sparse matrices","Neural Networks, Computer;Cognition;Brain;Problem Solving;Neurons","27","","87","IEEE","3 Sep 2021","","","IEEE","IEEE Journals"
"Fusion of Satellite Images and Weather Data With Transformer Networks for Downy Mildew Disease Detection","W. Maillet; M. Ouhami; A. Hafiane","PRISME Laboratory, INSA CVL, University of Orléans, Bourges, France; PRISME Laboratory, INSA CVL, University of Orléans, Bourges, France; PRISME Laboratory, INSA CVL, University of Orléans, Bourges, France",IEEE Access,"20 Jan 2023","2023","11","","5406","5416","Crop diseases significantly affect the quantity and quality of agricultural production. In a context where the goal of precision agriculture is to minimize or even avoid the use of pesticides, weather and remote sensing data with deep learning can play a pivotal role in detecting crop diseases, allowing localized treatment of crops. However, combining heterogeneous data such as weather and images remains a hot topic and challenging task. Recent developments in transformer architectures have shown the possibility of fusion of data from different domains, such as text-image. The current trend is to custom only one transformer to create a multimodal fusion model. Conversely, we propose a new approach to realize data fusion using three transformers. In this paper, we first solved the missing satellite images problem, by interpolating them with a ConvLSTM model. Then, we proposed a multimodal fusion architecture that jointly learns to process visual and weather information. The architecture is built from three main components, a Vision Transformer and two transformer-encoders, allowing to fuse both image and weather modalities. The results of the proposed method are promising achieving an overall accuracy of 97%.","2169-3536","","10.1109/ACCESS.2023.3237082","European Consortium ERA-NET ICT-AGRI-FOOD; French National Research Agency (ANR)(grant numbers:ANR-21-ICAF-0002-01); European Project MERIAVINO; ICT-AGRIFOOD ERA-NET; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10017285","Remote sensing;image processing;deep learning;data fusion;vegetation indices;crop monitoring;agriculture","Transformers;Meteorology;Satellites;Feature extraction;Diseases;Crops;Computer architecture;Vegetation mapping;Indexes;Deep learning;Remote sensing","","7","","49","CCBY","16 Jan 2023","","","IEEE","IEEE Journals"
"Developing and Evolving a Digital Twin of the Organization","F. Edrisi; D. Perez-Palacin; M. Caporuscio; S. Giussani","Department of Computer Science and Media Technology, Linnaeus University, Växjö, Sweden; Department of Computer Science and Media Technology, Linnaeus University, Växjö, Sweden; Department of Computer Science and Media Technology, Linnaeus University, Växjö, Sweden; Department of Computer Science and Media Technology, Linnaeus University, Växjö, Sweden",IEEE Access,"29 Mar 2024","2024","12","","45475","45494","Digital Twin of the Organization (DTO) is a relatively new concept that emerged to help managers have a full understanding of their organization and realize their objectives. Indeed, DTO enables connecting all the elements of an organization virtually by providing monitoring, optimization, prediction, and other capabilities through continuous simulations. Creating a flexible and evolvable DTO that covers and supports the organization’s business strategies is a complex and time-consuming task that requires engineering best practices. In this context, this paper presents and evaluates the EA Blueprint Pattern, which serves as an architectural reference for the development of a DTO by allowing for mapping well-known Enterprise Architecture concepts into software components defining the DTO software architecture. The evaluation is carried on by showing how to use the pattern for creating the DTO for a given organization. Then, a thorough discussion is conducted to analyze how the developed DTO should evolve to deal with vertical and horizontal integration. The lessons learned highlight the strengths and weaknesses along with practical implications for organizations that are eager to develop their DTO according to the EA Blueprint Pattern.","2169-3536","","10.1109/ACCESS.2024.3381778","Swedish Knowledge Foundation(grant numbers:20200117); ALADINO – ALigning Architectures for DIgital twiN of the Organization; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10478895","Digital twin;EA blueprint pattern;enterprise architecture;organizational integration;software evolution","Digital twins;Decision making;Information systems;Computer architecture;Standards organizations;Pattern analysis;Organizational aspects;Software engineering;Enterprise architecture management","","","","61","CCBY","25 Mar 2024","","","IEEE","IEEE Journals"
"An Algebra for Fuzzy Spatiotemporal Data in XML","L. Bai; L. Zhu","School of Computer and Communication Engineering, Northeastern University (Qinhuangdao), Qinhuangdao, China; School of Computer and Communication Engineering, Northeastern University (Qinhuangdao), Qinhuangdao, China",IEEE Access,"28 Feb 2019","2019","7","","22914","22926","A formal algebra is essential for applying standard database-style query optimization to XML queries. We develop such algebra for manipulating fuzzy spatiotemporal XML data. We also introduce several formal characterizations of fuzzy spatiotemporal algebraic equivalences and study how XQuery expressions can be transformed into algebraic expressions. It shows that the algebra can lay a firm foundation for managing fuzzy spatiotemporal XML data.","2169-3536","","10.1109/ACCESS.2019.2898228","National Natural Science Foundation of China(grant numbers:61402087); Natural Science Foundation of Hebei Province(grant numbers:F2019501030); Fundamental Research Funds for the Central Universities(grant numbers:N172304026); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8637954","Algebra;fuzzy spatiotemporal data;XML","XML;Spatiotemporal phenomena;Algebra;Data models;Vegetation;Finite element analysis;Standards","","5","","29","OAPA","8 Feb 2019","","","IEEE","IEEE Journals"
"Energy-Efficient High-Throughput VLSI Architectures for Product-Like Codes","C. Fougstedt; P. Larsson-Edefors","Department of Computer Science and Engineering, Chalmers University of Technology, Gothenburg, Sweden; Department of Computer Science and Engineering, Chalmers University of Technology, Gothenburg, Sweden",Journal of Lightwave Technology,"19 Feb 2019","2019","37","2","477","485","Implementing forward error correction (FEC) for modern long-haul fiber-optic communication systems is a challenge, since these high-throughput systems require FEC circuits that can combine high coding gains and energy-efficient operation. We present very large scale integration (VLSI) decoder architectures for product-like codes for systems with strict throughput and power dissipation requirements. To reduce energy dissipation, our architectures are designed to minimize data transfers in and out of memory blocks, and to use parallel noniterative component decoders. Using a mature 28-nm VLSI process technology node, we showcase different product and staircase decoder implementations that have the capacity to exceed 1-Tb/s information throughputs with energy efficiencies of around 2 pJ/b.","1558-2213","","10.1109/JLT.2019.2893039","Knut och Alice Wallenbergs Stiftelse; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8611331","Application specific integrated circuits;error correction codes;iterative decoding;very large scale integration","Decoding;Very large scale integration;Iterative decoding;Product codes;Forward error correction;Encoding;Throughput","","25","","26","IEEE","13 Jan 2019","","","IEEE","IEEE Journals"
"Simulating the Network Activity of Modern Manycores","M. Horro; G. Rodríguez; J. Touriño","Computer Architecture Group, CITIC, Universidade da Coruña, A Coruña, Spain; Computer Architecture Group, CITIC, Universidade da Coruña, A Coruña, Spain; Computer Architecture Group, CITIC, Universidade da Coruña, A Coruña, Spain",IEEE Access,"1 Jul 2019","2019","7","","81195","81210","Manycore architectures are one of the most promising candidates to reach the exascale. However, the increase in the number of cores on a single die exacerbates the memory wall problem. Modern manycore architectures integrate increasingly complex and heterogeneous memory systems to work around the memory bottleneck while increasing computational power. The Intel Mesh Interconnect architecture is the latest interconnect designed by Intel for its HPC product lines. Processors are organized in a rectangular network-on-chip (NoC), connected to several different memory interfaces, and using a distributed directory to guarantee coherent memory accesses. Since the traffic on the NoC is completely opaque to the programmer, simulation tools are needed to understand the performance trade-offs of code optimizations. Recently featured in Intel's Xeon Scalable lines, this interconnect was first included in the Knights Landing (KNL), a manycore processor with up to 72 cores. This work analyzes the behavior of the Intel Mesh Interconnect through the KNL architecture, proposing ways to discover the physical layout of its logical components. We have designed and developed an extension to the Tejas memory system simulator to replicate and study the low-level data traffic of the processor network. The reliability and accuracy of the proposed simulator is assessed using several state-of-the-art sequential and parallel benchmarks, and a particular Intel Mesh Interconnect-focused locality optimization is proposed and studied using the simulator and a real KNL system.","2169-3536","","10.1109/ACCESS.2019.2923855","Ministerio de Economía y Competitividad(grant numbers:TIN2016-75845-P (AEI/FEDER/EU)); Ministry of Education(grant numbers:FPU16/00816); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8740875","Computer architecture;cache coherence;distributed cache directory;high-performance computing;architectural simulator","Computer architecture;Program processors;Coherence;Optimization;Nonvolatile memory;Reverse engineering;Layout","","5","","38","CCBY","19 Jun 2019","","","IEEE","IEEE Journals"
"CMOL/CMOS Implementations of Bayesian Polytree Inference: Digital and Mixed-Signal Architectures and Performance/Price","M. S. Zaveri; D. Hammerstrom","Department of Electrical and Computer Engineering, Portland State University, Portland, OR, USA; Department of Electrical and Computer Engineering, Portland State University, Portland, OR, USA",IEEE Transactions on Nanotechnology,"8 Mar 2010","2010","9","2","194","211","In this paper, we focus on aspects of the hardware implementation of the Bayesian inference framework within the George and Hawkins' model. This framework is based on Judea Pearl's belief propagation. We then present a ¿hardware design space exploration¿ methodology for implementing and analyzing the (digital and mixed-signal) hardware for the Bayesian (polytree) inference framework. This, particular, methodology involves: analyzing the computational/operational cost and the related microarchitecture, exploring candidate hardware components, proposing various custom architectures using both traditional CMOS and hybrid nanotechnology CMOS/nanowire/molecular hybrid (CMOL), and investigating the baseline performance/price of these hardware architectures. The results suggest that hybrid nanotechnology is a promising candidate to implement Bayesian inference. Such implementations utilize the very high density storage/computation benefits of these new nanoscale technologies much more efficiently, for example, the throughput per 858 mm2 obtained for CMOL-based architectures is 32-40 times better than the TPM for a CMOS based multiprocessor/multifield-programmable gate array system, and almost 2000 times better than the TPM for a single PC implementation. In general, the assessment of such hypothetical hardware architectures provides a baseline for large-scale implementations of Bayesian inference, and guidance for implementing the same using nanogrid structures.","1941-0085","","10.1109/TNANO.2009.2028342","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5175451","Bayesian inference;CMOS/nanowire/molecular hybrid (CMOL);CMOS;digital;hardware;methodology;mixed signal (MS);nanoarchitectures;nanogrid;performance;Pearl's belief propagation;price","Bayesian methods;Hardware;Computer architecture;Space exploration;Nanotechnology;Semiconductor device modeling;Belief propagation;Design methodology;Performance analysis;Computational efficiency","","10","","52","IEEE","28 Jul 2009","","","IEEE","IEEE Journals"
"A 3-D CPU-FPGA-DRAM Hybrid Architecture for Low-Power Computation","X. Chen; N. K. Jha","Department of Electrical Engineering, Princeton University, Princeton, NJ, USA; Department of Electrical Engineering, Princeton University, Princeton, NJ, USA",IEEE Transactions on Very Large Scale Integration (VLSI) Systems,"21 Apr 2016","2016","24","5","1649","1662","The power budget is expected to limit the portion of the chip that we can power ON at the upcoming technology nodes. This problem, known as the utilization wall or dark silicon, is becoming increasingly serious. With the introduction of 3-D integrated circuits (ICs), it is likely to become more severe. Thus, how to take advantage of the extra transistors, made available by Moore's law and the onset of 3-D ICs, within the power budget poses a significant challenge to system designers. To address this challenge, we propose a 3-D hybrid architecture consisting of a CPU layer with multiple cores, a field-programmable gate array (FPGA) layer, and a DRAM layer. The architecture is designed for low power without sacrificing performance. The FPGA layer is capable of supporting a large number of accelerators. It is placed adjacent to the CPU layer, with a communication mechanism that allows it to access CPU data caches directly. This enables fast switches between these two layers. This architecture reduces the power and energy significantly, at better or similar performance. This then alleviates the dark silicon problem by letting us power ON more components to achieve higher performance. We evaluate the proposed architecture through a new framework we have developed. Relative to the out-of-order CPU, the accelerators on the FPGA layer can reduce function-level power by 6.9× and energy-delay product (EDP) by 7.2×, and application-level power by 1.9× and EDP by 2.2×, while delivering similar performance. For the entire system, this translates to a 47.5% power reduction relative to a baseline system that consists of a CPU layer and a DRAM layer. This also translates to a 72.9% power reduction relative to an alternative system that consists of a CPU layer, an L3 cache layer, and a DRAM layer.","1557-9999","","10.1109/TVLSI.2015.2483525","National Science Foundation(grant numbers:CCF-1216457); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7300466","3-D integrated circuit (IC);CPU;DRAM;field-programmable gate array (FPGA);hybrid architecture;low power;3-D integrated circuit (IC);CPU;DRAM;field-programmable gate array (FPGA);hybrid architecture;low power","Field programmable gate arrays;Computer architecture;Random access memory;Registers;Central Processing Unit;Hardware","","10","","59","IEEE","19 Oct 2015","","","IEEE","IEEE Journals"
"Designing a Magnetic Measurement Data Acquisition and Control System With Reuse in Mind: A Rotating Coil System Example","J. M. Nogiec; P. Akella; G. Chlachidze; J. DiMarco; M. Tartaglia; P. Thompson; K. Trombly-Freytag; D. Walbridge","Fermi National Accelerator Laboratory, Batavia, IL, USA; Fermi National Accelerator Laboratory, Batavia, IL, USA; Fermi National Accelerator Laboratory, Batavia, IL, USA; Fermi National Accelerator Laboratory, Batavia, IL, USA; Fermi National Accelerator Laboratory, Batavia, IL, USA; Fermi National Accelerator Laboratory, Batavia, IL, USA; Fermi National Accelerator Laboratory, Batavia, IL, USA; Fermi National Accelerator Laboratory, Batavia, IL, USA",IEEE Transactions on Applied Superconductivity,"15 Mar 2022","2022","32","6","1","5","Accelerator magnet test facilities frequently need to measure different magnets on differently equipped test stands and with different instrumentation. Designing a modular and highly reusable system that combines flexibility built-in at the architectural level as well as on the component level addresses this need. Specification of the backbone of the system, with the interfaces and dataflow for software components and core hardware modules, serves as a basis for building such a system. The design process and implementation of an extensible magnetic measurement data acquisition and control system are described, including techniques for maximizing the reuse of software. The discussion is supported by showing the application of this methodology to constructing two dissimilar systems for rotating coil measurements, both based on the same architecture and sharing core hardware modules and many software components. The first system is for production testing 10 m long cryo-assemblies containing two MQXFA quadrupole magnets for the high-luminosity upgrade of the Large Hadron Collider and the second for testing IQC conventional quadrupole magnets in support of the accelerator system at Fermilab.","1558-2515","","10.1109/TASC.2022.3156061","Fermi Research Alliance(grant numbers:DE-AC02-07CH11359); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9727087","Magnetic field measurement;measurement techniques;accelerator magnets;software reusability;software product lines","6G mobile communication;Harmonic analysis","","2","","12","IEEE","3 Mar 2022","","","IEEE","IEEE Journals"
"Availability Model for Data Center Networks With Dynamic Migration and Multiple Traffic Flows","J. Zhu; N. Huang; J. Wang; X. Qin","School of Reliability and System Engineering and the Key Laboratory of Science and Technology on Reliability and Environmental Engineering, Beihang University, Beijing, China; School of Reliability and System Engineering and the Key Laboratory of Science and Technology on Reliability and Environmental Engineering, Beihang University, Beijing, China; Department of Cloud Network Operation, China Telecom Research Institute, Guangzhou, China; Data Communication Product Line Architecture and Design Department, Huawei Technology Cooperation, Beijing, China",IEEE Transactions on Network and Service Management,"9 Oct 2023","2023","20","3","2975","2989","The evaluation of application availability is a crucial step in ensuring functionality of the data center network (DCN). The application of data center network is no more a chain of physical devices, but a chain of virtualized network function (VNF) dynamically installed in servers, i.e., the service function chain (SFC), due to the adaptation of network function virtualization (NFV). When dynamic migration is considered, the application availability evaluation would encounter problems since the state of VNF components is not independent. And in the application deployed in DCN, there is multiple traffic flow because of the serialization of 1+1 (active-standby) and N-way (load-sharing) redundant VNF, however only single flow is considered in current availability model. When dynamic migration and multiple traffic flows are considered, the application availability evaluation would encounter the following problems: 1) The application behavior is not described in the existing availability model; 2) The availability model could not quantify the influence of different traffic of each flow. This paper proposes an availability model, which consist of network evolution model (NEM) of DCN and the availability evaluation algorithm based on NEM (AEA-NEM), to evaluate the availability of different applications deployed on DCN. The NEM of DCN describes the dynamical process of migration and switch of three kinds of VNF (normal, 1+1 and N-way) in application, and the AEA-NEM evaluate the availability of application with multiple traffic flows. The simulation results show that, the steady state availability of the proposed model is consistent with it of generalized stochastic Petri net (GSPN) model. And the model could evaluate the application availability with dynamic migration and multiple traffic flows in DCN. Based on the current VNF placement and redundant strategy, the most available designing scheme is analyzed.","1932-4537","","10.1109/TNSM.2023.3242321","National Natural Science Foundation of China(grant numbers:61872018); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10037235","Data center network;network function virtualization;application reliability;network evolution model;service function chain","Noise measurement;Servers;Switches;Redundancy;Nanoelectromechanical systems;Data centers;Maintenance engineering","","7","","39","IEEE","6 Feb 2023","","","IEEE","IEEE Journals"
"Benchmarking In-Memory Computing Architectures","N. R. Shanbhag; S. K. Roy","Department of Electrical and Computer Engineering, University of Illinois at Urbana–Champaign, Urbana, IL, USA; Department of Electrical and Computer Engineering, University of Illinois at Urbana–Champaign, Urbana, IL, USA",IEEE Open Journal of the Solid-State Circuits Society,"14 Dec 2022","2022","2","","288","300","In-memory computing (IMC) architectures have emerged as a compelling platform to implement energy-efficient machine learning (ML) systems. However, today, the energy efficiency gains provided by IMC designs seem to be leveling off and it is not clear what the limiting factors are. The conceptual complexity of IMCs combined with the absence of a rigorous benchmarking methodology makes it difficult to gauge progress and identify bottlenecks in this exciting field. This article presents a benchmarking methodology for IMCs comprising: 1) a compositional view of IMCs that enables one to parse an IMC design into its canonical components; 2) a set of benchmarking metrics to quantify the performance, efficiency, and accuracy of IMCs; and 3) a strategy for analyzing the reported IMC data and metrics. We apply the proposed benchmarking methodology on an extensive database of IMC metrics extracted from > 70 IC designs published since 2018, in order to infer and comprehend trends in this area. Our benchmarking effort indicates: 1) SRAM-based IMCs show a clear win in terms of energy efficiency and compute density over digital accelerators at the bank level but the energy efficiency gap reduces dramatically when comparing at the processor level; 2) eNVM-based IMCs lag behind SRAM-based IMCs in terms of both energy efficiency and compute density, and surprisingly lag digital accelerators in terms of compute density; 3) the compute (bank-level) accuracy of IMCs, though a critical metric, is pervasively neglected in publications as is the energy versus accuracy tradeoff inherent to IMCs.","2644-1349","","10.1109/OJSSCS.2022.3210152","Defense Advanced Research Projects Agency (DARPA) and the Semiconductor Research Corporation (SRC) through the DARPA Electronic Resurgence Initiative (ERI) FRANC Program and the Center on Brain-Inspired Computing (C-BRIC); Semiconductor Research Corporation (SRC); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9976888","Benchmarking;eNVM;in-memory computing (IMC);SRAM","Memory management;Benchmark testing;Random access memory;Energy efficiency;Integrated circuits;Computer architecture;Market research;SRAM chips","","15","","111","CCBY","8 Dec 2022","","","IEEE","IEEE Journals"
"Message-Passing Receiver Architecture with Reduced-Complexity Channel Estimation","M. -A. Badiu; C. N. Manchon; B. H. Fleury","Department of Electronic Systems, Aalborg University, Denmark; Department of Electronic Systems, Aalborg University, Denmark; Department of Electronic Systems, Aalborg University, Denmark",IEEE Communications Letters,"23 Jul 2013","2013","17","7","1404","1407","We propose an iterative receiver architecture which allows for adjusting the complexity of estimating the channel frequency response in OFDM systems. This is achieved by approximating the exact Gaussian channel model assumed in the system with a Markov model whose state-space dimension is a design parameter. We apply an inference framework combining belief propagation and the mean field approximation to a probabilistic model of the system which includes the approximate channel model. By doing so, we obtain a receiver algorithm with adjustable complexity which jointly performs channel and noise precision estimation, equalization and decoding. Simulation results show that low-complexity versions of the algorithm - obtained by selecting low state-space dimensions - can closely attain the performance of a receiver devised based on the exact channel model.","1558-2558","","10.1109/LCOMM.2013.060513.130733","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6530822","Channel estimation;iterative algorithms;message passing;receiver design","Receivers;Channel estimation;Complexity theory;Approximation methods;Vectors;Approximation algorithms;Noise","","12","","9","IEEE","12 Jun 2013","","","IEEE","IEEE Journals"
"A Simulation Framework for Virtualized Resources in Cloud Data Center Networks","P. Bellavista; A. Corradi; L. Foschini; S. Luciano; M. Solimando","DISI, Universitá di Bologna, Bologna, Italy; DISI, Universitá di Bologna, Bologna, Italy; DISI, Universitá di Bologna, Bologna, Italy; DISI, Universitá di Bologna, Bologna, Italy; DISI, Universitá di Bologna, Bologna, Italy",IEEE Journal on Selected Areas in Communications,"6 Aug 2019","2019","37","8","1808","1819","Many IT companies are embracing the new softwarization paradigm through the adoption of new architecture models, such as software-defined network and network function virtualization, primarily to limit the costs of maintaining and deploying their network infrastructures, by giving the possibility to service/application providers to reconfigure and programmatically perform actions on the network. Accordingly, the dynamic management of the data center networks requires complex operations to ensure high availability and continuous reliability in order to guarantee full functionality of the virtualized resources. In this context, simulator-based approaches are helpful for planning and evaluating the deployment of the cloud data center networking, but existing cloud simulators have several limitations: they have too high overhead for wide-scale data center networks, complex configuration, and too abstract deployment models. For these motivations, we propose DCNs-2, a novel extension for the Ns-2 simulator, as a valid solution to efficiently simulate a cloud network infrastructure, with all the involved entities, such as switches, physical/virtual machines, and racks. The proposed solution not only makes configuration easier, but through extensive tests, we show that its execution overhead is limited to less than 130 MB of memory and the execution time is acceptable even for very wide-scale and complex deployment environments.","1558-0008","","10.1109/JSAC.2019.2927066","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8758131","Network simulation;data center network;software-defined networks;network functions virtualization;cloud computing;infrastructure as a service;Ns-2","Cloud computing;Data centers;Network topology;Computational modeling;Topology;Green products;Data models","","4","","32","IEEE","9 Jul 2019","","","IEEE","IEEE Journals"
"FLScalize: Federated Learning Lifecycle Management Platform","S. Yang; J. Moon; J. Kim; K. Lee; K. Lee","Department of Computer Engineering, Gachon University, Seongnam-si, South Korea; Department of Computer Engineering, Gachon University, Seongnam-si, South Korea; Innopia Technologies Inc., Seongnam-si, South Korea; Innopia Technologies Inc., Seongnam-si, South Korea; Department of Computer Engineering, Gachon University, Seongnam-si, South Korea",IEEE Access,"19 May 2023","2023","11","","47212","47222","Federated learning (FL) that can train using machine learning methods without moving data have attracted interest owing to the focus on data privacy. Several FL platforms and frameworks are being developed with various open datasets. However, FL has not yet been fully utilized in real-world projects; instead, centralized ML models are still being used for AI. Since FL is composed of numerous clients and executed, it is necessary to manage the lifecycle such as model deployment and status management to multiple clients in order to operate FL. This study proposes FLScalize to enable AI researchers to apply their own custom data and models to FL environments and to deploy and manage the FL lifecycle. Researchers who develop these models should be able to easily and conveniently apply custom data and models developed in a centralized environment to FL environments, deploy and train multiple clients, and manage the lifecycle of the entire FL process. FLScalize can be used to simulate system heterogeneity and data heterogeneity, both of which are FL issues that occur in real FL environments. Furthermore, FLScalize provides a manager component that continuously manages the FL client and server required for real-world FL tasks and realizes an FL lifecycle management implementation that enables continuous integration, deployment, and training.","2169-3536","","10.1109/ACCESS.2023.3275439","Commercializations Promotion Agency for Research and Development Outcome (COMPA); Korean Government (MSIT) through the Future Research Service Development Support(grant numbers:2022-1-SB4-1); National Research Foundation of Korea (NRF) Grant funded by MSIT(grant numbers:NRF-2022R1F1A1069069); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10122960","Federated learning;heterogeneous simulation;lifecycle management;platform","Data models;Servers;Predictive models;Task analysis;Simulation;Federated learning;Product life cycle management","","5","","29","CCBYNCND","11 May 2023","","","IEEE","IEEE Journals"
"Use of the Earth Observing One (EO-1) Satellite for the Namibia SensorWeb Flood Early Warning Pilot","D. Mandl; S. Frye; P. Cappelaere; M. Handy; F. Policelli; M. Katjizeu; G. Van Langenhove; G. Aubé; J. -F. Saulnier; R. Sohlberg; J. A. Silva; N. Kussul; S. Skakun; S. G. Ungar; R. Grossman; J. Szarzynski","Goddard Space Flight Center, NASA, Green Belt, MD, USA; SGT, Green Belt, MD, USA; Vightel, Inc., Ellicott City, MD, USA; Goddard Space Flight Center, NASA, Green Belt, MD, USA; Goddard Space Flight Center, NASA, Green Belt, MD, USA; Department of Hydrology, Ministry of Agriculture, Water and Forestry, Windhoek, Namibia; Department of Hydrology, Ministry of Agriculture, Water and Forestry, Windhoek, Namibia; Canadian Space Agency, Saint Hubert, QUE, Canada; Canadian Space Agency, Saint Hubert, QUE, Canada; Department of Geographical Sciences, University of Maryland, College Park, MD, USA; Department of Geographical Sciences, University of Maryland, College Park, MD, USA; Space Research Institute, NSAU, Kyiv, Ukraine; Space Research Institute, NSAU, Kyiv, Ukraine; Goddard Space Flight Center, NASA, Green Belt, MD, USA; Computation Institute, Searle Chemistry Laboratory, University of Chicago, Chicago, IL, USA; United Nations University, Bonn, Germany",IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing,"14 May 2013","2013","6","2","298","308","The Earth Observing One (EO-1) satellite was launched in November 2000 as a one year technology demonstration mission for a variety of space technologies. After the first year, it was used as a pathfinder for the creation of SensorWebs. A SensorWeb is the integration of a variety of space, airborne and ground sensors into a loosely coupled collaborative sensor system that automatically provides useful data products. Typically, a SensorWeb is comprised of heterogeneous sensors tied together with an open messaging architecture and web services. SensorWebs provide easier access to sensor data, automated data product production and rapid data product delivery. Disasters are the perfect arena to test SensorWeb functionality since emergency workers and managers need easy and rapid access to satellite, airborne and in-situ sensor data as decision support tools. The Namibia Early Flood Warning SensorWeb pilot project was established to experiment with various aspects of sensor interoperability and SensorWeb functionality. The SensorWeb system features EO-1 data along with other data sets from such satellites as Radarsat, Terra and Aqua. Finally, the SensorWeb team began to examine how to measure economic impact of SensorWeb technology infusion. This paper describes the architecture and software components that were developed along with performance improvements that were experienced. Also, problems and challenges that were encountered are described along with a vision for future enhancements to mitigate some of the problems.","2151-1535","","10.1109/JSTARS.2013.2255861","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6509993","Earth Observing One (EO-1);Flood Early Warning;sensor systems and applications;SensorWeb","Floods;Sensors;Satellites;Earth;Computer architecture;Service-oriented architecture","","28","","10","IEEE","29 Apr 2013","","","IEEE","IEEE Journals"
"System Architectures Enabling Reconfigurable Laboratory-Automation Systems","H. O. Unver","Mechanical Engineering Department, TOBB Economics and Technology University, Ankara, Turkey","IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)","17 Oct 2011","2011","41","6","909","922","As many biopharma companies fill their drug-discovery pipeline with new blockbuster candidates every year, the integration techniques employed become more critical. In the biopharma industry, high throughput screening (HTS) is an essential function to deliver new drugs rapidly and cost effectively. This interdisciplinary function requires not only understanding of the biology and biochemistry underlying the therapeutic target but involves engineering functions, such as automation, robotics, detection technologies, high-volume data acquisition, and analysis as well. This paper discusses a six-year long research and development (R&D) effort in pursuit of developing system architectures that makes HTS systems more flexible and reconfigurable. From the capital-intensive pharmaceutical laboratories to booming biotech startups driven by advances in human genomics, changing architectural paradigms in screening automation are reviewed. Recently, flexibility and reconfigurability of systems to achieve maximum utilization has emerged as the dominant requirement from a systems perspective as reuse of expensive instruments and equipment is an essential component of cost-effectiveness in drug discovery. In order to enable reconfigurability of systems, we present our modular and object-oriented control-system framework and software-design patterns adopted into our control architecture. Embodiment of these patterns in our control architecture added value to functions of various stakeholders of products from R&D engineers, marketing/sales, to field service and users. Further, we discuss the requirements, design, and implementation of these unique patterns, which effectively balances reusability, flexibility, ease of use, and throughput in integrated-system platforms that we have developed. The techniques and models that are presented in this paper will improve architectural flexibility of HTS systems, thereby helping automation experts, scientists, chemists, and other levels of users in the field to make the most out of their systems.","1558-2442","","10.1109/TSMCC.2011.2107552","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5723018","High throughput screening (HTS);laboratory automation systems;object-oriented design and development;reconfigurable automation;software patterns","Automation;Laboratories;Object oriented methods;Computer architecture;Reconfigurable architectures;Software;Biotechnology","","3","1","38","IEEE","3 Mar 2011","","","IEEE","IEEE Journals"
"Security Implications of Third-Party Accelerators","L. E. Olson; S. Sethumadhavan; M. D. Hill","Department of Computer Sciences, University of Wisconsin-Madison, Madison, WI; Department of Computer Science, Columbia University, New York, NY; Department of Computer Sciences, University of Wisconsin-Madison, Madison, WI",IEEE Computer Architecture Letters,"19 May 2017","2016","15","1","50","53","Third-party accelerators offer system designers high performance and low energy without the market delay of in-house development. However, complex third-party accelerators may include vulnerabilities due to design flaws or malicious intent that are hard to expose during verification. Rather than react to each new vulnerability, it is better to proactively build defenses for classes of attacks. To inspire future work on defenses, this paper develops a taxonomy of accelerator vulnerabilities. We consider the cross product of threat types (confidentiality, integrity, and availability) with risk categories (configuration, computation, termination, accelerator memory accesses, system memory accesses, microarchitecture/coherence, exceptions/interrupts, and power), as well as whether processes can be vulnerable only if they use the offending accelerator (accelerator-scope threat) or even when running in the same system (system-scope threat). Our taxonomy draws attention to a grave problem that needs immediate attention from computer architects.","1556-6064","","10.1109/LCA.2015.2445337","NSF(grant numbers:FA8750-10-2-0253,FA8650-11-C-7190,1054844); Alfred P. Sloan Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7123581","Computer security;accelerator architectures;Computer security;accelerator architectures","Hardware;Coherence;Taxonomy;Cryptography;Computer bugs;Registers","","15","","21","IEEE","15 Jun 2015","","","IEEE","IEEE Journals"
"Agent-Based Decision Support and Simulation for Wood Products Manufacturing","E. Elghoneimy; W. A. Gruver","Simon Fraser University, Burnaby, BC, Canada; Simon Fraser University, Burnaby, BC, Canada","IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)","21 Dec 2012","2012","42","6","1656","1668","A rough mill is a manufacturing plant where lumber of approximate dimensions is cut into components of specific sizes, priorities, and qualities to fill customer orders for wood products such as furniture, doors, and window frames. Lumber is a valuable natural resource that is a significant expense to the company. By improving the processes in the rough mill, cost can be reduced and waste of natural materials is decreased. We present an overview of research in agent-based manufacturing systems. The operations in a rough mill are described and the decisions that operators take are identified. A rough mill decision support and simulation system is designed and implemented. An agent ontology for rough mill operations is developed. A prototype system is implemented to demonstrate the architecture and interagent communication. This prototype is extended to two lines of production and the negotiation protocol is presented. Extension of the approach to multiple lines of production is discussed. The prototype system is used to implement a decision support and simulation system that is validated with historical data. Finally, we present a comparison of the advantages and disadvantages of using the multiagent paradigm in rough mill decision support.","1558-2442","","10.1109/TSMCC.2012.2213809","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6392453","Decision support;distributed intelligent systems;intelligent systems;multiagent systems;rough mill operations;wood products manufacturing","Job shop scheduling;Control systems;Schedules","","12","","53","IEEE","21 Dec 2012","","","IEEE","IEEE Journals"
"Low-Power Wireless Uplink Utilizing Harmonic With an Integrated Rectifier–Transmitter","X. Sun; C. Liu; Y. -D. Chen; J. Jing; Z. He; P. Wu","School of Electronics and Information Engineering, Sichuan University, Chengdu, China; School of Electronics and Information Engineering, Sichuan University, Chengdu, China; Pillar of Engineering Product Development, Singapore University of Technology and Design, Singapore; Pillar of Engineering Product Development, Singapore University of Technology and Design, Singapore; School of Electronics and Information Engineering, Sichuan University, Chengdu, China; School of Electronics and Information Engineering, Sichuan University, Chengdu, China",IEEE Microwave and Wireless Components Letters,"10 Feb 2021","2021","31","2","200","203","A novel integrated rectifier-transmitter (IRT) that targets to reduce the power consumption of the uplink communication of a wireless sensor is presented in this letter. The proposed IRT fully utilizes the second harmonic generated by the rectifier as the uplink carrier and modulates this carrier in amplitude through a reconfigurable bandstop filter (BSF) that is dynamically biased by the uplink baseband signal. As a proof of concept, an IRT prototype operating at 2.4 GHz has been implemented and characterized. We report the power conversion efficiency (PCE) to prove that the modulation does not affect the rectification of IRT. An uplink data rate of 100 kb/s has been demonstrated when the IRT is fed with -20-dBm RF power.","1558-1764","","10.1109/LMWC.2020.3043793","NFSC(grant numbers:62071316); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9305236","Rectifier;transmitter architecture;uplink;wireless power transmission (WPT)","Uplink;Harmonic analysis;Wireless communication;P-i-n diodes;Wireless sensor networks;Radio frequency;Power system harmonics","","8","","22","IEEE","23 Dec 2020","","","IEEE","IEEE Journals"
"Long Live the Image: On Enabling Resilient Production Database Containers for Microservice Applications","Z. Li; N. Saldías-Vallejos; D. Seco; M. A. Rodríguez; R. Ranjan","School of Electronics, Electrical Engineering and Computer Science, Queen’s University Belfast, Belfast, U.K.; Department of Computer Science, University of Concepción, Concepción, Chile; Department of Computer Science and Information Technologies, Universidade de A Coruña, A Coruña, Spain; Department of Computer Science, University of Concepción, Concepción, Chile; School of Computing, Newcastle University, Newcastle upon Tyne, U.K.",IEEE Transactions on Software Engineering,"18 Sep 2024","2024","50","9","2363","2378","Microservices architecture advocates decentralized data ownership for building software systems. Particularly, in the Database per Service pattern, each microservice is supposed to maintain its own database and to handle the data related to its functionality. When implementing microservices in practice, however, there seems to be a paradox: The de facto technology (i.e., containerization) for microservice implementation is claimed to be unsuitable for the microservice component (i.e., database) in production environments, mainly due to the data persistence issues (e.g., dangling volumes) and security concerns. As a result, the existing discussions generally suggest replacing database containers with cloud database services, while leaving the on-premises microservice implementation out of consideration. After identifying three statelessness-dominant application scenarios, we proposed container-native data persistence as a conditional solution to enable resilient database containers in production. In essence, this data persistence solution distinguishes stateless data access (i.e., reading) from stateful data processing (i.e., creating, updating, and deleting), and thus it aims at the development of stateless microservices for suitable applications. In addition to developing our proposal, this research is particularly focused on its validation, via prototyping the solution and evaluating its performance, and via applying this solution to two real-world microservice applications. From the industrial perspective, the validation results have proved the feasibility, usability, and efficiency of fully containerized microservices for production in applicable situations. From the academic perspective, this research has shed light on the operation-side micro-optimization of individual microservices, which fundamentally expands the scope of “software micro-optimization” and reveals new research opportunities.","1939-3520","","10.1109/TSE.2024.3436623","ANID Millennium Science Initiative Program(grant numbers:Code ICN17_002); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10620003","Container;data persistence;read-only database;stateless microservice;microservices architecture","Databases;Containers;Microservice architectures;Production;Usability;Runtime;Prototypes","","","","67","IEEE","1 Aug 2024","","","IEEE","IEEE Journals"
"A Survey to Predict the Trend of AI-able Server Evolution in the Cloud","D. He; Z. Wang; J. Liu","Beijing Key Laboratory of Network System Architecture and Convergence, Beijing University of Posts and Telecommunications, Beijing, China; Office of Educational Information, Beijing University of Posts and Telecommunications, Beijing, China; Beijing Key Laboratory of Network System Architecture and Convergence, Beijing University of Posts and Telecommunications, Beijing, China",IEEE Access,"15 Mar 2018","2018","6","","10591","10602","About a decade ago, people concerned about the risks of adopting cloud computing. It was an unproven new thing that raised more questions than it answered. Nowadays, we hear more about the risks of not adopting the cloud. Three of the leading cloud players, Amazon Web Services, Microsoft Azure, and Google Cloud Platform, and other participants have developed complex cloud platforms that are driving the cloud agenda and launching innovative new products to meet the needs of modern businesses. When looking at processors, core components of the cloud, there is a trend for hyperscale data centers is to move beyond the CPUs and turn to dedicated chips, such as graphics processing units, field programmable gating arrays, and application specific integrated circuits. We think it is an artificial intelligence (AI) realization process and provide a detailed survey about hardware server design in this process. After discussing and summarizing various disclosed techniques and platforms, we conceived a hybrid hardware structure for efficient AI applications.","2169-3536","","10.1109/ACCESS.2018.2801293","National Natural Science Foundation of China(grant numbers:61671078,61701031); Director Funds of Beijing Key Laboratory of Network System Architecture and Convergence(grant numbers:2017BKL-NSAC-ZJ-06); 111 Project of China(grant numbers:B08004,B17007); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8279419","Clouds;server;artificial intelligence","Cloud computing;Hardware;Servers;Graphics processing units;Field programmable gate arrays;Artificial intelligence;Data centers","","19","","51","OAPA","2 Feb 2018","","","IEEE","IEEE Journals"
"Systematic Design of RSA Processors Based on High-Radix Montgomery Multipliers","A. Miyamoto; N. Homma; T. Aoki; A. Satoh","Department of Computer and Mathematical Sciences, Graduate School of Information Sciences, University of Tohoku, Sendai, Japan; Department of Computer and Mathematical Sciences, Graduate School of Information Sciences, University of Tohoku, Sendai, Japan; Department of Computer and Mathematical Sciences, Graduate School of Information Sciences, University of Tohoku, Sendai, Japan; Department of Computer and Mathematical Sciences, Graduate School of Information Sciences, University of Tohoku, Sendai, Japan",IEEE Transactions on Very Large Scale Integration (VLSI) Systems,"23 Jun 2011","2011","19","7","1136","1146","This paper presents a systematic design approach to provide the optimized Rivest-Shamir-Adleman (RSA) processors based on high-radix Montgomery multipliers satisfying various user requirements, such as circuit area, operating time, and resistance against side-channel attacks. In order to involve the tradeoff between the performance and the resistance, we apply four types of exponentiation algorithms: two variants of the binary method with/without Chinese Remainder Theorem (CRT). We also introduces three multiplier-based datapath-architectures using different intermediate data forms: 1) single form, 2) semi carry-save form, and 3) carry-save form, and combined them with a wide variety of arithmetic components. Their radices are parameterized from 28 to 2128. A total of 242 datapaths for 1024-bit RSA processors were obtained for each radix. The potential of the proposed approach is demonstrated through an experimental synthesis of all possible processors with a 90-nm CMOS standard cell library. As a result, the smallest design of 861 gates with 118.47 ms/RSA to the fastest design of 0.67 ms/RSA at 153\thinspace 862 gates were obtained. In addition, the use of the CRT technique reduced the RSA operation time of the fastest design to 0.24 ms. Even if we employed the exponentiation algorithm resistant to typical side-channel attacks, the fastest design can perform the RSA operation in less than 1.0 ms.","1557-9999","","10.1109/TVLSI.2010.2049037","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5497217","Application-specific integrated circuit (ASIC) implementation;high-radix Montgomery multiplication;Rivest–Shamir–Adleman (RSA) cryptosystem","Process design;Cryptography;Computer architecture;Hardware;Design optimization;Circuits;Arithmetic;Cathode ray tubes;CMOS process;Libraries","","65","1","27","IEEE","28 Jun 2010","","","IEEE","IEEE Journals"
"Interdisciplinary Decision Support Dashboard: A New Framework for a Tanzanian Agricultural and Ecosystem Service Monitoring System Pilot","E. H. Fegraus; I. Zaslavsky; T. Whitenack; J. Dempewolf; J. A. Ahumada; K. Lin; S. J. Andelman","Tropical Ecology Assessment and Monitoring Network, Science and Knowledge Division, Conservation International, Arlington, VA, USA; San Diego Supercomputer Center, University of California, San Diego, La Jolla, CA, USA; San Diego Supercomputer Center, University of California, San Diego, La Jolla, CA, USA; Tropical Ecology Assessment and Monitoring Network, Science and Knowledge Division, Conservation International, Arlington, VA, USA; Tropical Ecology Assessment and Monitoring Network, Science and Knowledge Division, Conservation International, Arlington, VA, USA; San Diego Supercomputer Center, University of California, San Diego, La Jolla, CA, USA; Tropical Ecology Assessment and Monitoring Network, Science and Knowledge Division, Conservation International, Arlington, VA, USA",IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing,"28 Dec 2012","2012","5","6","1700","1708","Landscape degradation, soil depletion, scarcity of water and fuel resources are common threats to ecosystem services, agricultural production and human livelihoods in the developing world. Observatory or monitoring networks which focus on the dynamics of coupled human-natural systems are challenged by scarce data, data heterogeneity across multiple domains and spatial scales, and complex models required to produce meaningful sustainability indicators. An additional challenge is to visualize these complex data and indicators in a unified, easily understandable framework. This paper presents an environmental sustainability dashboard that integrates GIS data with household and plot surveys, field data and remote sensing imagery to compute a variety of metrics of ecosystem stress. The dashboard, a web-based decision support tool, is a key cyberinfrastructure component designed to satisfy the objectives of a Tanzanian agricultural and ecosystem services monitoring pilot. Based on this experience we discuss our framework and how it can be generalized for building decision support tools, and their associated cyberinfrastructure, for multi-scale, interdisciplinary monitoring networks.","2151-1535","","10.1109/JSTARS.2012.2204864","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6249772","Africa;agricultural products;agriculture;application software;data visualization;Earth Observing System;information systems;monitoring","Monitoring;Application software;Data visualization;Earth Observing System;Agricultural products;Africa","","20","","54","IEEE","26 Jul 2012","","","IEEE","IEEE Journals"
"Petri Nets-Based Modeling Solution for Cyber–Physical Product Control Considering Scheduling, Deployment, and Data-Driven Monitoring","Z. Liu; L. Hu; W. Hu; J. Tan","State Key Laboratory of CAD&CG, Zhejiang University, Hangzhou, China; State Key Laboratory of CAD&CG, Zhejiang University, Hangzhou, China; State Key Laboratory of CAD&CG, Zhejiang University, Hangzhou, China; State Key Laboratory of CAD&CG, Zhejiang University, Hangzhou, China","IEEE Transactions on Systems, Man, and Cybernetics: Systems","13 Jan 2023","2023","53","2","990","1002","For a complex electromechanical product that is a cyber–physical system (CPS), its dynamic behaviors are embodied in the closed-loop control between the logic process in its cyber component and actual actuators/sensors in its physical component, and thus, a well-defined model of the control is important to create a digital twin that acts as much like the real machine as possible. This article proposes a Petri nets (PNs)-based modeling solution that employs hybrid PNs (HPNs) for physics and system of sequential systems with shared resources (S4R) nets for logic in building a hierarchical control model. We also present PNs technologies for implementing a smooth transition and bidirectional mapping from the virtual prototype to the real machine. These technologies involve a PNs integration of a reinforcement learning (RL) method for generating a workflow scheduling agent in design, an extension of PNs definitions that is compatible with the microcontroller for easy deployment in manufacturing, and an architecture of PNs execution recording for data-driven monitoring in service. A software kit is provided for the solution that includes an integrated development environment of PNs, tools for quickly building a virtual prototype, and a monitor server for remote data-driven monitoring. This solution is successfully applied in the development of a typical cyber–physical product case, namely, the chemiluminescence immunoassay (CLIA) analyzer.","2168-2232","","10.1109/TSMC.2022.3170489","National Natural Science Foundation of China(grant numbers:51935009,52075480); Key Research and Development Program of Zhejiang Province(grant numbers:2021C01008); High-Level Talent Special Support Plan of Zhejiang Province(grant numbers:2020R52004); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9844011","Cyber–physical systems (CPSs);data-driven monitoring;digital twin;Petri nets (PNs);process control;scheduling","Solid modeling;Monitoring;Analytical models;Mathematical models;Data models;Process control;Job shop scheduling","","6","","50","IEEE","28 Jul 2022","","","IEEE","IEEE Journals"
"A 32 Terabit/s Data Acquisition from Mostly COTS Components","R. Schwemmer; N. Neufeld","CERN, PH Department, Geneva, Switzerland; CERN, PH Department, Geneva, Switzerland",IEEE Transactions on Nuclear Science,"14 Aug 2015","2015","62","4","1747","1751","The Large Hadron Collider beauty (LHCb) data acquisition after 2019 will need to perform event-building at an aggregated band-width of 32 Tbit/s. Apart from the technological challenges described in various papers also at this conference, the key challenge is to come up with an architecture which minimises the cost, while providing a system which can be maintained by a small team for a long time and which scales well. In this paper we present the analyses we have been doing to minimise the cost, the R&D topics we derived from that and how we combined all this into a coherent proposal which allows us to come up with a system which not only today fits the budgetary constraints of LHCb, but also will allow profiting from any main-stream technological development. We achieve this by aligning our system needs as much as possible to data-centre mass-market commercial of the shelf (COTS) products; by minimising the number of optical interconnects and by optimising the physical layout of the system. This system requires only one piece of custom-made hardware, and even this could, for a smaller setup be replaced by a commercially available item. We believe that the reasoning behind this design can be beneficial to any large, high-rate data acquisition system.","1558-1578","","10.1109/TNS.2015.2435902","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7153573","Data acquisition;multiprocessor interconnection networks;network topology;next generation networking;real-time systems","Servers;Buildings;Data acquisition;Field programmable gate arrays;Detectors;Bandwidth;Hardware","","3","","13","CCBY","9 Jul 2015","","","IEEE","IEEE Journals"
"Representation Learning With Dual Autoencoder for Multi-Label Classification","Y. Zhu; Y. Yang; Y. Li; J. Qiang; Y. Yuan; R. Zhang","School of Information Engineering, Yangzhou University, Yangzhou, Jiangsu, China; School of Information Engineering, Yangzhou University, Yangzhou, Jiangsu, China; School of Information Engineering, Yangzhou University, Yangzhou, Jiangsu, China; School of Information Engineering, Yangzhou University, Yangzhou, Jiangsu, China; School of Information Engineering, Yangzhou University, Yangzhou, Jiangsu, China; School of Electronics and Information Engineering, Anhui Jianzhu University, Hefei, China",IEEE Access,"19 Jul 2021","2021","9","","98939","98947","Multi-label classification aims to deal with the problem that an object may be associated with one or more labels, which is a more difficult task due to the complex nature of multi-label data. The crucial problem of multi-label classification is the more robust and higher-level feature representation learning, which can reduce non-helpful feature attributes from the input space prior to training. In recent years, deep learning methods based on autoencoders have achieved excellent performance in multi-label classification for the advantages of powerful representations learning ability and fast convergence speed. However, most existing autoencoder-based methods only rely on the single autoencoder model, which pose challenges for multi-label feature representations learning and fail to measure similarities between data spaces. To address this problem, in this paper, we propose a novel representation learning method with dual autoencoder for multi-label classification. Compared to the existing autoencoder-based methods, our proposed method can capture different characteristics and more abstract features from data by the serially connection of two different types of autoencoders. More specifically, firstly, the algorithm of Reconstruction Independent Component Analysis (RICA) in sparse autoencoder is trained on patches on all training and test dataset for robust global feature representations learning. Secondly, with the output of RICA, stacked autoencoder with manifold regularization (SAMR) is introduced to ameliorate the quality of multi-label features learning. Comprehensive experiments on several real-world data sets demonstrate the effectiveness of our proposed approach compared with several competing state-of-the-art methods.","2169-3536","","10.1109/ACCESS.2021.3096194","National Natural Science Foundation of China(grant numbers:61906060); Open Project Program of Key Laboratory of Huizhou Architecture in Anhui Province(grant numbers:HPJZ-2020-02); Open Project Program of Joint International Research Laboratory of Agriculture and Agri-Product Safety, the Ministry of Education of China, Yangzhou University(grant numbers:JILAR-KF202104); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9481139","Multi-label classification;dual autoencoder;RICA;manifold regularization;representation learning","Training;Manifolds;Independent component analysis;Data models;Correlation;Linear programming","","3","","46","CCBY","12 Jul 2021","","","IEEE","IEEE Journals"
"Optimizing Design Structure Matrices Using Markov Chain Modeling and Community Detection","R. A. Khatib; A. Chacon","Product Development—Vehicle Systems Engineering Division, Ford Motor Company, Dearborn, MI, USA; Product Development—Vehicle Systems Engineering Division, Ford Motor Company, Dearborn, MI, USA",IEEE Open Journal of Systems Engineering,"19 Sep 2024","2024","2","","148","156","This article proposes a new method to enhance the efficiency of the design process in systems engineering. Our approach involves utilizing a Markov chain based on the design structure matrix (DSM). By creating a transformation matrix using the DSM and converting it into a Markov chain, we enable faster convergence of process iterations and improved decoupling between modules or clusters. The Markov chain is plotted as a tree using a layered layout algorithm and partitioned into communities using the Louvain algorithm. We applied our method to two types of DSM data, i.e., component-based and parameter-based, and the results showed valuable insights into the design process. Our approach is a valuable tool for managing complex systems, especially as systems become increasingly complex and challenging for engineers to manage during the design process.","2771-9987","","10.1109/OJSE.2024.3431468","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10605078","Community detection;complex systems;design structure matrices (DSMs);Markov chain modeling;system architecture design;system design optimization","Clustering algorithms;Complexity theory;Modeling;Heuristic algorithms;Systems architecture;Aircraft;Task analysis","","","","15","CCBY","19 Jul 2024","","","IEEE","IEEE Journals"
"Design of Power Efficient Posit Multiplier","H. Zhang; S. -B. Ko","Department of Electrical and Computer Engineering, University of Saskatchewan, Saskatoon, Canada; Department of Electrical and Computer Engineering, University of Saskatchewan, Saskatoon, Canada",IEEE Transactions on Circuits and Systems II: Express Briefs,"30 Apr 2020","2020","67","5","861","865","Posit number system has been used as an alternative to IEEE floating-point number system in many applications, especially the recent popular deep learning. Its non-uniformed number distribution fits well with the data distribution of deep learning and thus can speedup the training process of deep learning. Among all the related arithmetic operations, multiplication is one of the most frequent operations used in applications. However, due to the bit-width flexibility nature of posit numbers, the hardware multiplier is usually designed with the maximum possible mantissa bit-width. As the mantissa bit-width is not always the maximum value, such multiplier design leads to a high power consumption especially when the mantissa bit-width is small. In this brief, a power efficient posit multiplier architecture is proposed. The mantissa multiplier is still designed for the maximum possible bit-width, however, the whole multiplier is divided into multiple smaller multipliers. Only the required small multipliers are enabled at run-time. Those smaller multipliers are controlled by the regime bit-width which can be used to determine the mantissa bit-width. This design technique is applied to 8-bit, 16-bit, and 32-bit posit formats in this brief and an average of 16% power reduction can be achieved with negligible area and timing overhead.","1558-3791","","10.1109/TCSII.2020.2980531","Natural Sciences and Engineering Research Council of Canada; Research and Development Program of MOTIE/KEIT (Developing Processor-Memory-Storage Integrated Architecture for Low Power, High Performance Big Data Servers)(grant numbers:10077609); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9035440","Posit number system;posit multiplier;computer arithmetic;low-power arithmetic circuit","Deep learning;Adders;Hardware;Standards;Power demand;Computer architecture;Generators","","31","","12","IEEE","13 Mar 2020","","","IEEE","IEEE Journals"
"Product Interface Design for Complexity Management in Assembly Systems","K. Oh; H. W. Kim; D. Kim; J. Lee; J. Lee; Y. S. Hong","Department of Industrial Engineering, Seoul National University, Seoul, South Korea; Manufacturing Innovation Center, Production Engineering Research Institute, LG Electronics, Pyeongteak, South Korea; Department of Industrial Engineering, Seoul National University, Seoul, South Korea; Department of Systems Management and Engineering, Pukyong National University, Busan, South Korea; Department of Industrial Engineering, Seoul National University, Seoul, South Korea; Department of Industrial Engineering, Seoul National University, Seoul, South Korea",IEEE Access,"24 Dec 2020","2020","8","","225491","225506","Manufacturing firms are facing the challenge of minimizing variety-induced complexity in assembly systems. One of the effective approaches to complexity management is to reconfigure the assembly system by rearranging its assembly sequence. In order to rearrange an assembly sequence, a design-oriented approach is necessary because assembly is an activity of connecting parts through an interface between them. It means that the assembly sequence in production is restricted by the structure of interface connections in design. In this vein, this paper introduces a new design-oriented approach called interface design approach to complexity management in assembly systems. First, the mechanism of how the structure of interface connections affects assembly system complexity is identified. Then, an interface design framework is proposed for effectively finding an optimal interface structure and its assembly sequence to minimize assembly system complexity. For evaluating the complexity, the operator choice complexity index is adopted and modified for the interface design problem. In the case study, the framework is applied to the interface design problem by using industrial data of a plasma display panel (PDP) family from LG Electronics. The result of the study demonstrates that the assembly system complexity is significantly reduced by the proposed interface design framework.","2169-3536","","10.1109/ACCESS.2020.3045041","National Research Foundation of Korea (NRF); Ministry of Science and ICT (MSIT), Korea Government(grant numbers:NRF-2017R1E1A1A03070846); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9294058","Assembly system complexity;complexity management;design for assembly;interface design;mixed-model assembly line;product architecture","Complexity theory;Assembly systems;Production;Indexes;Task analysis;Manuals;Uncertainty","","2","","44","CCBY","15 Dec 2020","","","IEEE","IEEE Journals"
"Production as a Service: A Digital Manufacturing Framework for Optimizing Utilization","E. C. Balta; Y. Lin; K. Barton; D. M. Tilbury; Z. M. Mao","Department of Mechanical Engineering, University of Michigan, Ann Arbor, MI, USA; Department of Electrical Engineering and Computer Science, University of Michigan, Ann Arbor, MI, USA; Department of Mechanical Engineering, University of Michigan, Ann Arbor, MI, USA; Department of Mechanical Engineering, University of Michigan, Ann Arbor, MI, USA; Department of Electrical Engineering and Computer Science, University of Michigan, Ann Arbor, MI, USA",IEEE Transactions on Automation Science and Engineering,"4 Oct 2018","2018","15","4","1483","1493","In current practice, product developers with customized small batch production needs come across the problem of finding capable and flexible manufacturers, whereas manufacturers face underutilization due to inconsistent demand. This paper presents a Production as a Service (PaaS) framework to connect users (consumers or product developers) who have customized small batch manufacturing needs with manufacturers who have existing underutilized resources. PaaS is a cloud-based, centralized framework based on a service-oriented architecture that abstracts the manufacturing steps of a product as individual (production) service requests. Using PaaS, the user is able to reach many capable manufacturers at once and receive quotations for the production request. On the other end, PaaS reduces the effort required to find new customers and enables the manufacturers to easily submit quotations to increase the utilization of their resources. The functionalities and concepts defined in this paper are illustrated through case studies. Note to Practitioners-In order to transition product fabrication from the design phase to manufacturing, there is a need for identifying capable manufacturers with available resources that could be paired with user requirements. We propose Production as a Service (PaaS) in this paper and present initial implementations of the front-end and back-end components with a customizable optimization algorithm. Proposed abstractions and data structures make PaaS a unique, efficient, and intellectual property preserving framework. The current implementation of the framework has been tested with new designs. The PaaS framework has the potential to scale over a large network of manufacturers to effectively coordinate geo-distributed manufacturers for custom manufacturing needs.","1558-3783","","10.1109/TASE.2018.2842690","National Science Foundation(grant numbers:1546036); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8398543","Genetic algorithms;intellectual property;intelligent manufacturing systems;manufacturing automation;service-oriented systems engineering","Intelligent manufacturing systems;Optimization;Genetic algorithms;Feature extraction;Service-oriented architecture;Intellectual property;Manufacturing automation","","38","","34","IEEE","27 Jun 2018","","","IEEE","IEEE Journals"
"Optimized Block-Based Connected Components Labeling With Decision Trees","C. Grana; D. Borghesani; R. Cucchiara","Dipartimento di Ingegneria dell'Informazione, Università degli Studi di Modena e Reggio Emilia, Emilia, Italy; Dipartimento di Ingegneria dell'Informazione, Università degli Studi di Modena e Reggio Emilia, Emilia, Italy; Dipartimento di Ingegneria dell'Informazione, Università degli Studi di Modena e Reggio Emilia, Emilia, Italy",IEEE Transactions on Image Processing,"13 May 2010","2010","19","6","1596","1609","In this paper, we define a new paradigm for eight-connection labeling, which employes a general approach to improve neighborhood exploration and minimizes the number of memory accesses. First, we exploit and extend the decision table formalism introducing or-decision tables, in which multiple alternative actions are managed. An automatic procedure to synthesize the optimal decision tree from the decision table is used, providing the most effective conditions evaluation order. Second, we propose a new scanning technique that moves on a 2 × 2 pixel grid over the image, which is optimized by the automatically generated decision tree. An extensive comparison with the state of art approaches is proposed, both on synthetic and real datasets. The synthetic dataset is composed of different sizes and densities random images, while the real datasets are an artistic image analysis dataset, a document analysis dataset for text detection and recognition, and finally a standard resolution dataset for picture segmentation tasks. The algorithm provides an impressive speedup over the state of the art algorithms.","1941-0042","","10.1109/TIP.2010.2044963","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5428863","Connected components labeling;decision tables;decision trees;optimization methods","Labeling;Decision trees;Image analysis;Pixel;Mesh generation;Art;Text analysis;Data analysis;Image recognition;Text recognition","Algorithms;Decision Support Techniques;Image Enhancement;Image Interpretation, Computer-Assisted;Pattern Recognition, Automated;Product Labeling;Reproducibility of Results;Sensitivity and Specificity","140","","31","IEEE","11 Mar 2010","","","IEEE","IEEE Journals"
"A Methodology for Digital Twin Modeling and Deployment for Industry 4.0","G. N. Schroeder; C. Steinmetz; R. N. Rodrigues; R. V. B. Henriques; A. Rettberg; C. E. Pereira","Department of Electrical Engineering, Federal University of Rio Grande do Sul, Porto Alegre, Brazil; Department Lippstadt 2-Computer Science, Hamm-Lippstadt University of Applied Sciences, Lippstadt, Germany; Center for Computational Sciences, Universidade Federal do Rio Grande, Rio Grande, Brazil; Department of Electrical Engineering, Federal University of Rio Grande do Sul, Porto Alegre, Brazil; Department Lippstadt 2-Computer Science, Hamm-Lippstadt University of Applied Sciences, Lippstadt, Germany; Department of Electrical Engineering, Federal University of Rio Grande do Sul, Porto Alegre, Brazil",Proceedings of the IEEE,"23 Mar 2021","2021","109","4","556","567","The digital twin (DT) is a virtual representation of a physical object, which has been proposed as one of the key concepts for Industry 4.0. The DT provides a virtual representation of products along their lifecycle that enables the prediction and optimization of the behavior of a production system and its components. A methodology design using model-driven engineering (MDE) is proposed that strives toward being both flexible and generic. This approach is presented at two levels: first, a DT is modeled as a composition of basic components that provide basic functionalities, such as identification, storage, communication, security, data management, human-machine interface (HMI), and simulation; second, an aggregated DT is defined as a hierarchical composition of other DTs. A generic reference architecture based on these concepts and a concrete implementation methodology are proposed using AutomationML. This methodology follows an MDE approach that supports most of the DT features currently proposed in the literature. A case study has been developed, the proposed ideas are being evaluated with industrial case studies, and some of the preliminary results are described in this article. With the case study, it is possible to verify that the proposed methodology supports the creation and the deployment process of a DT.","1558-2256","","10.1109/JPROC.2020.3032444","Coordenação de Aperfeiçoamento de Pessoal de Nível Superior(grant numbers:10.13039/501100002322); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9247401","AutomationML;cyber–physical systems (CPSs);digital twin (DT);Industry 4.0 (I4.0)","Data models;Computer architecture;Unified modeling language;Digital twin;Solid modeling;Industries;Context modeling;Cyber-physical systems;Fourth Industrial Revolution","","106","","49","IEEE","3 Nov 2020","","","IEEE","IEEE Journals"
"A Low-Cost Defect Segmentation System Based on IoT for Large-Scale Photovoltaic Manufacturing","C. Wang; H. Chen; S. Zhao; Y. Wang; Z. Cao","School of Artificial Intelligence and Data Science, Hebei University of Technology, Tianjin, China; School of Artificial Intelligence and Data Science, Hebei University of Technology, Tianjin, China; School of Artificial Intelligence and Data Science, Hebei University of Technology, Tianjin, China; School of Artificial Intelligence and Data Science, Hebei University of Technology, Tianjin, China; School of Artificial Intelligence and Data Science, Hebei University of Technology, Tianjin, China",IEEE Internet of Things Journal,"25 Apr 2024","2024","11","9","16928","16940","The photovoltaic industry is a strategic industry with international competitive advantages and is developing toward a larger scale, higher efficiency, and higher quality. However, current researchers have not built a pixel-level defect inspection system for large-scale photovoltaic production processes. This article proposes an intelligent defect segmentation system combining the Internet of Things (IoT), artificial intelligence (AI), and edge computing for quality inspection of large-scale photovoltaic production lines. The intelligent factory based on this system is highly intelligent and deeply integrated, which can significantly reduce labor costs and improve factory productivity and product quality. The system’s core uses edge computing to segment cells in real-time by a lightweight defect segmentation model. Specifically, this article proposes a lightweight yet effective architecture named low-cost defect segmentation network (LDSN). An efficient split (ES) block is designed to support more channels and improve model accuracy without adding much computational complexity. Moreover, the ES block can express multiscale features in a finer granularity and enhance the information interaction between grouping features. In the decoding structure, a dual focus attention (DFA) that efficiently captures long-range spatial and channel information is proposed. Comprehensive experiments have been performed on a low-end PC with an NVIDIA GeForce RTX3060 GPU and an Intel Core i5-10600KF. LDSN-T-Lite achieves 84FPS and the F-measure optimal image scale (OIS) of 0.827, which only has 166K parameters and 395.6M memory usage on our PSCDE data set. A bigger version of LDSN-B achieves the F-measure OIS of 0.872, significantly outperforming current methods.","2327-4662","","10.1109/JIOT.2024.3366945","National Natural Science Foundation of China(grant numbers:U21A20482,62073117,62173124); National Key Research and Development Program of China(grant numbers:2022YFB3303800); Natural Science Foundation of Hebei Province(grant numbers:F2022202064); Central Government Guides Local Science, Technology Development Fund Projects(grant numbers:206Z1701G); Interdisciplinary Postgraduate Training Program of Hebei University of Technology(grant numbers:HEBUT-Y-XKJC-2023001,2022101); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10439979","Artificial intelligence (AI);efficient defect segmentation model;Internet of Things (IoT);large-Scale photovoltaic manufacturing","Production;Solar power generation;Photovoltaic systems;Image edge detection;Computational modeling;Edge computing;Photovoltaic cells","","2","","43","IEEE","19 Feb 2024","","","IEEE","IEEE Journals"
"AIM: Automatic Interaction Machine for Click-Through Rate Prediction","C. Zhu; B. Chen; W. Zhang; J. Lai; R. Tang; X. He; Z. Li; Y. Yu","Shanghai Jiao Tong University, Shanghai, China; Huawei Noah's Ark Lab, Shenzhen, Guangdong, China; Shanghai Jiao Tong University, Shanghai, China; Huawei Noah's Ark Lab, Shenzhen, Guangdong, China; Huawei Noah's Ark Lab, Shenzhen, Guangdong, China; Huawei Noah's Ark Lab, Shenzhen, Guangdong, China; Huawei Noah's Ark Lab, Shenzhen, Guangdong, China; Shanghai Jiao Tong University, Shanghai, China",IEEE Transactions on Knowledge and Data Engineering,"7 Mar 2023","2023","35","4","3389","3403","Feature embedding learning and feature interaction modeling are two crucial components of deep models for Click-Through Rate (CTR) prediction in recommender systems. Most existing deep CTR models suffer from the following three problems. First, feature interactions are either manually designed or simply enumerated. However, not all the feature interactions are useful for the prediction task and useless feature interactions may introduce noisy signals thus causing overfitting. Second, all the feature interactions are modeled with an identical interaction function, whereas different interaction functions introduce different inductive biases to better capture various feature interaction patterns. Third, in most existing models, different features share the same embedding size. However, model size can be further optimized without sacrificing performance by differentiating embedding sizes for individual features, as the amount of information contained in each feature varies much. To address the three issues mentioned above, we propose Automatic Interaction Machine (AIM) with three core components, namely, Feature Interaction Search (FIS), Interaction Function Search (IFS) and Embedding Dimension Search (EDS), respectively. To tackle the first problem, FIS component automatically identifies different orders of essential feature interactions with useless ones pruned. Taking care of the second problem, IFS component selects appropriate interaction functions for each individual feature interaction in a learnable way. Moreover, to avoid learning conflict among different interaction functions, IFS proposes function-wise embeddings via performing multiple embeddings for each feature, where each feature embedding corresponds to one possible interaction function. However, utilizing multiple embeddings for each feature may make the model size affordably large if we keep the same embedding size as utilizing shared embedding (i.e., each feature shares the same embedding for different interaction functions). To solve this third problem, EDS automatically selects proper embedding size for each feature. Such a flexible embedding size adaptation is able to reduce the large amount of embedding parameters introduced by function-wise embeddings. Offline experiments on three large-scale datasets (two public benchmarks, one private dataset) validate that AIM can significantly improve various FM-based models. AIM has been deployed in the recommendation service of a mainstream app market, where a three-week online A/B test demonstrated the superiority of AIM, improving DeepFM model by 4.4% in terms of CTR.","1558-2191","","10.1109/TKDE.2021.3134985","New Generation of AI 2030(grant numbers:2018AAA0100900); Shanghai Municipal Science and Technology Major Project(grant numbers:2021SHZDZX0102); National Natural Science Foundation of China(grant numbers:62076161,62177033); Huawei Innovation Research Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9650594","CTR prediction;feature interaction;neural architecture search;factorization machine;recommender systems","Predictive models;Logic gates;Frequency modulation;Feature extraction;Deep learning;Data models;Costs","","3","","38","IEEE","14 Dec 2021","","","IEEE","IEEE Journals"
"Artificial Learning for Part Identification in Robotic Disassembly Through Automatic Rule Generation in an Ontology","G. Foo; S. Kara; M. Pagnucco","Sustainable Manufacturing and Life Cycle Engineering Research Group, School of Mechanical and Manufacturing Engineering, University of New South Wales, Sydney, NSW, Australia; Sustainable Manufacturing and Life Cycle Engineering Research Group, School of Mechanical and Manufacturing Engineering, University of New South Wales, Sydney, NSW, Australia; School of Computer Science and Engineering, University of New South Wales, Sydney, NSW, Australia",IEEE Transactions on Automation Science and Engineering,"5 Jan 2023","2023","20","1","296","309","With the increasing concern for sustainable treatment of waste electrical and electronic equipment (WEEE), methods of robotic disassembly of WEEE to address various challenges of handling end-of-life products has been a trend in research. The main challenge for robotic disassembly is the uncertainties of product structures, models, and conditions. The ability of a robotic disassembly system to learn new product structures and reason about existing knowledge of product structure is vital to addressing this challenge. This paper presents an effective learning framework and demonstrates the system’s ability to learn relevant information for the disassembly of LCD monitors. The learning algorithm uses a database of previous disassembly experience of the product family and analyses it to create rules and relations between the components and disassembly concepts before expanding the generic ontology for future disassembly runs. The results show a significant increase from 11% to 87% in successful part identification of LCD monitors after being trained on past disassembly experience. The proposed method can greatly aid robotic disassembly of any product family. Note to Practitioners—Robotic systems struggle to disassemble electronic waste due to the complexity and uncertainties in end-of-life products and variations in models and parts. An artificially intelligent method is proposed to enable a robotic disassembly system to address these uncertainties. The method uses a computing technique resembling the cognitive reasoning of a human mind in the form of a map of disassembly concepts connected by relationships. Artificial learning by the robotic system occurs by collecting data from previous disassembly runs of a product, analyzing the data, and expanding the map of knowledge with new concepts and relational rules found. The approach is tested on the robotic disassembly system’s ability to identify parts of LCD monitors which possess uncertainties. An improvement from 11% of successful part identification to 87% is found, which demonstrate that learning has taken place. This approach will be implemented in a larger robotic disassembly system and tested with real robotic disassembly runs in the near future.","1558-3783","","10.1109/TASE.2022.3149242","Australian Government Research Training Program Scholarship; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9708413","AI-based methods;disassembly;learning from demonstration;robotics in hazardous fields","Robots;Uncertainty;Ontologies;Electronic waste;Cognition;Monitoring;Liquid crystal displays","","7","","49","IEEE","9 Feb 2022","","","IEEE","IEEE Journals"
"Digital Twinning From Vehicle Usage Statistics for Customer-Centric Automotive Systems Engineering","K. Ling","Ingolstadt School of Management, Catholic University of Eichstätt-Ingolstadt, Ingolstadt, Germany",IEEE Open Journal of Intelligent Transportation Systems,"21 Dec 2023","2023","4","","966","978","Towards customer-centric automotive systems engineering, it is essential to incorporate physical models and vehicle usage behavior into decision support systems (DSSs). Such DSSs tend to apply digital twin concepts, where simulations are parameterized with fine-grained time-series data acquired from customer fleets. However, logging vast amounts of data from customer fleets is costly and raises privacy concerns. Alternatively, these time-series data can be aggregated into vehicle usage statistics. The feasibility of creating digital twins from these vehicle usage statistics and the corresponding DSSs for systems engineering is yet to be established. This paper aims to demonstrate this feasibility by proposing a DSS framework that integrates four key elements of digital twinning: aggregate usage statistics from customer fleets, logging data from testing fleets, physical models for vehicle simulation, and evaluation models to derive decision support metrics. The digital twinning involves a four-step process: pre-processing, profiling, simulation, and post-processing. Based on a real-world fleet of 57110 vehicles and four evaluation metrics, a proof of concept is conducted. Results show that the digital twin covers the evaluation metrics of 99% of the vehicles and reaches an average fleet twinning accuracy of 91.09%, which indicates the feasibility and plausibility of the proposed DSS framework.","2687-7813","","10.1109/OJITS.2023.3339430","Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) within the “Open Access Publication Funding” Program(grant numbers:512640851); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10342795","Customer centricity;decision support system;digital twin;fleet data;systems engineering","Digital twins;Modeling;Decision support systems;Data models;Automotive engineering;Spread spectrum communication;Systems engineering and theory","","1","","52","CCBY","5 Dec 2023","","","IEEE","IEEE Journals"
"HEPCloud: An FPGA-Based Multicore Processor for FV Somewhat Homomorphic Function Evaluation","S. Sinha Roy; K. Järvinen; J. Vliegen; F. Vercauteren; I. Verbauwhede","KU Leuven ESAT/COSIC and IMEC, Kasteelpark Arenberg 10, Leuven-Heverlee, Belgium; Department of Computer Science, University of Helsinki, Gustaf Hällströmin katu 2b, Helsinki, Finland; KU Leuven ESAT/COSIC and IMEC, Kasteelpark Arenberg 10, Leuven-Heverlee, Belgium; KU Leuven ESAT/COSIC and IMEC, Kasteelpark Arenberg 10, Leuven-Heverlee, Belgium; KU Leuven ESAT/COSIC and IMEC, Kasteelpark Arenberg 10, Leuven-Heverlee, Belgium",IEEE Transactions on Computers,"7 Oct 2018","2018","67","11","1637","1650","In this paper, we present an FPGA based hardware accelerator ‘ $\mathsf{HEPCloud}$ ’ for homomorphic evaluations of medium depth functions which has applications in cloud computing. Our $\mathsf{HEPCloud}$  architecture supports the polynomial ring based homomorphic encryption scheme FV for a ring-LWE parameter set of dimension  $2^{15}$ , modulus size 1,228-bit, and a standard deviation 50. This parameter-set offers a multiplicative depth 36 and at least 85 bit security. The processor of  $\mathsf{HEPCloud}$  is composed of multiple parallel cores. To achieve fast computation time for such a large parameter-set, various optimizations in both algorithm and architecture levels are performed. For fast polynomial multiplications, we use CRT with NTT and achieve two dimensional parallelism in  $\mathsf{HEPCloud}$ . We optimize the BRAM access, use a fast Barrett like polynomial reduction method, optimize the cost of CRT, and design a fast divide-and-round unit. Beside parallel processing, we apply pipelining strategy in several of the sequential building blocks to reduce the impact of sequential computations. Finally, we implement  $\mathsf{HEPCloud}$  on a medium-size Xilinx Virtex 6 FPGA board ML605 board and measure its on-board performance. To store the ciphertexts during a homomorphic function evaluation, we use the large DDR3 memory of the ML605 board. Our FPGA-based implementation of $\mathsf{HEPCloud}$  computes a homomorphic multiplication in 26.67 s, of which the actual computation takes only 3.36 s and the rest is spent for off-chip memory access. It requires about 37,551 s to evaluate the SIMON-64/128 block cipher, but the per-block timing is only about 18 s because $\mathsf{HEPCloud}$  processes 2,048 blocks simultaneously. The results show that FPGA-based acceleration of homomorphic function evaluations is feasible, but fast memory interface is crucial for the performance.","1557-9956","","10.1109/TC.2018.2816640","Research Council KU Leuven(grant numbers:C16/15/058); Flemish Government; Hercules Foundation(grant numbers:AKUL/11/19); European Commission; ICT Programme; Horizon 2020 Research and Innovation Programme(grant numbers:H2020-ICT-2014-644371); WITDOM(grant numbers:H2020-ICT-2014-644209 HEAT,H2020-ICT-2014-645622 PQCRYPTO); Cathedral ERC Advanced(grant numbers:695305); Academy of Finland(grant numbers:283250,303578); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8318681","Homomorphic encryption;FV;lattice-based cryptography;ring-LWE;polynomial multiplication;number theoretic transform;hardware implementation","Hardware;Encryption;Computer architecture;Cloud computing;Acceleration","","45","","41","IEEE","16 Mar 2018","","","IEEE","IEEE Journals"
"Improvement of Collaborative Filtering Recommendation Algorithm Based on Intuitionistic Fuzzy Reasoning Under Missing Data","Y. Zhang; Y. Wang; S. Wang","School of Business Administration, Liaoning Technical University, Huludao, China; School of Business Administration, Liaoning Technical University, Huludao, China; School of Business Administration, Liaoning Technical University, Huludao, China",IEEE Access,"19 Mar 2020","2020","8","","51324","51332","Commodity recommendation plays an essential role in the marketing field in the Internet era, and collaborative filtering, as a powerful technique of commodity recommendation, has been widely concerned in both academic studies and practical applications. Existing research on collaborative filtering often uses methods such as genetic algorithm and neural network to solve the sparsity and cold start problems while ignoring the fuzziness of users' ratings on goods or services. To solve the problems, we propose a recommendation algorithm (IFR-CF) based on intuitionistic fuzzy reasoning and collaborative filtering. In this algorithm, the characteristic coefficient in intuitionistic fuzzy reasoning is used to replace the traditional similarity coefficient to determine neighbor set, and the finite prior ordering method is used to replace traditional algorithm to recommend commodity. Two groups of data are extracted from Movielens and Jester datasets for experiments, and the MAE value generated by the recommended items is taken as the metric to verify the algorithm performance. Experimental results show that compared with the traditional algorithms, our algorithm achieves lower MAE value and higher recommendation accuracy. Meanwhile, the intuitionistic index of fuzzy set is taken into account in the calculation of the hesitation coefficient, which provides a novel solution to the problem of missing scoring data of users.","2169-3536","","10.1109/ACCESS.2020.2980624","Provincial Department of Education Project of Liaoning (Organization Optimization of Urban Space System Based on Check-in Data of Residents Mobile Network), China(grant numbers:LJ2017QW010); Provincial Social Science Planning Fund of Liaoning (Research on Urban Space-time Elasticity Based on Data Signed by Resident Mobile Network), China(grant numbers:L18CJY003); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9035509","Collaborative filtering;intuitionistic fuzzy reasoning;intuitive index;similarity","Fuzzy reasoning;Collaboration;Fuzzy sets;Prediction algorithms;Clustering algorithms;Cognition","","11","","27","CCBY","13 Mar 2020","","","IEEE","IEEE Journals"
"A Novel Approach to Address Random Hardware Failures for Automotive Application Within the ISO26262 and AUTOSAR Frameworks","J. Sini; K. Scialabba; M. Violante; F. Cosimi; A. Arena","Department of Control and Computer Engineering, Politecnico di Torino, Turin, Italy; Department of Control and Computer Engineering, Politecnico di Torino, Turin, Italy; Department of Control and Computer Engineering, Politecnico di Torino, Turin, Italy; Evidence SRL, Pisa, Italy; Evidence SRL, Pisa, Italy",IEEE Access,"13 Nov 2024","2024","12","","165845","165860","The current trends of the automotive industry, namely Automation, Connection, and Electrification, place novel challenges in product development. In particular, the industry needs to increase vehicle computational power availability, trying to keep the same costs as in the past. Of course, since automotive applications can affect people’s safety, there is also the need to keep the same reliability levels with fewer hardware components to limit costs. Another advantage is that considering the usage of Commercial-Off-The-Shelf chiplets featuring multiple cores with diverse levels of integrities, it allows the use of lower-integrity ones, increasing the overall computation capabilities for a given component. This paper proposes a novel approach based on Software-Implemented Hardware Fault Tolerance, such as Control Flow Checking and Data Hardening, to move forward in this direction, addressing mixed-criticality multi-core systems. The main focus is exploiting the computational power of lower-integrity cores or hardware accelerators to execute safety-critical tasks without increasing the risk level. The effectiveness of the proposed approach has been demonstrated by fault injection campaigns on a real, yet simplified, AUTOSAR-compliant automotive application. Considering the Control Flow Checking Algorithms, the approach moved the DC from around 10% (without multi-core timeout detection strategy) up to around 45% (with timeout detection). For the hybrid data hardening, the approach Diagnostic Coverage is around 15% for integer and floating point values. The absence of residual faults shows that the proposed solution can complement other functional safety strategies, even if insufficient to guarantee the metrics for an ASIL D application.","2169-3536","","10.1109/ACCESS.2024.3488897","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10740288","Hardening techniques;fault tolerance","Hardware;Safety;Automotive engineering;Monitoring;Costs;Industries;Fault tolerant systems;Computer architecture;Automotive applications","","","","18","CCBYNCND","31 Oct 2024","","","IEEE","IEEE Journals"
"Detection of Manufacturing Defects in Steel Using Deep Learning With Explainable Artificial Intelligence","Z. Aboulhosn; A. Musamih; K. Salah; R. Jayaraman; M. Omar; Z. Aung","Department of Computer Science, Khalifa University of Science and Technology, Abu Dhabi, United Arab Emirates; Department of Management Science and Engineering, Khalifa University of Science and Technology, Abu Dhabi, United Arab Emirates; Department of Computer and Communication Engineering, Khalifa University of Science and Technology, Abu Dhabi, United Arab Emirates; Department of Management Science and Engineering, Khalifa University of Science and Technology, Abu Dhabi, United Arab Emirates; Department of Management Science and Engineering, Khalifa University of Science and Technology, Abu Dhabi, United Arab Emirates; Department of Computer Science, Khalifa University of Science and Technology, Abu Dhabi, United Arab Emirates",IEEE Access,"24 Jul 2024","2024","12","","99240","99257","Guaranteeing steel quality is a crucial step in the steel manufacturing process. Many manufacturing industries still resort to manual visual inspection, which is inefficient and time-consuming. Industries have not fully adopted automated visual inspection due to inaccuracies, the variability of real-world manufacturing environments, and a lack of familiarity with the decisions output by the automated technology. Nonetheless, the implementation of automated defect detection systems can substantially enhance the quality of the end product. In particular, Convolutional Neural Networks (CNNs) have demonstrated exceptional abilities in image classification and segmentation tasks. There is still significant room for improvement in terms of the detection and localization accuracy, the robustness of the algorithms, and their practicality of use. This paper employs and evaluates different semantic segmentation approaches with U-Net and Feature Pyramid Network (FPN) architecture utilizing different CNN backbones. Additionally, the study enhances the model’s robustness by utilizing various data augmentation techniques. Moreover, the study incorporates Explainable Artificial Intelligence (XAI) to provide insights into the decision-making processes of deep neural networks, bridging the gap in understanding. The contributions of this work are in improving the practicality, interpretability, and robustness of CNN-based algorithms for steel surface defect detection and segmentation.","2169-3536","","10.1109/ACCESS.2024.3430113","Khalifa University of Science and Technology, Center for Digital Supply Chain and Operations Management,(grant numbers:RCII-2019-002); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10600705","Convolutional neural networks;data augmentation;explainability;industry 4.0;steel defect detection","Steel;Manufacturing;Data models;Feature extraction;Predictive models;Defect detection;Deep learning;Convolutional neural networks;Data augmentation;Fourth Industrial Revolution","","1","","39","CCBYNCND","18 Jul 2024","","","IEEE","IEEE Journals"
"Innovative Homomorphic Sorting of Environmental Data in Area Monitoring Wireless Sensor Networks","N. B. Malvi; N. Shylashree","Department of Electronics and Communication Engineering, RV College of Engineering (affiliated to Visvesvaraya Technological University Belagavi), Bengaluru, Karnataka, India; Department of Electronics and Communication Engineering, RV College of Engineering (affiliated to Visvesvaraya Technological University Belagavi), Bengaluru, Karnataka, India",IEEE Access,"2 May 2024","2024","12","","59260","59272","In many special cases, the data collected from wireless sensor networks are stored in encrypted form to provide the required privacy. Sorting is an essential operation on any stored data for orderly presentation and fast searching. In the case of cloud-stored data, sorting of the data can be delegated to the cloud server, employing suitable homomorphic encryption that supports sorting. This paper presents a new homomorphic sorting algorithm based on the Hardy-Littlewood-Polya rearrangement inequality. The associated homomorphic encryption scheme is accomplished using integer matrix keys generated based on Hermite Normal Form transformation. This work uses the homomorphic sort support encryption algorithm to securely sort the wireless sensor data stored in the cloud. Subsequently, the computation of the corresponding descriptive statistical values is securely outsourced to the Cloud Server. Our scheme saves the homomorphic sort execution time by about 30% compared to its nearest competing method.","2169-3536","","10.1109/ACCESS.2024.3390053","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10500700","Homomorphic encryption;homomorphic decryption;homomorphic sorting;parallel processing;privacy;wireless sensor network","Sorting;Cloud computing;Wireless sensor networks;Polynomials;Servers;Homomorphic encryption;Computational efficiency","","","","35","CCBYNCND","16 Apr 2024","","","IEEE","IEEE Journals"
"MAX2: An ReRAM-Based Neural Network Accelerator That Maximizes Data Reuse and Area Utilization","M. Mao; X. Peng; R. Liu; J. Li; S. Yu; C. Chakrabarti","School of Electrical, Computer and Energy Engineering, Arizona State University, Tempe, AZ, USA; School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, USA; School of Electrical, Computer and Energy Engineering, Arizona State University, Tempe, AZ, USA; School of Electrical, Computer and Energy Engineering, Arizona State University, Tempe, AZ, USA; School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, USA; School of Electrical, Computer and Energy Engineering, Arizona State University, Tempe, AZ, USA",IEEE Journal on Emerging and Selected Topics in Circuits and Systems,"11 Jun 2019","2019","9","2","398","410","Although recent advances in resistive random access memory (ReRAM)-based accelerator designs for deep convolutional neural networks (CNNs) offer energy-efficiency improvements over CMOS-based accelerators, they have a large number of energy consuming data transactions. In this paper, we propose MAX2, a multi-tile ReRAM accelerator framework for supporting multiple CNN topologies, that maximizes on-chip data reuse and reduces on-chip bandwidth to minimize energy consumption due to data movement. Building upon the fact that a large filter can be built with a stack of smaller (3×3) filters, we design every tile with nine processing elements (PEs). Each PE consists of multiple ReRAM subarrays to compute the dot product. The PEs operate in a systolic fashion, thereby maximizing input feature map reuse and minimizing interconnection cost. MAX2 chooses the data size granularity in the systolic array in conjunction with weight duplication to achieve very high area utilization without requiring additional peripheral circuits. We provide a detailed energy and area breakdown of each component at the PE level, tile level, and system level. The system-level evaluation in 32-nm node on several VGG-network benchmarks shows that the MAX2 can improve computation efficiency (TOPs/s/mm2) by 2.5× and energy efficiency (TOPs/s/W) by 5.2× compared with a state-of-the-art ReRAM-based accelerator.","2156-3365","","10.1109/JETCAS.2019.2908937","NSF-Computer and Network Systems (CNS)(grant numbers:1218183,1615774); NSF-Computing and Communication Foundations (CCF)(grant numbers:1449653); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8680623","ReRAM;CNN;accelerator;systolic;data reuse","Table lookup;Bandwidth;Convolution;Energy efficiency;Integrated circuit interconnections;Computational efficiency","","19","","35","IEEE","2 Apr 2019","","","IEEE","IEEE Journals"
"Instruction-Set Accelerated Implementation of CRYSTALS-Kyber","M. Bisheh-Niasar; R. Azarderakhsh; M. Mozaffari-Kermani","Department of Computer and Electrical Engineering and Computer Science, Florida Atlantic University, Boca Raton, FL, USA; Department of Computer and Electrical Engineering and Computer Science, Florida Atlantic University, Boca Raton, FL, USA; Department of Computer Engineering and Science, University of South Florida, Tampa, FL, USA",IEEE Transactions on Circuits and Systems I: Regular Papers,"10 Nov 2021","2021","68","11","4648","4659","Large scale quantum computers will break classical public-key cryptography protocols by quantum algorithms such as Shor’s algorithm. Hence, designing quantum-safe cryptosystems to replace current classical algorithms is crucial. Luckily there are some post-quantum candidates that are assumed to be resistant against future attacks from quantum computers, and NIST is considering standardizing them. Among these candidates, lattice-based cryptography sounds more interesting than others due to the performance results as well as confidence in the security. There are few works in the literature evaluating the performance of lattice-based cryptography in hardware. In this paper, we focus on Cryptographic Suite for Algebraic Lattices (CRYSTALS) key exchange mechanisms known as Kyber and provide an instruction-set hardware architecture and implement on Xilinx Artix-7 FPGA for performance evaluation and testing. Our proposed architecture provides an efficient and high-performance set of components to perform polynomial sampling, number-theoretic transform (NTT), and point-wise multiplication to speed up lattice-based post-quantum cryptography (PQC). This architecture implemented on ASIC outperforms state-of-the-art implementations.","1558-0806","","10.1109/TCSI.2021.3106639","NSF(grant numbers:1801341); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9525069","ASIC;FPGA;hardware architecture;Kyber;lattice-based cryptography;post-quantum cryptography","Computer architecture;Cryptography;Hardware;Elliptic curve cryptography;Computers;Field programmable gate arrays;Signal processing algorithms","","67","","42","IEEE","30 Aug 2021","","","IEEE","IEEE Journals"
"Data Acquisition System for ITER Neutron Diagnostic Divertor Neutron Flux Monitor","V. A. Fedorov; Y. A. Kashchuk; E. S. Martazov; Y. A. Parishkin; N. A. Selyaev; V. A. Vorobiev","National Research Nuclear University MEPhI, Moscow, Russia; Institution “Project Center ITER,”, Moscow, Russia; National Research Nuclear University MEPhI, Moscow, Russia; National Research Nuclear University MEPhI, Moscow, Russia; National Research Nuclear University MEPhI, Moscow, Russia; Institution “Project Center ITER,”, Moscow, Russia",IEEE Transactions on Nuclear Science,"13 Sep 2018","2018","65","9","2392","2397","Neutron diagnostic “Divertor Neutron Flux Monitor” is being under the development for the ITER project. This diagnostic is a primary tool for total neutron yield and fusion power measurements. Diagnostic consists of the three detector modules and the enhanced data acquisition (DAQ) systems. Each module contains three fission chambers (FCs) with 235U and three with 238U. The choice of the FC types and sensitivities is determined by the project requirements for the neutron flux measurement range, error, and time resolution. The DAQ system performs preliminary amplification and processing of the fission chamber signals, and the calculation of the neutron flux at the module location to calculate the total neutron yield and fusion power. The DAQ system transfers measured data to the upper level of the control system with a time resolution of 1 ms and provides raw data archiving. The hardware and software of the DAQ system were developed taking into account the requirements of the ITER project. The data processing system mockup of a single detection module was manufactured. This mockup passed laboratory and reactor tests. The system has passed the preliminary design approval. Preparation for the manufacturing of the system prototype is carried out at this moment. The architecture of the DAQ system and its components are shown in the report, and the test results of the system mockup are discussed.","1558-1578","","10.1109/TNS.2018.2855961","Institution “Project Center ITER” through the framework of the state contract with State Corporation “ROSATOM.”; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8411456","Fusion reactors;neutrons;reactor instrumentation;tokamak devices","Data acquisition;Neutrons;Detectors;Current measurement;Control systems;Pulse measurements;Monitoring","","3","","8","IEEE","16 Jul 2018","","","IEEE","IEEE Journals"
"A Novel Hybrid Acquisition System for Industrial Condition Monitoring and Predictive Maintenance","D. Pinardi; L. Arpa; A. Toscani; E. Manconi; M. Binelli; E. Mucchi","Department of Engineering and Architecture, University of Parma, Parma, Italy; Department of Engineering, University of Ferrara, Ferrara, Italy; Department of Engineering and Architecture, University of Parma, Parma, Italy; Department of Engineering and Architecture, University of Parma, Parma, Italy; Department of Engineering and Architecture, University of Parma, Parma, Italy; Department of Engineering, University of Ferrara, Ferrara, Italy",IEEE Access,"22 Jul 2024","2024","12","","98121","98129","A novel data acquisition system for condition monitoring and predictive maintenance of mechanical parts, machinery, and industrial plants is presented. Current commercial solutions rely on an analog architecture and a star topology, in which all transducers are connected to a centralized acquisition unit. Usually this requires long shielded cables, which are sensitive to electromagnetic disturbances, always present in industrial environments. The proposed solution makes use of a digital bus implemented on an Unshielded Twisted Pair to connect one or more Acquisition Nodes to a data storage system (e.g., a laptop or an industrial computer). The wiring is simplified, cabling cost is reduced, high disturbance rejection is obtained, at the same time ensuring synchronization between all signals, mandatory for the computation of the most advanced diagnostic metrics. The performance and effectiveness of the developed system are proved in comparison with a top-quality, laboratory-grade commercial solution. A 10-days experiment was performed on a radial bearing mounted on a bearing test bench, by employing both systems side-by-side. Early-stage damage identification will be demonstrated with the described solution, despite costing a fraction and offering numerous advantages for industrial applications with respect to products currently available on the market.","2169-3536","","10.1109/ACCESS.2024.3428313","National Recovery and Resilience Plan (NRRP) Mission 4 Component 2 Investment 1.5—Call for tender No. 3277 of 30/12/2021 of Italian Ministry of University and Research through European Union—NextGenerationEU Award: Project Code ECS_00000033, Concession Decree No. 1052 of 23/06/2022, adopted by Italian Ministry of University and Research, CUP B33D21019790006, Ecosystem for Sustainable Transition of Emilia-Romagna (ECOSISTER); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10597382","Bearing fault detection;data acquisition system;digital bus;industrial condition monitoring;predictive maintenance","Data acquisition;Condition monitoring;Band-pass filters;Topology;Cables;Analog-digital conversion;Predictive maintenance;Fault detection","","","","41","CCBYNCND","15 Jul 2024","","","IEEE","IEEE Journals"
"Digital Twin and Data-Driven Quality Prediction of Complex Die-Casting Manufacturing","D. Liu; Y. Du; W. Chai; C. Lu; M. Cong","School of Mechanical Engineering, Dalian University of Technology, Dalian, China; Dalian Jiaotong University, Dalian, China; School of Mechanical Engineering, Dalian University of Technology, Dalian, China; School of Mechanical Engineering, Dalian University of Technology, Dalian, China; School of Mechanical Engineering, Dalian University of Technology, Dalian, China",IEEE Transactions on Industrial Informatics,"19 Sep 2022","2022","18","11","8119","8128","Digital twin and data-driven technologies provide an idea for realizing complex product quality prediction. Aiming at the issues of real-time visual monitoring, operating status analysis, and quality prediction in complex die-casting intelligent manufacturing, a digital twin and data-driven quality prediction architecture is proposed. The virtual-real interaction digital twin of die-casting manufacturing cells is established. The collaborative working mode of physical cells, virtual cells, and real-time monitoring is constructed to predict product quality. The learning method of die-casting parameter data and appearance defect data is proposed to realize the real-time quality prediction in die-casting process and the appearance defect quality prediction after processing, respectively. The data preprocessing and XGBoost-based learning method is proposed for real-time quality prediction of die-casting process. A single-shot refinement neural network for aluminum casting tiny defects detection (Refine-ACTDD) based on deep learning is proposed to solve the high-precision defect detection problems of small appearance defects of complex castings and large interference of complex background. Taking the complex aluminum die-casting as an example, the applications of quality prediction are verified. The method provides a new technical approach for high-precision quality prediction of complex die-casting manufacturing.","1941-0050","","10.1109/TII.2022.3168309","Science and Technology Research Project of Liaoning Province(grant numbers:2021JH1/104000 79); Dalian Science and Technology Major Project(grant numbers:2020ZD13GX003); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9762013","Deep learning;defects detection;die-casting manufacturing;digital twin;quality prediction","Digital twin;Manufacturing;Casting;Real-time systems;Solid modeling;Data models;Production","","27","","30","IEEE","25 Apr 2022","","","IEEE","IEEE Journals"
"LSTM-Based Energy-Efficient Wireless Communication With Reconfigurable Intelligent Surfaces","K. D. Gupta; R. Nigam; D. K. Sharma; S. K. Dhurandher","Department of Computer Science and Engineering, Maharaja Surajmal Institute of Technology, New Delhi, India; Division of Computer Engineering, University of Delhi, Netaji Subhas Institute of Technology, New Delhi, India; Department of Information Technology, Netaji Subhas University of Technology, New Delhi, India; Department of Information Technology, Netaji Subhas University of Technology, New Delhi, India",IEEE Transactions on Green Communications and Networking,"23 May 2022","2022","6","2","704","712","A Reconfigurable Intelligent Surface is an eminent approach for improving the net data rate and maximizing the energy efficacy of wireless Base Stations (BS). Due to the vast number of surface elements, the task of optimizing the BS’s transmission and Reconfigurable Intelligent Surface (RIS) element’s configuration is incredibly challenging. In principle, to enhance energy conservation and diminish the BS power consumption, it is essential to optimize the transmission power of the BS and phase configuration of the RIS. This paper proposes a Long Short-Term Memory (LSTM) based scheme which performs decision-making using dynamic information of the wireless networks following channel intricacy and RIS’s energy harvesting while increasing the energy efficacy. Once trained in a real-time environment, the proposed LSTM model foretells optimal RIS configuration for each transmission. The transmissions considered are designated for users located in various regions in the corresponding wireless network. The LSTM model and Adam optimizer are used to build the RIS-aided downlink system model and explore its energy efficiency and robustness. The results achieved after performing various simulations determine that the LSTM framework raises energy efficacy to 35.42% while increasing the RIS elements from 9 to 25. In addition, the model can achieve more than 100 bps $/$ Hz net data rate.","2473-2400","","10.1109/TGCN.2021.3135437","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9650786","Adam optimizer;energy efficiency;long short-term memory;phase configuration;reconfigurable intelligent surfaces","Energy efficiency;Array signal processing;Green products;Wireless networks;Downlink;Optimization;Energy consumption","","12","","45","IEEE","14 Dec 2021","","","IEEE","IEEE Journals"
"MiniFloats on RISC-V Cores: ISA Extensions With Mixed-Precision Short Dot Products","L. Bertaccini; G. Paulin; M. Cavalcante; T. Fischer; S. Mach; L. Benini","Integrated System Laboratory (IIS), ETH Zurich, Zürich, Switzerland; Integrated System Laboratory (IIS), ETH Zurich, Zürich, Switzerland; Integrated System Laboratory (IIS), ETH Zurich, Zürich, Switzerland; Integrated System Laboratory (IIS), ETH Zurich, Zürich, Switzerland; Axelera AI, Zürich, Switzerland; Integrated System Laboratory (IIS), ETH Zurich, Zürich, Switzerland",IEEE Transactions on Emerging Topics in Computing,"5 Dec 2024","2024","12","4","1040","1055","Low-precision floating-point (FP) formats have recently been intensely investigated in the context of machine learning inference and training applications. While 16-bit formats are already widely used, 8-bit FP data types have lately emerged as a viable option for neural network training when employed in a mixed-precision scenario and combined with rounding methods increasing the precision in compound additions, such as stochastic rounding. So far, hardware implementations supporting FP8 are mostly implemented within domain-specific accelerators. We propose two RISC-V instruction set architecture (ISA) extensions, enhancing respectively scalar and vector general-purpose cores with low and mixed-precision capabilities. The extensions support two 8-bit and two 16-bit FP formats and are based on dot-product instructions accumulating at higher precision. We develop a hardware unit supporting mixed-precision dot products and stochastic rounding and integrate it into an open-source floating-point unit (FPU). Finally, we integrate the enhanced FPU into a cluster of scalar cores, as well as a cluster of vector cores, and implement them in a 12 nm FinFET technology. The former achieves 575 GFLOPS/W on FP8-to-FP16 matrix multiplications at 0.8 V, 1.26 GHz; the latter reaches 860 GFLOPS/W at 0.8 V, 1.08 GHz, 1.93x higher efficiency than computing on FP16-to-FP32.","2168-6750","","10.1109/TETC.2024.3365354","The European Pilot(grant numbers:101034126); European High Performance Computing Joint Undertaking; Fractal(grant numbers:877056); Electronic Components and Systems for European Leadership; EU Horizon 2020 research and innovation programme; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10440050","Transprecision computing;RISC-V;ISA extension;floating-point architectures;widening dot product;NN training","Training;Computer architecture;Hardware;Dynamic range;Artificial neural networks;Stochastic processes;Computational modeling","","3","","45","IEEE","19 Feb 2024","","","IEEE","IEEE Journals"
"The Cyber Security Modeling Language: A Tool for Assessing the Vulnerability of Enterprise System Architectures","T. Sommestad; M. Ekstedt; H. Holm","Royal Institute of Technology, Stockholm, Sweden; Royal Institute of Technology, Stockholm, Sweden; Royal Institute of Technology, Stockholm, Sweden",IEEE Systems Journal,"4 Jul 2013","2013","7","3","363","373","The cyber security modeling language (CySeMoL) is a modeling language for enterprise-level system architectures coupled to a probabilistic inference engine. If the computer systems of an enterprise are modeled with CySeMoL, this inference engine can assess the probability that attacks on the systems will succeed. The theory used for the attack-probability calculations in CySeMoL is a compilation of research results on a number of security domains and covers a range of attacks and countermeasures. The theory has previously been validated on a component level. In this paper, the theory is also validated on a system level. A test indicates that the reasonableness and correctness of CySeMoL assessments compare with the reasonableness and correctness of the assessments of a security professional. CySeMoL's utility has been tested in case studies.","1937-9234","","10.1109/JSYST.2012.2221853","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6378394","Computer security;expert systems;risk analysis;supervisory control and data acquisition (SCADA) systems","Computer architecture;Software;Databases;Systems engineering and theory;Computer security;Probabilistic logic","","111","","65","IEEE","11 Dec 2012","","","IEEE","IEEE Journals"
"Reinforcement Learning-Based Energy-Aware Area Coverage for Reconfigurable hRombo Tiling Robot","A. V. Le; R. Parween; P. T. Kyaw; R. E. Mohan; T. H. Q. Minh; C. S. C. S. Borusu","ROAR lab, Engineering Product Development Pillar, Singapore University of Technology and Design, Singapore; ROAR lab, Engineering Product Development Pillar, Singapore University of Technology and Design, Singapore; ROAR lab, Engineering Product Development Pillar, Singapore University of Technology and Design, Singapore; ROAR lab, Engineering Product Development Pillar, Singapore University of Technology and Design, Singapore; Optoelectronics Research Group, Faculty of Electrical and Electronics Engineering, Ton Duc Thang University, Ho Chi Minh, Vietnam; ROAR lab, Engineering Product Development Pillar, Singapore University of Technology and Design, Singapore",IEEE Access,"1 Dec 2020","2020","8","","209750","209761","Applying the automation in covering the areas entirely eases manual jobs in various domestic fields such as site investigation, search, rescue, security, cleaning, and maintenance. A self-reconfigurable robot with adjustable dimensions is a viable answer to improve the coverage percentage for predefined map areas. However, the shape-shifting of this robot class also adds to the complexity of locomotion components and the need for an optimal complete coverage strategy for this new type of robot. The typical complete coverage route, including the least times of shape-shifting, the shortest navigation route, and the minimum travel time, is presented in the article. By splitting the map into the sub-areas similar to the self-reconfigurable robot's available shapes, the robot can design the ideal tileset and optimal navigation strategies to cover the workspace. To this end, we propose a Complete Tileset Energy-Aware Coverage Path Planning (CTPP) framework for a tiling self-reconfigurable robot named hRombo with four rhombus-shaped modules. The robot can reconfigure its base structure into seven distinct forms by activating the servo motors to drive the three robot hinges connecting robot modules. The problem of optimal path planning assisting the proposed hRombo robot to clear optimally all predefined tiles within the arbitrary workspace is considered a classic Travel Salesman Problem (TSP), and this TSP is solved by the reinforcement learning (RL) approach. The RL's reward function and action space are based on robot kinematic and the required energies, including transformation, translation, and orientation actions, to move the robot inside the workspace. The CTPP for the hRombo robot is validated with conventional complete coverage methods in simulation and real workspace conditions. The results showed that the CTPP is suitable for producing Pareto plans that enable robots to navigate from source to target in different workspaces with the least consumed energy and time among considered methods.","2169-3536","","10.1109/ACCESS.2020.3038905","National Robotics Programme under its Robotics Enabling Capabilities and Technologies(grant numbers:192 25 00051); National Robotics Programme under its Robot Domain Specific(grant numbers:192 22 00058); Agency for Science, Technology, and Research; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9262896","Reconfigurable robot;tiling robotic;reinforcement learning;complete coverage planning;energy path planning","Robots;Shape;Navigation;Robot kinematics;Path planning;Wheels;Servomotors","","27","","47","CCBY","18 Nov 2020","","","IEEE","IEEE Journals"
"A Hybrid Task Crash Recovery Solution for Edge Computing in IoT-Based Manufacturing","R. Xiao; Y. Zhang; X. H. Cui; F. Zhang; H. H. Wang","School of Cyber Science and Engineering, Wuhan University, Wuhan, China; School of Computer and Information Engineering, Hubei University, Wuhan, China; School of Cyber Science and Engineering, Wuhan University, Wuhan, China; Department of Finance, McQuay Air Conditioning and Refrigeration (Wuhan) Company, Wuhan, China; School of Computer and Information Engineering, Hubei University, Wuhan, China",IEEE Access,"9 Aug 2021","2021","9","","106220","106231","Smart factory is the deep integration of technology, business, products, and industry. The R&D of products, the construction of factory information, customer orders, and supply chain data are combined to act on the production. This paper proposes a Hybrid Internet of Things (H-IoT) platform framework, which consists of five layers: intelligent device layer, communication protocol layer, edge computing layer, IoT control layer, and application layer. Object Linking and Embedding (OLE) for Process Control (OPC) transmits the received device data to the database of the edge server through the TCP/IP protocol. After the edge server performs preprocessing such as data cleaning, the device data are uniformly collected and distributed through the IoT layer. The various subsystems of the smart factory obtain the required resource data through IoT. To run tasks uninterruptedly and efficiently, we propose a Container-Managed Task Crash Recovery Mechanism for the Edge Computing (EC) layer. We design a reasonable EC hierarchy, then propose a task migration scheduling strategy. Our method ensures the reliability and stability of manufacturing with mass data transmission even in the case of a random crash of partial edge servers.","2169-3536","","10.1109/ACCESS.2021.3068471","National Key Research and Development Program of China(grant numbers:2018YFC1604000); Fundamental Research Funds for the Central Universities of China(grant numbers:2042017gf0035,2042019kf0268); National Natural Science Foundation of China(grant numbers:61572374,U163620068,U1135005,61572371); Natural Science Foundation of Hubei Province(grant numbers:2017CFB663); Academic Team Building Plan for Young Scholars from Wuhan University(grant numbers:WHU2016012); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9385091","H-IoT framework;EC;container-managed task crash recovery mechanism","Edge computing;Production;Task analysis;Manufacturing;Computer architecture;Job shop scheduling;Processor scheduling","","9","","40","CCBYNCND","24 Mar 2021","","","IEEE","IEEE Journals"
"High-Performance and Scalable System Architecture for the Real-Time Estimation of Generalized Laguerre-Volterra MIMO Model From Neural Population Spiking Activity","W. X. Y. Li; R. H. M. Chan; W. Zhang; R. C. C. Cheung; D. Song; T. W. Berger","Department of Electronic Engineering, City University of Hong Kong, Hong Kong SAR, China; Department of Electronic Engineering, City University of Hong Kong, Hong Kong SAR, China; Department of Electronic Engineering, City University of Hong Kong, Hong Kong SAR, China; Department of Electronic Engineering, City University of Hong Kong, Hong Kong SAR, China; Department of Biomedical Engineering, Center for Neural Engineering, Los Angeles, CA, USA; Department of Biomedical Engineering, Center for Neural Engineering, Los Angeles, CA, USA",IEEE Journal on Emerging and Selected Topics in Circuits and Systems,"30 Jan 2012","2011","1","4","489","501","A hardware-based computational platform is developed to model the generalized Laguerre–Volterra (GLV) multiple-input multiple-output (MIMO) system which is essential in identification of the time-varying neural dynamics underlying spike activities. Time cost for model parameters estimation is greatly reduced by a significant enhancement of 3.1$\,\times 10^{3}~{\rm x}$ in data throughput of the Xilinx XC6VSX475T field programmable gate array (FPGA)-based system compared to a C model running on an Intel i7–860 Quad Core processor. The processing core consists of a first stage containing a vector convolution and MAC (multiply and accumulation) component; a second stage containing a prethreshold potential updating unit with an error approximation function component; and a third stage consisting of a gradient calculation unit. The hardware platform is scalable with the utilization of different number of processing units within each stage. It is also easily extendable into a multi-FPGA structure to further enhance the computational capability. A hardware IP library is proposed for versatile neural models and applications. The implementation of the self-reconfiguring platform and its applications to future research of neural dynamics are explored.","2156-3365","","10.1109/JETCAS.2011.2178733","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6112182","Field programmable gate array (FPGA);generalized Laguerre-Volterra model;IP library;multiple-input multiple-output (MIMO) system;neuroscience","Hardware;Brain modeling;Algorithm design and analysis;MIMO;Kernel;Computational modeling;Field programmable gate arrays","","17","","35","IEEE","23 Dec 2011","","","IEEE","IEEE Journals"
"Data Augmentation With CycleGAN to Build a Classifier for Novel Defects From the Dicing Stage of Semiconductor Package Assembly","C. T. Wu; C. S. Tsou; S. H. Li","College of Business, National Taipei University of Business, Taipei, Taiwan; Institute of Information and Decision Sciences, National Taipei University of Business, Taipei, Taiwan; Department of Accounting Information, National Taipei University of Business, Taipei, Taiwan",IEEE Access,"4 Sep 2023","2023","11","","93012","93018","Industry 4.0, a concept first proposed by Germany, has resulted in an increasing number of companies adopting a mass customization strategy. This strategy is widely used across various industries, enabling the production of small batches of diversified products to meet the diverse needs of customers. It encompasses the business process of providing customized goods that best fulfill individual customer requirements, thereby necessitating small-scale production of multiple products. Therefore, the product life cycle of mass customization is much shorter than other production strategies. When product line changes are frequent and customized products have high yield rates, accurately detecting potential defects from a limited number of images is a daunting challenge. If the defect identification classification model needs to maintain a certain level of identification accuracy and the model needs to be deployed quickly, it is impossible to wait until a large number of defect images are collected before deploying an accurate model for new defects. Obtaining a high-precision defect identification classification model is crucial. In this study, we employed the style transfer method of CycleGAN, which takes advantage of the unmatched training images, to successfully transfer the style of defective images from old products to defect-free images of new products. However, CycleGAN requires a large number of images for training, so this study primarily focuses on rare sample categories. We first obtained the defect mask through a semantic segmentation model and then separated the foreground defect from the wafer background using digital image processing techniques. We then copied and pasted the separated defect onto a new wafer background to generate fake defect images. Finally, a generative adversarial network architecture was used to perform image blending to make the fake defect images more natural and realistic. The effectiveness of the data augmentation method was verified through a convolutional neural network model. Through the proposed method in this study, the number of defect images in new products was successfully increased, which helps to deploy a defect identification classification model for new products quickly.","2169-3536","","10.1109/ACCESS.2023.3309159","National Science and Technology Council, Executive Yuan, R.O.C(grant numbers:NSTC 112-2637-H-141-003-); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10231323","Automated optical inspection (AOI);outsourced semiconductor assembly and test (OSAT);artificial intelligence;vision defects;GAN;image fusion","Semiconductor device modeling;Data models;Training;Integrated circuit modeling;Artificial intelligence;Production facilities;Semantic segmentation;Outsourcing;Assembly systems","","1","","29","CCBY","28 Aug 2023","","","IEEE","IEEE Journals"
"Digital Twin in Aerospace Industry: A Gentle Introduction","L. Li; S. Aslam; A. Wileman; S. Perinpanayagam","IVHM Centre, Cranfield University, Bedfordshire, U.K.; IVHM Centre, Cranfield University, Bedfordshire, U.K.; IVHM Centre, Cranfield University, Bedfordshire, U.K.; IVHM Centre, Cranfield University, Bedfordshire, U.K.",IEEE Access,"27 Jan 2022","2022","10","","9543","9562","Digital twin (DT), primarily a virtual replica of any conceivable physical entity, is a highly transformative technology with profound implications. Whether it be product development, design optimisation, performance improvement, or predictive maintenance, digital twins are changing the ways work is undertaken in various industries with multifarious business applications. Aerospace industry, including its manufacturing base, is one such keen adopter of digital twins with an unprecedented interest in their bespoke design, development, and implementation across wider operations and critical functions. This, however, comes with some misconceptions about the digital twin technology and lack of understanding with respect to its optimal implementation. For instance, equating a digital twin to an intelligent model while ignoring the essential components of data acquisition and visualisation, misleads the creators into building digital shadow or digital models, instead of the actual digital twin. This paper unfolds such intricacies of digital twin technology for the aerospace community in particular and others in general so as to remove the fallacies that affect their effective realisation for safety-critical systems. It comprises a comprehensive survey of digital twins and their constituent elements. Elaborating their characteristic state-of-the-art composition along with corresponding limitations, three dimensions of the future digital twins for the aerospace sector, termed as aero-Digital Twins (aero-DTs), are proposed as an outcome of this survey. These include the interactive, standardisation, and cognitive dimensions of digital twins, which if leveraged diligently could help the aero-DT research and development community quadruple the efficiency of existing and future aerospace systems as well as their associated processes.","2169-3536","","10.1109/ACCESS.2021.3136458","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9656111","Digital twins;aircraft operation and maintenance;aerospace manufacturing","Digital twin;Computational modeling;Aerospace industry;Atmospheric modeling;Aircraft;Sensors;Analytical models","","78","","157","CCBY","20 Dec 2021","","","IEEE","IEEE Journals"
"LCG-YOLO: A Real-Time Surface Defect Detection Method for Metal Components","J. Yu; X. Shi; W. Wang; Y. Zheng","Hebei University of Architecture, Zhangjiakou, China; Hebei University of Architecture, Zhangjiakou, China; Hebei University of Architecture, Zhangjiakou, China; Hebei University of Architecture, Zhangjiakou, China",IEEE Access,"25 Mar 2024","2024","12","","41436","41451","Surface defect inspection of metal components plays a critical role in ensuring product quality, enhancing production efficiency, and reducing costs, with particular emphasis on the detection of small-sized surface defects to ensure the safety and reliability of metal components during their usage. Existing detection methods for small size defects on the surfaces of metal components have some shortcomings, such as low precision and poor real-time performance. To solve these two problems, this paper proposes a real-time defect detection method based on improved YOLO. Firstly, the LSandGlass (LSG) module is used to replace the residual module in the backbone network, which reduces information loss, eliminates the low-resolution feature layer, and minimizes semantic loss. The network then uses a lightweight Ghost convolution at the neck to extract the network features. In addition, the convolutional block attention mechanism (CBAM) module is added to improve the detection precision of small-size defects. Finally, soft intersection over union (SIoU) is used to further enhance target detection capability. The experiment was carried out a self-made hexagonal bolt data set of typical commonly used metal components. The experimental results show that compared to the original YOLOv5, the mAP (0.5) is improved by 5.7% to 95.50%, and the reasoning FPS is improved by 21 fps to 95 fps. These results indicate that the proposed LCG-YOLO improves the real-time detection performance of metal component surface defects.","2169-3536","","10.1109/ACCESS.2024.3378999","Basic Scientific Research Business Fund Project of Universities in Hebei Province(grant numbers:2022CXTD08); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10474410","Surface defect detection;LSandGlass;CBAM;ghost;SIoU;YOLOv5","Metals;Feature extraction;YOLO;Surface treatment;Defect detection;Real-time systems;Production","","1","","35","CCBYNCND","18 Mar 2024","","","IEEE","IEEE Journals"
"Key-Components for Digital Twin Modeling With Granularity: Use Case Car-as-a-Service","C. Steinmetz; G. N. Schroeder; R. N. Rodrigues; A. Rettberg; C. E. Pereira","Hamm-Lippstadt University of Applied Sciences, Hamm, Germany; Department of Electrical Engineering, Federal University of Rio Grande do Sul, Porto Alegre, RS, Brazil; Center for Computacional Sciences, Universidade Federal do Rio Grande, Rio Grande, RS, Brazil; Hamm-Lippstadt University of Applied Sciences, Hamm, Germany; Department of Electrical Engineering, Federal University of Rio Grande do Sul, Porto Alegre, RS, Brazil",IEEE Transactions on Emerging Topics in Computing,"3 Mar 2022","2022","10","1","23","33","Digital technologies are changing the way people interact with the world. The Digital Twin (DT) is one of the key enablers of Industry 4.0. It provides a virtual representation of an observable element of the real world. These elements can be both physical objects such as devices or non-physical such as interactions and processes. Digitalization of the real world enables new business models, transforming traditional products into services, as for instance, the Car-as-a-Service (CaaS). To integrate all components that will be part of systems like CaaS or Smart Cities, it is necessary to have well-defined standards for modeling and defining an architecture especially taking into consideration the granularity level of the system. This paper proposes the main components needed for building DT-based systems with different levels of granularity. These components have been arranged in layers to specify the concerns of each part of the system. A case study has been developed to demonstrate the modeling and the deployment of the Digital Twin, highlighting how this concept can be one of the key enablers for CaaS.","2168-6750","","10.1109/TETC.2021.3131532","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9638377","Digital twin;architecture;granularity;model;car-as-a-service;industry 4.0","Digital twin;Data models;Computer architecture;Automobiles;Standards;Solid modeling;Ontologies","","4","","45","IEEE","6 Dec 2021","","","IEEE","IEEE Journals"
"A Novel MPSoC Interface and Control Architecture for Multistandard RF Transceivers","S. Brandstätter; M. Huemer","Danube Mobile Communications Engineering GmbH and Company, KG., Linz, Austria; Institute of Signal Processing, Johannes Kepler University Linz, Linz, Austria",IEEE Access,"20 May 2017","2014","2","","771","787","The introduction of new mobile communication standards, enabling the ever growing amount of data transmitted in mobile communication networks, continuously increases the complexity of control processing within radio frequency (RF) transceivers. Since this complexity cannot be handled by traditional approaches, this paper focuses on the partitioning of RF transceiver systems and on the implementation of application-specific components to introduce an advanced multiprocessor system-on-chip interface and control architecture which is able to fulfill the requirements of future RF transceiver integrations. The proposed framework demonstrates a high degree of scalability, flexibility, and reusability. Consequently, the time to market for products can be reduced and fast adaptations to the requirements of the market are feasible. In addition, the developed application-specific components achieve improved or at least equivalent performance results compared with common architectures while the silicon area can be reduced. This characteristic has positive effects on the costs as well as on the power consumption of the RF transceiver.","2169-3536","","10.1109/ACCESS.2014.2345194","Austrian COMET-K2 Program through the Linz Center of Mechatronics GmbH, Linz, Austria; Austrian Federal Government; Federal State of Upper Austria; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6870422","RF transceiver;hard real-time controlling;MPSoC;on-chip synchronization;on-chip communication;application-specific processor design;application-specific NoC design","Radio frequency;Transceivers;Process control;Baseband;Mobile communication","","4","","27","OAPA","1 Aug 2014","","","IEEE","IEEE Journals"
"ATCA-Based Hardware for Control and Data Acquisition on Nuclear Fusion Fast Control Plant Systems","M. Correia; J. Sousa; A. P. Rodrigues; A. J. N. Batista; B. Goncalves; C. A. F. Varandas; C. M. B. A. Correia","Associação Euratom, Instituto de Plasmas e Fusão Nuclear, Laboratório Associado, Instituto Superior Técnico, Universidade Técnica de Lisboa, Lisboa, Portugal; Associação Euratom, Instituto de Plasmas e Fusão Nuclear, Laboratório Associado, Instituto Superior Técnico, Universidade Técnica de Lisboa, Lisboa, Portugal; Associação Euratom, Instituto de Plasmas e Fusão Nuclear, Laboratório Associado, Instituto Superior Técnico, Universidade Técnica de Lisboa, Lisboa, Portugal; Associação Euratom, Instituto de Plasmas e Fusão Nuclear, Laboratório Associado, Instituto Superior Técnico, Universidade Técnica de Lisboa, Lisboa, Portugal; Associação Euratom, Instituto de Plasmas e Fusão Nuclear, Laboratório Associado, Instituto Superior Técnico, Universidade Técnica de Lisboa, Lisboa, Portugal; Associação Euratom, Instituto de Plasmas e Fusão Nuclear, Laboratório Associado, Instituto Superior Técnico, Universidade Técnica de Lisboa, Lisboa, Portugal; Grupo de Electrónica e Instrumentação do Centro de Instrumentação, Department de Física, Universidade de Coimbra Polo II, Coimbra, Portugal",IEEE Transactions on Nuclear Science,"18 Aug 2011","2011","58","4","1701","1705","In contemporary control and data acquisition systems for Nuclear Fusion devices, the galloping need for high channel density and real-time multi-input-multi-output (MIMO) controller support gave rise to a new generation of hardware architecture based on the Advanced Telecommunications Computing Architecture (ATCA) specification. In addition, ATCA successfully delivered solutions in other sensitive issues like redundancy, power dissipation and available area for components and routing. Experience has shown, however, that such hardware devices can require a lengthy development. The ATCA specification allows for custom solutions in areas of the interfaces which can be used to define extensions of the standard for instrumentation needs. The""'xTCA for Physics"" workgroups are currently developing ATCA and MicroTCA extensions for Physics instrumentation applications. These ex tensions will define interfaces in customizable areas which will support functionalities required by the instrumentation and facilitate hardware development and its posterior operation in a Fusion control plant environment-most notably, dedicated timing and input-output (IO) port assignment on the Rear Transition Module (RTM). The prototype hereby presented is a Peripheral Component Interface (PCIe) switch Advanced Mezzanine Card (AMC) carrier blade. The device serves as a hub, as to control and handle I/O data from its parent nodes existing within the same ATCA shelf through its fabric channels in dual-star topology. Parent node blades, under development, are equally linked through ATCA's agnostic fabric in full-mesh topology, as to attain system MIMO functionality from all I/O endpoints. The switch blade carries up to four AMC modules, adding up to modularity and versatility. This allows for a much more independent and speedier hardware development, as dedicated AMC modules, such as data processing and storage devices, can be simultaneously developed. Commercial off-the-shelf (COTS) AMC products are readily available and may also be immediately integrated in the system.","1558-1578","","10.1109/TNS.2011.2158111","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5887362","Advanced Telecommunications Computing Architecture (ATCA);fast control plant systems","Hardware;Blades;Fabrics;Switches;Synchronization;Field programmable gate arrays","","16","","24","IEEE","16 Jun 2011","","","IEEE","IEEE Journals"
"Redefining IBM power system design for CORAL","S. Roberts; C. Mann; C. Marroquin",NA; NA; NA,IBM Journal of Research and Development,"13 May 2020","2020","64","3/4","2:1","2:10","Stipulations in the 2014 Collaboration of Oak Ridge, Argonne, and Livermore (CORAL) joint procurement activity not only motivated a fundamental change in IBM's high-performance computer design, which refocused IBM power systems on compute nodes that can scale to 200 petaflops with access to 2.5 PB of memory, but also served the commercial market for single-server applications. The distribution of both processing elements and memory required a careful look at data movement. The resultant AC922 POWER9 system features NVIDIA V100 GPUs with cache line access granularity, more than double the IO bandwidth of PCIe Gen3, and low-latency interfaces interconnected by the state-of-the-art dual-rail Mellanox CAPI EDR HCAs running at 50 Gb/s. With processing units designed to operate at 250 and 300 W, a single system can produce up to 3,080 kW. The overall CORAL solutions achieved power usage effectiveness rankings in the top ten on the Green500. Previous power designs used uniquely designed cabinets and scaled-up infrastructure to achieve efficiency. For successful commercial use, our design uses industry-standard 19-in drawers and racks. Both air- and water-cooled solutions allow for use in a wide range of customer environments. This article documents the novel design features that facilitate data movement and enable new coherent programming models. It describes how three generations of system designs became the foundation for the CORAL contract fulfillment and illustrates key features and specifications of the final product.","0018-8646","","10.1147/JRD.2019.2963637","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8949743","POWER9;NVLink;CORAL;CAPI","Graphics processing units;Central Processing Unit;Computer architecture;Bandwidth;Biological system modeling;Hardware;Standards","","2","","14","IBM","3 Jan 2020","","","IBM","IBM Journals"
"Estimation of the Ocean Water Albedo From Remote Sensing and Meteorological Reanalysis Data","Y. Feng; Q. Liu; Y. Qu; S. Liang","State Key Laboratory of Remote Sensing Science, College of Global Change and Earth System Science, Beijing Normal University, Beijing, China; State Key Laboratory of Remote Sensing Science, College of Global Change and Earth System Science, Beijing Normal University, Beijing, China; State Key Laboratory of Remote Sensing Science, College of Global Change and Earth System Science, Northeast Normal University, Changchun, China; School of Geography, University of Maryland, College Park, MD, USA",IEEE Transactions on Geoscience and Remote Sensing,"19 Jan 2016","2016","54","2","850","868","Ocean water albedo (OWA) plays an important role in the global climate variation. Compared with the achievements in land surface albedo studies, the global distributions of ocean water and sea ice albedo are seldom addressed. This study designed an operational global OWA algorithm based on the three-component reflectance model of the ocean water: sun glint, whitecaps, and water-leaving reflectance. The related achievements in these three areas are reviewed and integrated into the operational algorithm. After the sensitive analysis, the algorithm is compared with previous studies and validated with ground observations at COVE site located 25 km east of Virginia Beach (36.91° N, 75.71° W), and the results indicate that the proposed algorithm is generally consistent with previous parameterization scheme. As an example, the global OWAs in summer and winter 2011 are generated using the remote sensing reflectance data sets via the Moderate Resolution Imaging Spectroradiometer and Modern-Era Retrospective analysis for Research and Applications meteorological reanalysis data set. The generated product includes instantaneous (e.g., local noon) and daily mean OWAs under both clear-sky and white-sky conditions. Upon the examples, the local noon clear-sky OWA shows a significant latitude variation due to the dominance of the solar angle, whereas the white-sky OWA is sensitive to wind speeds and optical constituents. The global distribution of the daily mean OWA exhibits a similar trend to the local noon OWA. However, the daily mean clear-sky OWA is significantly larger than the local noon OWA; this finding should be noted when using OWA products for energy balance research. Additionally, all forms of OWA products exhibit increase in coastal areas with high input of terrestrial matters.","1558-0644","","10.1109/TGRS.2015.2468054","International S&T Cooperation Program of China(grant numbers:2012DFG21710); National Natural Science Foundation of China(grant numbers:41371356,41331171); National High Technology Research and Development Program of China(grant numbers:2013AA122801); China Postdoctoral Science Foundation(grant numbers:2014M550025); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7236898","Ocean water albedo (OWA);sun glint;water-leaving reflectance;whitecaps;Ocean water albedo (OWA);sun glint;water-leaving reflectance;whitecaps","Open wireless architecture;Sea surface;Wind speed;Remote sensing;Sea measurements;Biological system modeling","","41","","83","OAPA","2 Sep 2015","","","IEEE","IEEE Journals"
"Component-Based Microservices for Flexible and Scalable Automation of Industrial Bioprocesses","V. Ibarra-Junquera; A. González; C. M. Paredes; D. Martínez-Castro; R. A. Nuñez-Vizcaino","Laboratorio de Agrobiotecnología, Universidad de Colima, Coquimatlán, México; Laboratorio de Agrobiotecnología, Universidad de Colima, Coquimatlán, México; Facultad de Ingeniería, Universidad Autónoma de Occidente, Cali, Colombia; Facultad de Ingeniería, Universidad Autónoma de Occidente, Cali, Colombia; Facultad de Ingeniería Mecánica y Eléctrica, Universidad de Colima, Coquimatlán, México",IEEE Access,"19 Apr 2021","2021","9","","58192","58207","Industry 4.0 involves the digital transformation of the industry with the integration and digitization of all industrial processes that make up the value chain, which is characterized by adaptability, flexibility, and efficiency to meet the needs of customers in today's market. Therefore, the adaptations of the new bioprocess industry require a lot of flexibility to react quickly and constantly to market changes and to be able to offer more specialized, customized products with high operational efficiency. This paper presents a flexible, scalable, and robust framework based on software components, container technology, microservice concepts, and the publish/subscribe paradigm. This framework allows new components to be added or removed online, without the need for system reconfiguration, while maintaining temporal and functional constraints in industrial automation systems. The main objective of the framework proposed is the use of components based on microservices, allowing easy implementation, scalability, and fast maintenance, without losing or degrading the robustness from previous developments. Finally, the effectiveness of the proposed framework was verified in two case studies (1) a soursop soda making process is presented, with a fuzzy controller implemented to keep the pasteurizer output flow constant (UHT) and (2) an automatic storage tank selection and filling process with actuated valves to direct the fluid to the corresponding tank at the time to start the process. The results showed that the platform provided a high-fidelity design, analysis, and testing environment for the flow of cyber information and its effect on the physical operation in a beverage processing plant with high demand for flexibility, scalability, and robustness of its processes, as they were experimentally verified in a real production process.","2169-3536","","10.1109/ACCESS.2021.3072040","Research Cooperation between the Universidad de Colima (Mexico), the Universidad Autónoma de Occidente (Colombia), and the Juice Production Plant Punta Delicia, Colima, Mexico; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9399423","Industry 40;distributed industrial automation systems;interoperability;middleware;industrial cyber-physical systems","Computer architecture;Scalability;Containers;Industries;Real-time systems;Production;Process control","","11","","30","CCBY","9 Apr 2021","","","IEEE","IEEE Journals"
"Neuromorphic In-Memory RRAM NAND/NOR Circuit Performance Analysis in a CNN Training Framework on the Edge for Low Power IoT","N. L. Prabhu; N. Raghavan","Engineering Product Development (EPD) Pillar, Singapore University of Technology and Design, Tampines, Singapore; Engineering Product Development (EPD) Pillar, Singapore University of Technology and Design, Tampines, Singapore",IEEE Access,"6 Dec 2022","2022","10","","125112","125135","Training a CNN involves computationally intense optimization algorithms to fit the network using a training dataset, to update the network weight for inferencing and then pattern classification. Hence, the application of in-memory computation would enable a highly power-efficient low latency on-the-edge CNN training technique by avoiding the memory-wall created during the external memory read/write operation (for off chip instruction and data transfer). A memory write-verify, and re-program technique can control the RRAM variability. Still, memory verification and re-program is a complex process with additional resources needed for practical implementation of verification circuit. In this study, we have demonstrated a practical (First-in Max-Out) FIMO-based cache memory called Maximum Count Binary Comparator Layer (MCBC), using 1T3R, 1T5R, and 1T7R RRAM structures by using a probability-based accuracy improvement architecture, without the conventional verification process. We constructed 10 layered modified MobileNET with filter size ranging from 32 - 512 and trained with Traffic Sign Recognition Database (TSRD) using a three-tier abstraction simulation learning framework - (1) High level, 10 layered CNN implementation with Python+TensorFlow; (2) Verilog HDL based FP32MUL and FP32ADD (32-bits Floating Point adder and multiplier) circuits constructed with RRAM NAND gates using 1T2R structures; and (3) Digital Look-Up-Table (LUT) model for RRAM variability. An edge learning framework (for the forward pass) is demonstrated using digital RRAM-NAND/NOR universal gates integrated with the Maximum Count Binary Comparator Layer (MCBC) to partially circumvent the impact of RRAM variability and to quantify the RRAM variability on the CNN training prediction accuracy for 65nm CMOS OxRAM (TiN/HfO2/Hf/TiN) with varying device current compliance of 5, 10, and  $50\mu \text{A}$  for low power IoT applications. The MCBC layer was simulated using a SPICE model, for which the estimated chip layout is  $1150\times 1230$  nm2 per logical gate input, which resulted in an overall prediction accuracy improvement from 10% to 60% by repeating the logical operations of the NOR gate for {1, 3, 5, and 7} cycles respectively.","2169-3536","","10.1109/ACCESS.2022.3219066","A*STAR through the Brain Efficient Nanomechanical Artificial Intelligence Computing (BRENAIC) Programmatic Research(grant numbers:A18A5b0056); Ministry of Education (MOE), Singapore, through the Research Student Scholarship (RSS) at SUTD (2018–2022); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9936672","Resistive RAM;convolution neural network (CNN);look-up-table (LUT);in-memory computation;image classification;CNN training;Internet of Things (IoT);complementary metal oxide semiconductor (CMOS)","Internet of Things;Computational modeling;Switches;Deep learning;Computer architecture;Mathematical models;Data models;Neuromorphics;Convolutional neural networks;Random access memory;Training data","","1","","49","CCBY","3 Nov 2022","","","IEEE","IEEE Journals"
"NNPIM: A Processing In-Memory Architecture for Neural Network Acceleration","S. Gupta; M. Imani; H. Kaur; T. S. Rosing","Department of Computer Science and Engineering, University of California San Diego, La Jolla, CA, USA; Department of Computer Science and Engineering, University of California San Diego, La Jolla, CA, USA; Department of Computer Science and Engineering, University of California San Diego, La Jolla, CA, USA; Department of Computer Science and Engineering, University of California San Diego, La Jolla, CA, USA",IEEE Transactions on Computers,"7 Aug 2019","2019","68","9","1325","1337","Neural networks (NNs) have shown great ability to process emerging applications such as speech recognition, language recognition, image classification, video segmentation, and gaming. It is therefore important to make NNs efficient. Although attempts have been made to improve NNs' computation cost, the data movement between memory and processing cores is the main bottleneck for NNs' energy consumption and execution time. This makes the implementation of NNs significantly slower on traditional CPU/GPU cores. In this paper, we propose a novel processing in-memory architecture, called NNPIM, that significantly accelerates neural network's inference phase inside the memory. First, we design a crossbar memory architecture that supports fast addition, multiplication, and search operations inside the memory. Second, we introduce simple optimization techniques which significantly improves NNs' performance and reduces the overall energy consumption. We also map all NN functionalities using parallel in-memory components. To further improve the efficiency, our design supports weight sharing to reduce the number of computations in memory and consecutively speedup NNPIM computation. We compare the efficiency of our proposed NNPIM with GPU and the state-of-the-art PIM architectures. Our evaluation shows that our design can achieve 131.5× higher energy efficiency and is 48.2× faster as compared to NVIDIA GTX 1,080 GPU architecture. Compared to state-of-the-art neural network accelerators, NNPIM can achieve on an average 3.6× higher energy efficiency and is 4.6× faster, while providing the same classification accuracy.","1557-9956","","10.1109/TC.2019.2903055","CRISP; JUMP; DARPA; National Science Foundation(grant numbers:#1730158,#1527034); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8658117","Non-volatile memory;processing in-memory;neural networks","Artificial neural networks;Biological neural networks;Memory management;Acceleration;Computational modeling;Neurons","","41","","52","IEEE","4 Mar 2019","","","IEEE","IEEE Journals"
"Exploiting User-Generated Content in Product Launch Videos to Compute a Launch Score","S. D. Das; P. K. Bala; S. Das","Indian Institute of Management Ranchi, Ranchi, India; Indian Institute of Management Ranchi, Ranchi, India; Department of Artificial Intelligence and Data Science, Faculty of Science and Technology (IcfaiTech), The ICFAI Foundation for Higher Education, Hyderabad, Telangana, India",IEEE Access,"10 Apr 2024","2024","12","","49624","49639","This study investigated the relationship between the essential aspects of user-generated content (UGC) and product launch videos to derive the product launch score (PLS). This score can be considered a key performance indicator (KPI) to evaluate the performance of product launch videos. The product launch score can provide businesses and marketers with insights into how well the community and audience perceive a product launch on virtual social media platforms such as YouTube. The authors examined 52 product launch videos with a total of 1,11,716 comments on YouTube and analyzed the data to derive various sentimental, emotional, and social networking aspects from the comments on the product launch videos. Furthermore, the relationship between brand and product mentions was evaluated to determine the centrality of the launch activity. The work determined how effectively the community was engaged with the brand and product launch. Finally, relationship analysis and principal component analysis (PCA) were performed to select relevant aspects for calculating the PLS. This KPI provides a holistic view of user engagement in product launch videos.","2169-3536","","10.1109/ACCESS.2024.3381541","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10478487","Text mining;social networks;emotions analysis;word-of-mouth;analytic models;marketing analytics","Social networking (online);Web sites;Video on demand;Videos;Companies;Key performance indicator;User-generated content;Text mining;Emotion recognition;Analytical models;Market research","","","","82","CCBYNCND","27 Mar 2024","","","IEEE","IEEE Journals"
"Information Leakage Analysis Using a Co-Design-Based Fault Injection Technique on a RISC-V Microprocessor","J. Plusquellic; D. E. Owen; T. J. Mannos; B. Dziki","Department of Electrical and Computer Engineering, University of New Mexico, Albuquerque, NM, USA; Department of Electrical and Computer Engineering, University of New Mexico, Albuquerque, NM, USA; Advanced CMOS Products/Design, Sandia National Labs, Albuquerque, NM, USA; Department of Defense, Information Assurance Research, Fort G. G. Meade, MD, USA",IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems,"18 Feb 2022","2022","41","3","438","451","The RISC-V instruction set architecture open licensing policy has spawned a hive of development activity, making a range of implementations publicly available. The environments in which RISC-V operates have expanded correspondingly, driving the need for a generalized approach to evaluating the reliability of RISC-V implementations under adverse operating conditions or after normal wear-out periods. Fault injection (FI) refers to the process of changing the state of registers or wires, either permanently or momentarily, and then observing execution behavior. The analysis provides insight into the development of countermeasures that protect against the leakage or corruption of sensitive information, which might occur because of unexpected execution behavior. In this article, we develop a hardware–software co-design architecture that enables fast, configurable fault emulation and utilize it for information leakage and data corruption analysis. Modern system-on-chip FPGAs enable building an evaluation platform, where control elements run on a processor(s) (PS) simultaneously with the target design running in the programmable logic (PL). Software components of the FI system introduce faults and report execution behavior. A pair of RISC-V FI-instrumented implementations are created and configured to execute the Advanced Encryption Standard and Twister algorithms. Key and plaintext information leakage and degraded pseudorandom sequences are both observed in the output for a subset of the emulated faults.","1937-4151","","10.1109/TCAD.2021.3065915","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9380709","Fault analysis;fault emulation (FE);FPGA;RISC-V","Circuit faults;Field programmable gate arrays;Emulation;Transient analysis;Microprocessors;Instruments;Logic gates","","7","","32","IEEE","17 Mar 2021","","","IEEE","IEEE Journals"
"Compact and Computationally Efficient Representation of Deep Neural Networks","S. Wiedemann; K. -R. Müller; W. Samek","Fraunhofer Heinrich Hertz Institute, Berlin, Germany; Technische Universität Berlin, Berlin, Germany; Fraunhofer Heinrich Hertz Institute, Berlin, Germany",IEEE Transactions on Neural Networks and Learning Systems,"28 Feb 2020","2020","31","3","772","785","At the core of any inference procedure, deep neural networks are dot product operations, which are the component that requires the highest computational resources. For instance, deep neural networks, such as VGG-16, require up to 15-G operations in order to perform the dot products present in a single forward pass, which results in significant energy consumption and thus limits their use in resource-limited environments, e.g., on embedded devices or smartphones. One common approach to reduce the complexity of the inference is to prune and quantize the weight matrices of the neural network. Usually, this results in matrices whose entropy values are low, as measured relative to the empirical probability mass distribution of its elements. In order to efficiently exploit such matrices, one usually relies on, inter alia, sparse matrix representations. However, most of these common matrix storage formats make strong statistical assumptions about the distribution of the elements; therefore, cannot efficiently represent the entire set of matrices that exhibit low-entropy statistics (thus, the entire set of compressed neural network weight matrices). In this paper, we address this issue and present new efficient representations for matrices with low-entropy statistics. Alike sparse matrix data structures, these formats exploit the statistical properties of the data in order to reduce the size and execution complexity. Moreover, we show that the proposed data structures can not only be regarded as a generalization of sparse formats but are also more energy and time efficient under practically relevant assumptions. Finally, we test the storage requirements and execution performance of the proposed formats on compressed neural networks and compare them to dense and sparse representations. We experimentally show that we are able to attain up to  $\times 42$  compression ratios,  $\times 5$  speed ups, and  $\times 90$  energy savings when we lossless convert the state-of-the-art networks, such as AlexNet, VGG-16, ResNet152, and DenseNet, into the new data structures and benchmark their respective dot product.","2162-2388","","10.1109/TNNLS.2019.2910073","Fraunhofer Society through the MPI-FhG collaboration project “Theory and Practice for Reduced Learning Machines,”; Bundesministerium für Bildung und Forschung(grant numbers:01IS14013A); Bundesministerium für Bildung und Forschung(grant numbers:01IS18037I); Deutsche Forschungsgemeinschaft(grant numbers:390685689); Information and Communications Technology Planning and Evaluation (IITP) Grant; Korean Government(grant numbers:2017-0-00451); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8725933","Computationally efficient deep learning;data structures;lossless coding;neural network compression;sparse matrices","Sparse matrices;Data structures;Entropy;Biological neural networks;Complexity theory;Quantization (signal)","Deep Learning;Entropy;Neural Networks, Computer","51","","59","CCBY","29 May 2019","","","IEEE","IEEE Journals"
"A Blockchain-Based Application System for Product Anti-Counterfeiting","J. Ma; S. -Y. Lin; X. Chen; H. -M. Sun; Y. -C. Chen; H. Wang","Fujian Provincial Key Laboratory of Network Security and Cryptology, College of Mathematics and Informatics, Fujian Normal University, Fuzhou, China; Department of Computer Science, National Tsing Hua University, Hsinchu, Taiwan; Fujian Provincial Key Laboratory of Network Security and Cryptology, College of Mathematics and Informatics, Fujian Normal University, Fuzhou, China; Department of Computer Science, National Tsing Hua University, Hsinchu, Taiwan; Department of Computer Science, University of California at Davis, Davis, USA; Division of Mathematical Sciences, School of Physical and Mathematical Sciences, Nanyang Technological University, Singapore",IEEE Access,"8 May 2020","2020","8","","77642","77652","In recent years, blockchain has received increasing attention and numerous applications have emerged from this technology. A renowned Blockchain application is the cryptocurrency Bitcoin, that has not only been effectively solving the double-spending problem but also it can confirm the legitimacy of transactional records without relying on a centralized system to do so. Therefore, any application using Blockchain technology as the base architecture ensures that the contents of its data are tamper-proof. This paper uses the decentralized Blockchain technology approach to ensure that consumers do not fully rely on the merchants to determine if products are genuine. We describe a decentralized Blockchain system with products anti-counterfeiting, in that way manufacturers can use this system to provide genuine products without having to manage direct-operated stores, which can significantly reduce the cost of product quality assurance.","2169-3536","","10.1109/ACCESS.2020.2972026","National Natural Science Foundation of China(grant numbers:61872089,61902070,61972094); Ministry of Science and Technology of the Republic of China(grant numbers:MOST 106-2221-E-007-026-MY3,MOST 107-2221-E-007-015-MY3,MOST 108-2218E001-001); National Research Foundation, Prime Minister’s Office, Singapore under its Strategic Capability Research Centres Funding Initiative and Singapore Ministry of Education under Research(grant numbers:MOE2016-T2-2-014(S)); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8985337","Blockchain;ethereum;counterfeit","Blockchain;Bitcoin;Smart contracts;Online banking;Companies;Supply chains","","57","","29","CCBY","6 Feb 2020","","","IEEE","IEEE Journals"
"Hybrid Accumulator Factored Systolic Array for Machine Learning Acceleration","K. Inayat; J. Chung","Department of Electronics Engineering, Incheon National University, Incheon, South Korea; Department of Electronics Engineering, Incheon National University, Incheon, South Korea",IEEE Transactions on Very Large Scale Integration (VLSI) Systems,"28 Jun 2022","2022","30","7","881","892","Deep learning applications have become ubiquitous in today’s era and it has led to vast development in machine learning (ML) accelerators. Systolic arrays have been a primary part of ML accelerator architecture. To fully leverage the systolic arrays, it is required to explore the computer arithmetic data-path components and their tradeoffs in accelerators. We present a novel factored systolic array (FSA) architecture, in which the carry propagation adder (CPA) and carry-save adder (CSA) perform hybrid accumulation on least significant bit (LSB) bits and most significant bits (MSB) bits, respectively, inside each processing element. In addition, a small CPA to complete accumulation for MSB bits along with rounding logic for each column of the array is placed, which not only reduces the area, delay, and power but also balances the combinational and sequential area tradeoffs. We demonstrate the hybrid accumulator with partial CPA factoring in “Gemmini,” an open-source practical systolic array accelerator and factoring technique does not change the functionality of the base design. We implemented three baselines, original Gemmini and two variants of it, and show that the proposed approach leads to overall significant reduction in area within the range 12.8% – 50.2% and in power within the range 18.6% – 41% with improved or similar delay in comparison to the baselines.","1557-9999","","10.1109/TVLSI.2022.3170233","Software Systems for AI Semiconductor Design Project(grant numbers:2021-0-00754); Neuromorphic Computing Software Platform for Artificial Intelligence Systems Project through the Institute of Information and Communications Technology Planning and Evaluation (IITP)(grant numbers:2018-0-00769); Korea Government Ministry of Science and Information Communication Technology (MSIT); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9773321","Accelerator;factorization;Gemmini;machine learning;systolic array","Systolic arrays;Delays;Adders;Power demand;Computer architecture;Tensors;System-on-chip","","13","","47","IEEE","12 May 2022","","","IEEE","IEEE Journals"
"Hybrid Particle Filter Trained Neural Network for Prognosis of Lithium-Ion Batteries","K. Pugalenthi; H. Park; S. Hussain; N. Raghavan","Engineering Product Development Pillar, Singapore University of Technology and Design, Singapore; Department of Information Systems, Hanyang University, Seoul, Republic of Korea; Computational Intelligence Group, A*STAR Institute of High Performance Computing (IHPC), Singapore; Engineering Product Development Pillar, Singapore University of Technology and Design, Singapore",IEEE Access,"7 Oct 2021","2021","9","","135132","135143","Prognostics and Health Management (PHM) plays a key role in Industry 4.0 revolution by providing smart predictive maintenance solutions. Early failure detection and prediction of remaining useful life (RUL) of critical industrial machines/components are the main challenges addressed by PHM methodologies. In literature, model-based and data-driven methods are widely used for RUL estimation. Model-based methods rely on empirical/phenomenological degradation models for RUL prediction using Bayesian formulations. In many cases, the lack of accurate physics-based models emphasizes the need to resort to machine learning based prognostic algorithms. However, data-driven methods require extensive machine failure data incorporating all possible operating conditions along with all possible failure modes pertaining to that particular machine/component, which are seldom available in their entirety. In this work, we propose a three-stage hybrid prognostic algorithm (HyA) combining model-based (Particle Filters-PF) and data-driven (Neural Networks-NN) methods in a unique way. The proposed method aims to overcome the need for accurate degradation modeling or extensive failure data sets. In the first stage, a feedforward neural network is used to formulate lithium-ion battery’s degradation trends and the corresponding NN model parameters are used to define the initial prior distribution of PF algorithm. In the second stage, the PF algorithm optimizes the model parameters and the posterior model parameter distributions are utilized to ‘warm-start’ the neural network used for prognosis and the third/final stages focuses on prognosis and RUL estimation using the trained NN model leveraging on the posterior distributions of the PF fine-tuned weights and biases. The proposed method is demonstrated on CALCE and NASA lithium-ion battery capacity degradation datasets. The efficacy of the proposed hybrid algorithm is evaluated using root mean square error (RMSE) values and alpha-lambda prognostic metrics. Also, the impact of the NN architecture on the prediction accuracy and computational load are analyzed.","2169-3536","","10.1109/ACCESS.2021.3116264","Ministry of Education (MOE), Singapore, through the Research Student Scholarship (RSS)(grant numbers:2018–2021); Agency for Science, Technology and Research (A*STAR), Singapore, through the Explainable Physics-Based AI Program (ePAI) under Programmatic Proposal(grant numbers:A20H5b0142,IGIPAMD1801); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9551933","Hybrid prognostic algorithm;particle filters;neural networks;remaining useful life;lithium-ion batteries","Degradation;Artificial neural networks;Prediction algorithms;Data models;Prognostics and health management;Predictive models;Lithium-ion batteries","","11","","27","CCBY","29 Sep 2021","","","IEEE","IEEE Journals"
"PR-Transformer: Long-Term Prediction of Train Wheel Diameters Using Progressive Refinement Transformer","Q. Zhang; J. Ding; K. Wang","State Key Laboratory of Rail Transit Vehicle System, Southwest Jiaotong University, Chengdu, China; State Key Laboratory of Rail Transit Vehicle System, Southwest Jiaotong University, Chengdu, China; State Key Laboratory of Rail Transit Vehicle System, Southwest Jiaotong University, Chengdu, China",IEEE Transactions on Instrumentation and Measurement,"15 Oct 2024","2024","73","","1","11","Massive amounts of wheel diameter data can be collected from the trackside wheel detection subsystem, providing a feasible way for developing a data-driven model for wheel diameter prediction. To address this issue, a novel wheel diameter prediction model, named progressive refinement transformer (PR-Transformer), which combines time embedding and data decomposition, is proposed. Time embedding encodes temporal information into the model, offering precise temporal context regarding wheel diameter changes and enabling the model to better understand the potential dependencies between time and wheel diameter wear. Data decomposition partitions the wheel diameter data into seasonal and trend components, simplifying each component and making them more predictable. The PR-Transformer, which adopts an encoder-decoder architecture, is designed to extract long-term dependencies using scaled dot-product attention (SDPA) and multihead attention (MHA) mechanisms. It progressively refines its predictions by integrating information from both the encoder and decoder. Results indicate that the PR-Transformer achieves minimal mean squared error (MSE) and mean absolute error (MAE) across various wheel diameter datasets, surpassing other state-of-the-art models and demonstrating its potential as a robust tool for wheel diameter prediction.","1557-9662","","10.1109/TIM.2024.3470949","National Natural Science Foundation of China(grant numbers:52388102); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10700789","Rail vehicle;time-series analysis;time-series decomposition;transformer;wheel diameter prediction","Wheels;Predictive models;Data models;Transformers;Numerical models;Market research;Prediction algorithms;Feature extraction;Data mining;Vibrations","","","","34","IEEE","30 Sep 2024","","","IEEE","IEEE Journals"
"A Values-Driven Cyber-Farm of Trigram Metaverse Based on Autonomic Crowd-Dispatching","Y. Li","School of Computer Science, Fudan University, Shanghai, China",International Journal of Crowd Science,"22 Dec 2023","2023","7","4","200","211","The objective of this work is to apply cutting-edge digital techniques to address several identified essential problems, from which farmers, farming, and farms have suffered for centuries. It has been found that the participants in the metaverse-related agricultural applications have been designed to be users rather than residents. There is another critical setback for the metaverse to be a fusion cyber-physical space, in which the cyber space is subject to different values principles from the physical space. A trigram metaverse of Cyber-Farm is proposed to be constructed on a unified trigram space through the fusion of cyber, physical, and values spaces. As a parallel and superstructure to the cyber and physical spaces, the values space enables the cyber space and physical space to follow the same values principles through its autonomic, values-driven, and crowd-dispatching governance system. Unlike in the existing metaverse-related agricultural applications, the Cyber-Farm participants are the subjects/residents rather than the users of a Cyber-Farm. The agricultural elements are coming into being and evolving in the interlinked and fusion trigram space. The basic production means, production relations, and superstructure of the trigram metaverse have been discussed. Both the connotations and scopes of farm, farmer, and farming have been redefined in the trigram metaverse of Cyber-Farm. The intentions, scenarios, principles, and businesses of the Cyber-Farm have been restructured. Basically, the Cyber-Farm can address the identified essential problems with today's agriculture, while a grand vision is to bring about farm-featured Utopias parallel to human communities.","2398-7294","","10.26599/IJCS.2023.9100027","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10371288","metaverse;digital agriculture;cyber space;digital twin;crowd intelligence science","Systematics;Metaverse;Green products;Prototypes;Collaboration;Production;Vegetation","","","","30","","22 Dec 2023","","","TUP","TUP Journals"
"LSTM-CRF Neural Network With Gated Self Attention for Chinese NER","Y. Jin; J. Xie; W. Guo; C. Luo; D. Wu; R. Wang","Key Laboratory of Specialty Fiber Optics and Optical Access Networks, Joint International Research Laboratory of Specialty Fiber Optics and Advanced Communication, Shanghai Institute for Advanced Communication and Data Science, Shanghai University, Shanghai, China; Key Laboratory of Specialty Fiber Optics and Optical Access Networks, Joint International Research Laboratory of Specialty Fiber Optics and Advanced Communication, Shanghai Institute for Advanced Communication and Data Science, Shanghai University, Shanghai, China; School of Engineering, University of Warwick, Coventry, U.K.; Key Laboratory of Specialty Fiber Optics and Optical Access Networks, Joint International Research Laboratory of Specialty Fiber Optics and Advanced Communication, Shanghai Institute for Advanced Communication and Data Science, Shanghai University, Shanghai, China; Key Laboratory of Specialty Fiber Optics and Optical Access Networks, Joint International Research Laboratory of Specialty Fiber Optics and Advanced Communication, Shanghai Institute for Advanced Communication and Data Science, Shanghai University, Shanghai, China; Key Laboratory of Specialty Fiber Optics and Optical Access Networks, Joint International Research Laboratory of Specialty Fiber Optics and Advanced Communication, Shanghai Institute for Advanced Communication and Data Science, Shanghai University, Shanghai, China",IEEE Access,"30 Sep 2019","2019","7","","136694","136703","Named entity recognition (NER) is an essential part of natural language processing tasks. Chinese NER task is different from the many European languages due to the lack of natural delimiters. Therefore, Chinese Word Segmentation (CWS) is usually regarded as the first step of processing Chinese NER. However, the word-based NER models relying on CWS are more vulnerable to incorrectly segmented entity boundaries and the presence of out-of-vocabulary (OOV) words. In this paper, we propose a novel character-based Gated Convolutional Recurrent neural network with Attention called GCRA for Chinese NER task. In particular, we introduce a hybrid convolutional neural network with gating filter mechanism to capture local context information and a highway neural network after LSTM to select characters of interest. The additional gated self-attention mechanism is used to capture the global dependencies from different multiple subspaces and arbitrary adjacent characters. We evaluate the performance of our proposed model on three datasets, including SIGHAN bakeoff 2006 MSRA, Chinese Resume, and Literature NER dataset. The experiment results show that our model outperforms other state-of-the-art models without relying on any external resources like lexicons and multi-task joint training.","2169-3536","","10.1109/ACCESS.2019.2942433","NSFC, China(grant numbers:61771299); National Key Research and Development Program of China(grant numbers:2018YFB2101303); Shanghai University(grant numbers:SKLSFO2012-14); Key Laboratory of Wireless Sensor Network and Communication, Shanghai Institute of Microsystem and Information Technology; Chinese Academy of Sciences; Shanghai Science Committee(grant numbers:12511503303,14511105602,14511105902); H2020 European Institute of Innovation and Technology(grant numbers:778305); Innovate UK(grant numbers:10734); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8844740","Chinese NER;gating mechanism;highway neural network;self-attention","Task analysis;Hidden Markov models;Logic gates;Labeling;Feature extraction;Neural networks;Road transportation","","41","","45","CCBY","19 Sep 2019","","","IEEE","IEEE Journals"
"Enterprise storage software lifecycle management system","E. Butler; T. D. Griffin; D. Jadav; H. P. Petersen; A. A. Barabas",NA; NA; NA; NA; NA,IBM Journal of Research and Development,"14 Mar 2017","2017","61","1","10:110","10:120","Storage subsystems reside at the bottom-most layer of a contemporary data-center information technology (IT) stack. As with all other production software, the storage layer's embedded software (or firmware) must be constantly maintained in terms of upgrading it when new versions are released by hardware vendors. We study the problem of maintaining the currency of the storage software layer. We survey the typical processes that are used to keep storage firmware at recommended versions within a data center, and present an automated solution for this tedious and labor-intensive task. We present an approach to quantify the risk for continuing operations posed by stale firmware, a context-based approach for recommending target levels for devices with stale firmware, and an Upgrade Planner for rectifying the firmware of such devices. Our system has been deployed in the field using two approaches: as an operational tool used by hundreds of storage administrators within an outsourced IT context, and as an automated analytics component of an appliance-based approach within a maintenance services organization. We study the growth of the monitored infrastructure over two years. Finally, we show how our system drastically shrinks the time for an enterprise IT firmware upgrade cycle from days to minutes, and changes the nature of the complex task from a reactive to a proactive paradigm.","0018-8646","","10.1147/JRD.2016.2636758","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7877286","","Software development;Databases;Servers;Computer architecture;Product life cycle management;Outsourcing;Storage automation","","","","35","IBM","14 Mar 2017","","","IBM","IBM Journals"
"Tiny Machine Learning for High Accuracy Product Quality Inspection","A. Albanese; M. Nardello; G. Fiacco; D. Brunelli","Department of Industrial Engineering, University of Trento, Trento, Italy; Department of Industrial Engineering, University of Trento, Trento, Italy; Department of Industrial Engineering, University of Trento, Trento, Italy; Department of Industrial Engineering, University of Trento, Trento, Italy",IEEE Sensors Journal,"13 Jan 2023","2023","23","2","1575","1583","The quality inspection of industrial products is a fundamental step in large-scale production as it boosts the yield and reduces the costs. Intelligent embedded platforms with built-in tiny machine learning (tinyML) algorithms and cameras can automate quality inspection; however, running complex deep learning algorithms in low-cost and low-power embedded devices is still challenging because of limited memory and energy resources. This article presents an innovative sensor system with three microcontroller unit (MCU)-based tinyML cameras capable of automatic artifact and anomaly detection in plastic components. The system consists of a top camera responsible for identifying shape defects and two side cameras for color anomalies. Data processing is executed locally with tinyML reducing data transmission to a few bytes. Two state-of-the-art convolutional neural network (CNN) architectures are evaluated, namely, MobileNetV2 and SqueezeNet. Results show how both the architectures—with appropriate compression techniques—are suitable to be evaluated by resource-constrained microcontrollers. The networks achieve 99% classification accuracy while maintaining suitable real-time performance, respectively, equal to 5 and 2 frames/s.","1558-1748","","10.1109/JSEN.2022.3225227","STMicroelectronics, Italy; Rosa Micro srl, Ceggia, Italy; European Union under NextGenerationEU; Project “INEST-Interconnected Nord-Est Innovation”; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9969601","Edge processing;Industrial Internet of Things (I-IoT);Industry 4.0;tiny machine learning (tinyML);visual inspection","Cameras;Inspection;Sensors;Visualization;Cloud computing;Belts;Production","","17","","24","IEEE","2 Dec 2022","","","IEEE","IEEE Journals"
"Multi-Aspect + Transitivity + Bias: An Integral Trust Inference Model","Y. Yao; H. Tong; X. Yan; F. Xu; J. Lu","State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; School of Computing, Informatics, Decision Systems Engineering, Arizona State University, Phoenix, AZ, USA; University of California at Santa Barbara, Santa Barbara, CA, USA; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China",IEEE Transactions on Knowledge and Data Engineering,"9 Jul 2014","2014","26","7","1706","1719","Inferring the pair-wise trust relationship is a core building block for many real applications. State-of-the-art approaches for such trust inference mainly employ the transitivity property of trust by propagating trust along connected users, but largely ignore other important properties such as trust bias, multi-aspect, etc. In this paper, we propose a new trust inference model to integrate all these important properties. To apply the model to both binary and continuous inference scenarios, we further propose a family of effective and efficient algorithms. Extensive experimental evaluations on real data sets show that our method achieves significant improvement over several existing benchmark approaches, for both quantifying numerical trustworthiness scores and predicting binary trust/distrust signs. In addition, it enjoys linear scalability in both time and space.","1558-2191","","10.1109/TKDE.2013.147","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6585254","Data mining;Knowledge management applications;Trust inference;trust prediction;transitivity property;multi-aspect property;latent factors;trust bias","Inference algorithms;Vectors;Collaboration;Optimization;Knowledge discovery;Computational modeling;Couplings","","5","","41","IEEE","23 Aug 2013","","","IEEE","IEEE Journals"
"Monolithic 3D-Based SRAM/MRAM Hybrid Memory for an Energy-Efficient Unified L2 TLB-Cache Architecture","Y. -H. Gong","School of Computer and Information Engineering, Kwangwoon University, Seoul, Republic of Korea",IEEE Access,"17 Feb 2021","2021","9","","18915","18926","Monolithic 3D (M3D) integration has been emerged as a promising technology for fine-grained 3D stacking. As the M3D integration offers extremely small dimension of via in a nanometer-scale, it is beneficial for small microarchitectural blocks such as caches, register files, translation look-aside buffers (TLBs), etc. However, since the M3D integration requires low-temperature process for stacked layers, it causes lower performance for stacked transistors compared to the conventional 2D process. In contrast, non-volatile memory (NVM) such as magnetic RAM (MRAM) is originally fabricated at a low temperature, which enables the M3D integration without performance degradation. In this paper, we propose an energy-efficient unified L2 TLB-cache architecture exploiting M3D-based SRAM/MRAM hybrid memory. Since the M3D-based SRAM/MRAM hybrid memory consumes much smaller energy than the conventional 2D SRAM-only memory and 2D SRAM/MRAM hybrid memory, while providing comparable performance, our proposed architecture improves energy efficiency significantly. Especially, as our proposed architecture changes the memory partitioning of the unified L2 TLB-cache depending on the L2 cache miss rate, it maximizes the energy efficiency for parallel workloads suffering extremely high L2 cache miss rate. According to our analysis using PARSEC benchmark applications, our proposed architecture reduces the energy consumption of L2 TLB + L2 cache by up to 97.7% (53.6% on average), compared to the baseline with the 2D SRAM-only memory, with negligible impact on performance. Furthermore, our proposed technique reduces the memory access energy consumption by up to 32.8% (10.9% on average), by reducing memory accesses due to TLB misses.","2169-3536","","10.1109/ACCESS.2021.3054021","Research Grant of Kwangwoon University in 2020; National Research Foundation of Korea (NRF); Korea government (MSIT)(grant numbers:NRF-2020R1G1A1100040); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9334969","Monolithic 3D;cache memory;translation look-aside buffer;SRAM;MRAM;energy efficiency","Three-dimensional displays;Random access memory;Through-silicon vias;Memory management;Transistors;Stacking;Two dimensional displays","","6","","42","CCBY","25 Jan 2021","","","IEEE","IEEE Journals"
"Toward the Internet of Things for Physical Internet: Perspectives and Challenges","H. Tran-Dang; N. Krommenacker; P. Charpentier; D. -S. Kim","Department of IT Convergence Engineering, Kumoh National Institute of Technology, Gumi, South Korea; Center Research on Automatic Control in Nancy, University of Lorraine, Vandoeuvre-lès-Nancy, France; Center Research on Automatic Control in Nancy, University of Lorraine, Vandoeuvre-lès-Nancy, France; Department of IT Convergence Engineering, Kumoh National Institute of Technology, Gumi, South Korea",IEEE Internet of Things Journal,"12 Jun 2020","2020","7","6","4711","4736","The Physical Internet (PI, or π) paradigm has been developed to be a global logistics system that aims to move, handle, store, and transport logistics products in a sustainable and efficient way. To achieve the goal, the PI requires a high-level interconnectivity in the physical, informational, and operational aspects enabled by an interconnected network of intermodal hubs, collaborative protocols, and standardized, modular, and smart containers. In this context, PI is a key player poised to benefit from the Internet-of-Things (IoT) revolution since it potentially provides an end-to-end visibility of the PI objects, operations, and systems through ubiquitous information exchange. This article is to investigate opportunities of application of the IoT technology in the PI vision. In addition, an IoT ecosystem (π-IoT) encompassing key enabling IoT technologies, building blocks, and a service-oriented architecture (SoA) is proposed as a potential component for accelerating the implementation of PI. The major challenges regarding the deployment of IoT into the emerging logistics concept are also discussed intensively for further research.","2327-4662","","10.1109/JIOT.2020.2971736","Priority Research Centers Program through the National Research Foundation of Korea; Ministry of Education, Science and Technology(grant numbers:2018R1A6A1A03024003); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8984361","Internet of Things (IoT);IoT services;IoT technologies;logistics operations;logistics system;Physical Internet (PI);service-oriented architecture (SoA);sustainability","Internet of Things;Logistics;Protocols;Sensors;Containers;Ecosystems","","134","","202","IEEE","5 Feb 2020","","","IEEE","IEEE Journals"
"A Heterogeneous Access Metamodel for Efficient IoT Remote Sensing Observation Management: Taking Precision Agriculture as an Example","L. Zhou; W. Tu; C. Wang; Q. Li","School of Civil Engineering, Chongqing Jiaotong University, Chongqing, China; Guangdong Key Laboratory of Urban Informatics, School of Architecture and Urban Planning, Shenzhen University, Shenzhen, China; Guangdong Key Laboratory of Urban Informatics, School of Architecture and Urban Planning, Shenzhen University, Shenzhen, China; Shenzhen Key Laboratory of Spatial Smart Sensing and Services, Shenzhen University, Shenzhen, China",IEEE Internet of Things Journal,"23 May 2022","2022","9","11","8616","8632","Standard remote sensing observation (RSO) access and formulization is essential to Internet of Things (IoT) data management, such as in precision agriculture (PA). Because of the heterogeneous characteristics and the petabyte data size of RSO, massive remote sensing processing in RSO management has been hampered. Here, we present a heterogeneous access metamodel for efficient RSO management (HAMERM) and verify it in PA. The structure of basic metadata components is defined. A five-tuple metadata structure based on the metaobject facility is designed. HAMERM consists of identification, platform, observation, product, and access, which represent the five aspects of RSO metadata information. In addition, the flatMap/reduceByKey algorithms and the table structure have been proposed under Sensor Web and Geographic Information Science (GIS) techniques. Intensive experiments in Guangdong Province, China are conducted to test the proposed method. Two RSO metadata formulization instances were conducted to examine the ability of sheltering the differences of multisource and heterogeneous RSO. Experiments containing data storage and data soil moisture (SM) mapping were performed. The results suggest that the HAMERM method achieved a performance 30.1 times higher than that of Hadoop and three times higher than that of Spark (stand-alone). Consequently, the proposed HAMERM can be applied to achieve efficient SM mapping within PA, which is helpful for efficient RSO management for the IoT.","2327-4662","","10.1109/JIOT.2021.3118024","National Key Research and Development Program of China(grant numbers:2019YFB2103104); National Nature Science Foundation of China (NSFC) Program(grant numbers:42071360,41974006,42001324); Department of Education of Guangdong Province(grant numbers:2018KTSCX196); Shenzhen Scientific Research and Development Funding Program(grant numbers:20200812164904001); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9560714","Geographic information science (GIS);heterogeneity;Internet of Things (IoT) remote sensing observation (RSO) management;metaobject facility;RSO metadata representation model;sensor Web","Metadata;Internet of Things;Standards;Encoding;Robot sensing systems;Computer architecture;XML","","7","","71","IEEE","6 Oct 2021","","","IEEE","IEEE Journals"
"Multiscale Analysis of the Aging Process of Cable Insulation","X. Hua; L. Wang; S. Yang","Department of Electrical Engineering, Nanjing University of Aeronautics and Astronautics (NUAA), Nanjing, China; Department of Electrical Engineering, Nanjing University of Aeronautics and Astronautics (NUAA), Nanjing, China; Department of Electrical Engineering, Nanjing University of Aeronautics and Astronautics (NUAA), Nanjing, China",IEEE Transactions on Dielectrics and Electrical Insulation,"26 Jan 2023","2023","30","1","238","246","Cables, transmitting both power and signal, are essential in electric power systems. Due to the combined effect of electromagnetic and thermal fields, cable insulation aging starts from the destruction of polymer molecular structure and deteriorates in the form of insulation defects, resulting in the degradation of cables eventually. In this article, multiscale simulation is implemented to comprehensively analyze the insulation aging mechanism and reveal the variation law of aging characteristics. Regarding multiscales, by molecular dynamics (MD) simulation and finite-element method (FEM), the material and electrical parameters are calculated and quantitatively analyzed. According to the findings, tiny molecular products resulting from thermal and electrical aging are the main causes of dielectric constant and electrical conductivity variations. Field distribution inside the cable is distorted due to the degradation of material parameters, thus changing power loss and electrical parameters. The multiscale analysis method in this article can make the cable insulation aging analysis more time- and resource-efficient, providing the theoretical basis and data support for cable fault diagnosis and remaining useful life prediction.","1558-4135","","10.1109/TDEI.2022.3217425","National Natural Science Foundation of China(grant numbers:51877102,52277187); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9930811","Finite-element method (FEM);insulation aging;molecular dynamics (MD) simulation;multiscale analysis","Aging;Power cables;Power cable insulation;Analytical models;Finite element analysis;Mathematical models;Computational modeling","","3","","35","IEEE","26 Oct 2022","","","IEEE","IEEE Journals"
"SquASH: Approximate Square-Accumulate With Self-Healing","G. A. Gillani; M. A. Hanif; M. Krone; S. H. Gerez; M. Shafique; A. B. J. Kokkeler","Universiteit Twente, Enschede, Overijssel, NL; Technische Universitat Wien, Wien, Wien, AT; Universiteit Twente, Enschede, Overijssel, NL; Universiteit Twente, Enschede, Overijssel, NL; Technische Universitat Wien, Wien, Wien, AT; Universiteit Twente, Enschede, Overijssel, NL",IEEE Access,"20 Sep 2018","2018","6","","49112","49128","Approximate computing strives to achieve the highest performance-, area-, and power-efficiency for a given quality constraint and vice versa. Conventional approximate design methodology restricts the introduction of errors to avoid a high loss in quality. However, this limits the computing efficiency and the number of pareto-optimal design alternatives for a quality-efficiency tradeoff. This paper presents a novel self-healing (SH) methodology for an approximate square-accumulate (SAC) architecture. SAC refers to a hardware architecture that computes the inner product of a vector with itself. SH exploits the algorithmic error resilience of the SAC structure to ensure an effective quality-efficiency tradeoff, wherein the squarer is regarded as an approximation stage, and the accumulator as a healing stage. We propose to deploy an approximate squarer mirror pair, such that the error introduced by one approximate squarer mirrors the error introduced by the other, i.e., the errors generated by the approximate squarers are approximately the additive inverse of each other. This helps the healing stage (accumulator) to automatically average out the error originated in the approximation stage, and thereby to minimize the quality loss. For random input vectors, SH demonstrates up to 25% and 18.6% better area and power efficiency, respectively, with a better quality output than the conventional approximate computing methodology. As a case study, SH is applied to one of the computationally expensive components (SAC) of the radio astronomy calibration application, where it shows up to 46.7% better quality for equivalent computing efficiency as that of conventional methodology.","2169-3536","","10.1109/ACCESS.2018.2868036","Nederlandse Organisatie voor Wetenschappelijk Onderzoek; Dutch Ministry of EL&I; Province of Drenthe; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8451860","Approximate computing;approximate multiplier;approximate squarer;multiply-accumulate;radio astronomy;self-healing;square-accumulate","Mirrors;Computer architecture;Approximate computing;Hardware;Radio astronomy;Error analysis;Approximation algorithms","","21","","39","OAPA","30 Aug 2018","","","IEEE","IEEE Journals"
"Self-Supervised Multi-Category Counting Networks for Automatic Check-Out","H. Chen; Y. Zhou; J. Li; X. -S. Wei; L. Xiao","School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China; School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China; School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China; School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China; School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China",IEEE Transactions on Image Processing,"11 Apr 2022","2022","31","","3004","3016","The practical task of Automatic Check-Out (ACO) is to accurately predict the presence and count of each product in an arbitrary product combination. Beyond the large-scale and the fine-grained nature of product categories as its main challenges, products are always continuously updated in realistic check-out scenarios, which is also required to be solved in an ACO system. Previous work in this research line almost depends on the supervisions of labor-intensive bounding boxes of products by performing a detection paradigm. While, in this paper, we propose a Self-Supervised Multi-Category Counting (S2MC2) network to leverage the point-level supervisions of products in check-out images to both lower the labeling cost and be able to return ACO predictions in a class incremental setting. Specifically, as a backbone, our S2MC2 is built upon a counting module in a class-agnostic counting fashion. Also, it consists of several crucial components including an attention module for capturing fine-grained patterns and a domain adaptation module for reducing the domain gap between single product images as training and check-out images as test. Furthermore, a self-supervised approach is utilized in S2MC2 to initialize the parameters of its backbone for better performance. By conducting comprehensive experiments on the large-scale automatic check-out dataset RPC, we demonstrate that our proposed S2MC2 achieves superior accuracy in both traditional and incremental settings of ACO tasks over the competing baselines.","1941-0042","","10.1109/TIP.2022.3163527","National Key Research and Development Program of China(grant numbers:2021YFA1001100); Natural Science Foundation of Jiangsu Province of China(grant numbers:BK20210340); Natural Science Foundation of China(grant numbers:61871226,62072242); Fundamental Research Funds for the Central Universities(grant numbers:30920041111); Chinese Association for Artificial Intelligence (CAAI)-Huawei MindSpore Open Fund; Beijing Academy of Artificial Intelligence (BAAI); MindSpore, Compute Architecture for Neural Networks (CANN) and Ascend AI Processor used for this research; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9749978","Automatic check-out;self-supervised;domain adaptation;multi-category counting","Task analysis;Training;Annotations;Testing;Object detection;Feature extraction;Deep learning","","5","","55","IEEE","5 Apr 2022","","","IEEE","IEEE Journals"
"Optimized Configurable Architectures for Scalable Soft-Input Soft-Output MIMO Detectors With 256-QAM","M. M. Mansour; L. M. A. Jalloul","Department of Electrical and Computer Engineering, American University of Beirut, Lebanon; Qualcomm Inc., San Jose, CA",IEEE Transactions on Signal Processing,"19 Aug 2015","2015","63","18","4969","4984","This paper presents an optimized low-complexity and high-throughput MIMO signal detector core for detecting spatially multiplexed data streams. The core architecture supports various layer configurations up to 4, while achieving near-optimal performance, and configurable modulation constellations up to 256-QAM on each layer. The core is capable of operating as a soft-input soft-output log-likelihood ratio (LLR) MIMO detector which can be used in the context of iterative detection and decoding. High area-efficiency is achieved via algorithmic and architectural optimizations performed at two levels. First, distance computations and slicing operations for an optimal 2-layer maximum a posteriori MIMO detector are optimized to eliminate use of multipliers and reduce the overhead of slicing in the presence of soft-input LLRs. We show that distances can be easily computed using elementary addition operations, while optimal slicing is done via efficient comparisons with soft decision boundaries, resulting in a simple feed-forward pipelined architecture. Second, to support more layers, an efficient channel decomposition scheme is presented that reduces the detection of multiple layers into multiple 2-layer detection subproblems, which map onto the 2-layer core with a slight modification using a distance accumulation stage and a post-LLR processing stage. Various architectures are accordingly developed to achieve a desired detection throughput and run-time reconfigurability by time-multiplexing of one or more component cores. The proposed core is applied also to design an optimal multiuser MIMO detector for LTE. The core occupies an area of 1.58 MGE and achieves a throughput of 733 Mbps for 256-QAM when synthesized in 90-nm CMOS.","1941-0476","","10.1109/TSP.2015.2446441","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7124510","Maximum Likelihood detection;MIMO systems;256-QAM;Reconfigurable MIMO detector;Sphere decoder","MIMO;Detectors;Complexity theory;Signal processing algorithms;Optimization;Computer architecture;Matrix decomposition","","13","","62","IEEE","16 Jun 2015","","","IEEE","IEEE Journals"
"Enhancing Time Series Product Demand Forecasting With Hybrid Attention-Based Deep Learning Models","X. Zhang; P. Li; X. Han; Y. Yang; Y. Cui","School of Business, Computing and Social Sciences, University of Gloucestershire, Cheltenham, U.K.; Business School, University of Hull, Hull, U.K.; School of Business, Renmin University of China, Beijing, China; Viterbi School of Engineering, University of Southern California, Los Angeles, CA, USA; McCallum Graduate School of Business, Bentley University, Waltham, MA, USA",IEEE Access,"19 Dec 2024","2024","12","","190079","190091","Time series forecasting plays a crucial role in various industries, particularly in predicting product demand for effective supply chain management. This paper presents a novel approach to time series forecasting by leveraging advanced deep learning techniques, specifically focusing on hybrid models that combine attention mechanisms with traditional recurrent neural networks. Our proposed method, the Hybrid Attention-based Long Short-Term Memory (HA-LSTM) network, integrates multi-head self-attention modules with LSTM layers to capture both long-term dependencies and local temporal patterns in time series data. We evaluate our model on a large-scale retail dataset from the “Predict Future Sales” competition, demonstrating its effectiveness in handling complex, real-world time series with multiple seasonalities and trends. Experimental results show that the HA-LSTM outperforms state-of-the-art baselines, including ARIMA, Prophet, and vanilla LSTM models, achieving a 15% improvement in Mean Absolute Percentage Error (MAPE) and a 12% reduction in Root Mean Square Error (RMSE). Furthermore, we conduct an extensive ablation study to analyze the contribution of each component in our hybrid model. The proposed approach not only enhances forecasting accuracy but also provides interpretable attention weights, offering insights into the relative importance of different time steps in making predictions. This research contributes to the growing body of work on deep learning for time series analysis and offers practical implications for improving demand forecasting in retail and supply chain management.","2169-3536","","10.1109/ACCESS.2024.3516697","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10795122","Time series forecasting;deep learning;attention mechanisms;product demand prediction","Time series analysis;Forecasting;Predictive models;Long short term memory;Deep learning;Attention mechanisms;Computer architecture;Data models;Computational modeling;Accuracy","","","","36","CCBY","12 Dec 2024","","","IEEE","IEEE Journals"
"SpikeSim: An End-to-End Compute-in-Memory Hardware Evaluation Tool for Benchmarking Spiking Neural Networks","A. Moitra; A. Bhattacharjee; R. Kuang; G. Krishnan; Y. Cao; P. Panda","Department of Electrical Engineering, Yale University, New Haven, CT, USA; Department of Electrical Engineering, Yale University, New Haven, CT, USA; School of Electrical, Computer, and Energy Engineering, Arizona State University, Tempe, AZ, USA; Meta Reality Labs, Redmond, WA, USA; School of Electrical, Computer, and Energy Engineering, Arizona State University, Tempe, AZ, USA; Department of Electrical Engineering, Yale University, New Haven, CT, USA",IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems,"19 Oct 2023","2023","42","11","3815","3828","Spiking neural networks (SNNs) are an active research domain toward energy-efficient machine intelligence. Compared to conventional artificial neural networks (ANNs), SNNs use temporal spike data and bio-plausible neuronal activation functions such as leaky-integrate fire/integrate fire (LIF/IF) for data processing. However, SNNs incur significant dot-product operations causing high memory and computation overhead in standard von-Neumann computing platforms. To this end, in-memory computing (IMC) architectures have been proposed to alleviate the “memory-wall bottleneck” prevalent in von-Neumann architectures. Although recent works have proposed IMC-based SNN hardware accelerators, the following key implementation aspects have been overlooked: 1) the adverse effects of crossbar nonideality on SNN performance due to repeated analog dot-product operations over multiple time-steps and 2) hardware overheads of essential SNN-specific components, such as the LIF/IF and data communication modules. To this end, we propose SpikeSim, a tool that can perform realistic performance, energy, latency and area evaluation of IMC-mapped SNNs. SpikeSim consists of a practical monolithic IMC architecture called SpikeFlow for mapping SNNs. Additionally, the nonideality computation engine (NICE) and energy–latency–area (ELA) engine performs hardware-realistic evaluation of SpikeFlow-mapped SNNs. Based on 65nm CMOS implementation and experiments on CIFAR10, CIFAR100 and TinyImagenet datasets, we find that the LIF/IF neuronal module has significant area contribution  $(>11\%$  of the total hardware area). To this end, we propose SNN topological modifications that leads to  $1.24\times $  and  $10\times $  reduction in the neuronal module’s area and the overall energy-delay-product value, respectively. Furthermore, in this work, we perform a holistic comparison between IMC implemented ANN and SNNs and conclude that lower number of time-steps are the key to achieve higher throughput and energy-efficiency for SNNs compared to 4-bit ANNs. The code repository for the SpikeSim tool is available at Github link.","1937-4151","","10.1109/TCAD.2023.3274918","JUMP2.0 Center and CBRIC a JUMP1.0 Center; DARPA and SRC; Google Research Scholar Award; National Science Foundation CAREER Award, TII (Abu Dhabi); DARPA AI Exploration (AIE) Program; DoE MMICC Center SEACROGS(grant numbers:DE-SC0023198); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10122627","Analog crossbars;emerging devices;in-memory computing (IMC);spiking neural networks (SNNs)","Hardware;Computer architecture;Neurons;Energy efficiency;Benchmark testing;Biological neural networks;Engines","","12","","46","IEEE","10 May 2023","","","IEEE","IEEE Journals"
"Broadband Printed Compound Air-Fed Array Antennas","Z. -H. Wu; W. -X. Zhang","State Key Laboratory of Millimeter Waves, South-East University, Nanjing, China; State Key Laboratory of Millimeter Waves, South-East University, Nanjing, China",IEEE Antennas and Wireless Propagation Letters,"5 Apr 2010","2010","9","","187","190","The printed compound air-fed array (PCAFA) is an improved Fabry-Perot resonator (FPR) antenna, which exhibits wider bandwidth and higher aperture efficiency than traditional FPR antennas because the nonuniform phase and magnitude of field distribution on aperture are partly compensated in design. This letter proposes an essential method to enhance the gain bandwidth while keeping the high gain and aperture efficiency by means of forming a flattened gain-frequency response to enlarge the (gain × bandwidth) product. The detailed design example for 14 GHz is analyzed using CST-2006 simulator and tested in an anechoic chamber. The full-wave simulated results exhibit 19.1 dBi peak gain corresponding to 71% aperture efficiency and 9.9% bandwidth for -1 dB gain-drop or 14.1% bandwidth for -3 dB gain-drop. The measured data are in good agreement with the simulation .","1548-5757","","10.1109/LAWP.2010.2045470","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5430951","Air-fed array antenna;broadband printed antenna;Fabry–Perot resonator (FPR) antenna;frequency selective surface (FSS);high impedance surface (HIS)","Broadband antennas;Antenna arrays;Bandwidth;Phased arrays;Aperture antennas;Fabry-Perot;Product design;Analytical models;Testing;Anechoic chambers","","48","","20","IEEE","15 Mar 2010","","","IEEE","IEEE Journals"
"Will Metro Networks Be the Playground for (True) Elastic Optical Networks?","P. Layec; A. Dupas; D. Verchère; K. Sparks; S. Bigo","Nokia Bell Labs, Nozay, France; Nokia Bell Labs, Nozay, France; Nokia Bell Labs, Nozay, France; Nokia Bell Labs, Murray Hill, NJ, USA; Nokia Bell Labs, Nozay, France",Journal of Lightwave Technology,"12 Apr 2017","2017","35","6","1260","1266","Located at the meeting point between telecom operators and over-the-top service providers, metro networks are particularly well suited for the introduction of radical acceleration of dynamics in the optical networks, leveraging elastic building blocks such as transponders and optical nodes. In this paper, we review innovative solutions which could be used to address some of the challenges of metro networks in the short-medium term (e.g., 2-5 years from now). In particular, we discuss the most valuable application scenarios for elastic optical networking. We then highlight a few features of next generation metro networks and outline the main road toward this next generation with network experiments and associated use cases.","1558-2213","","10.1109/JLT.2017.2665783","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7847391","Networks optimization;optical fiber communication;optical networks","Optical fiber networks;Optical fibers;IP networks;Optical signal processing;Next generation networking","","18","","37","IEEE","8 Feb 2017","","","IEEE","IEEE Journals"
"Editorial for the Special Issue on Next Generation Datacenter Power Conversion Technologies","X. Yang; H. Wang","Xi'an Jiaotong University, Xi'an, China; ShanghaiTech University, Shanghai, China",CPSS Transactions on Power Electronics and Applications,"6 Oct 2022","2022","7","3","227","228","Modern datacenter is becoming the critical infrastructure with the rapid evolvement of emerging information technologies such as 5G communications, big data, cloud computing, blockchain, and artificial intelligence. In 2030, energy consumption in datacenters is projected to be 3000 TWh, which will account 7.6% of global energy usuage. The rising demand for data center services is accompanied by massive energy consumption, and it motivates intensive research on cost-effective, reliable, and greener electricity to optimize the utilization of electric power. In datacenter, less than half of the total energy is delivered to the terminal load, such as CPU, GPU, memory, and disk, while the rest is lost during power conversion, distribution, and cooling. This results in high costs, large cooling equipment, and inefficient power utilization. Higher energy efficiency, higher power density, better cooling, and cost reduction are the major driving forces to shape greener datacenter power management technologies. Correspondingly, we organized this Special Issue on Next Generation Datacenter Power Conversion Technologies to provide technical insights on the latest power architectures, power electronic topologies, modeling and analysis methods, and control strategies to embrace next-generation datacenter power conversion.","2475-742X","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9913372","","Energy consumption;Costs;Cooling;Special issues and sections;Shape;Green products;Power electronics","","","","0","","6 Oct 2022","","","CPSS","CPSS Journals"
"Investigating the 59-Day Error Signal in the Mean Sea Level Derived From TOPEX/Poseidon, Jason-1, and Jason-2 Data With FES and GOT Ocean Tide Models","L. Zawadzki; M. Ablain; L. Carrere; R. D. Ray; N. P. Zelensky; F. Lyard; A. Guillot; N. Picot","Collecte Localisation Satellite, Ramonville Saint-Agne, France; Collecte Localisation Satellite, Ramonville Saint-Agne, France; Collecte Localisation Satellite, Ramonville Saint-Agne, France; Goddard Space Flight Center (NASA/GSFC), Greenbelt, MD, USA; Stinger Ghaffarian Technologies Inc., Greenbelt, MD, USA; Laboratoire d’Etudes en Géophysique et Océanographie Spatiales, Toulouse, France; Centre National d’Etudes Spatiales, Toulouse, France; Centre National d’Etudes Spatiales, Toulouse, France",IEEE Transactions on Geoscience and Remote Sensing,"21 May 2018","2018","56","6","3244","3255","Since the beginning of the altimeter mission TOPEX/Poseidon (T/P), followed by Jason-1 and Jason-2 on similar orbits, and many other missions on different orbits (ERS, EnviSat, etc.), mean sea level (MSL) products became essential for the comprehension of global ocean circulation. Since early in the T/P mission, a suspicious signal, having a period of near 59 days and amplitude of roughly 5 mm, was apparent in the Global MSL record. Compared with the 4-5-mm amplitude of the annual signal, the 59-day signal has understandably attracted attention. Moreover, the same signal has been subsequently detected in Jason-1 and later in Jason-2 MSLs. In 2010, the Ocean Surface Topography Science Team (OSTST) concluded this signal as the aliasing of a higher frequency error inherited from the tide model correction: the semi-diurnal wave S2. The source of this error was mainly attributed to T/P measurements, which were assimilated in ocean tide models. When these models are used in the computation of T/P MSL, most of the error cancels. However, this error is communicated to Jason-1 and Jason-2 MSLs. In order to gather and publish the OSTST analyses on this matter, this paper first attempts to list the myriad possibilities for the puzzling 59-day error in MSL. Then, this paper goes deeper into the description of the main contributor to this list: the tide models error. Indeed, since 2010, considerable efforts have been undertaken within the ocean tide community in order to correct ocean tide S2-waves from this error, particularly in the Goddard Ocean Tide (GOT) and finite element solution (FES) latest versions. Comparing several GOT and FES versions and a pure hydrodynamic tide model, this paper assesses, quantifies, and describes a reduction of the MSL 59-day error thanks to the latest releases. These analyses also confirm that a large part of this error has its origins in the T/P mission and has contaminated ocean tide solutions and Jason-1 and Jason-2 MSLs. They also suggest that ocean tide is not the only possible vector. Jason-1 and Jason-2 MSLs contain additional 59-day error-though to a lesser extent-that may either come from the measurements themselves or from another vector.","1558-0644","","10.1109/TGRS.2018.2796630","CNES through the framework of the FES2014 Project; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8291062","Level measurements;oceanography;sea measurements;tides","Tides;Atmospheric modeling;Orbits;Satellites;Data models;Load modeling","","8","","38","IEEE","13 Feb 2018","","","IEEE","IEEE Journals"
"Area- and Power-Efficient Architecture for High-Throughput Implementation of Lifting 2-D DWT","B. K. Mohanty; A. Mahajan; P. K. Meher","Department of Electronics and Communication Engineering, Jaypee University of Engineering and Technology, Guna, Madhya Pradesh, India; Department of Electronics and Communication Engineering, Jaypee University of Engineering and Technology, Guna, Madhya Pradesh, India; Department of Embedded Systems, Institute for Infocomm Research, Singapore",IEEE Transactions on Circuits and Systems II: Express Briefs,"12 Jul 2012","2012","59","7","434","438","We have suggested a new data-access scheme for the computation of lifting two-dimensional (2-D) discrete wavelet transform (DWT) without using data transposition. We have derived a linear systolic array directly from the dependence graph (DG) and a 2-D systolic array from a suitably segmented DG for parallel and pipeline implementation of 1-D DWT. These two systolic arrays are used as building blocks to derive the proposed transposition-free structure for lifting 2-D DWT. The proposed structure requires only a small on-chip memory of (4N + 8P) words and processes a block of P samples in every cycle, where N is the image width. Moreover, it has small output latency of nine cycles and does not require control signals which are commonly used in most of the existing DWT structures. Compared with the best of the existing high-throughput structures, the proposed structure requires the same arithmetic resources but involves 1.5N less on-chip memory and offers the same throughput rate. ASIC synthesis result shows that the proposed structure for block size 8 and image size 512 512 involves 28% less area, 35% less area-delay product, and 27% less energy per image than the best of the corresponding existing structures. Apart from that, the proposed structure is regular and modular; and it can be easily configured for different block sizes.","1558-3791","","10.1109/TCSII.2012.2200169","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6220869","Block processing;discrete wavelet transform (DWT);lifting;systolic VLSI;2-D DWT","Discrete wavelet transforms;Arrays;Memory management;System-on-a-chip;Complexity theory","","40","1","8","IEEE","19 Jun 2012","","","IEEE","IEEE Journals"
"An Intelligent Metrology Architecture With AVM for Metal Additive Manufacturing","H. -C. Yang; M. Adnan; C. -H. Huang; F. -T. Cheng; Y. -L. Lo; C. -H. Hsu","Institute of Electrical Engineering, National Kaohsiung University of Science and Technology, Kaohsiung, Taiwan; Institute of Manufacturing Information and Systems, National Cheng Kung University, Taiwan; Institute of Manufacturing Information and Systems, National Cheng Kung University, Taiwan; Institute of Manufacturing Information and Systems, National Cheng Kung University, Taiwan; Department of Mechanical Engineering, National Cheng Kung University, Tainan, Taiwan; Department of Information Management, Chang Jung Christian University, Tainan, Taiwan",IEEE Robotics and Automation Letters,"24 Jun 2019","2019","4","3","2886","2893","The capability of measuring melt pool variation is the key evaluating metal additive manufacturing quality. To measure the variation, a metrology architecture with in situ melt pool measurement and an estimation module is required. However, it is a challenge to effectively extract significant features from the huge data collected by the in situ metrology for quality estimation requirement. The purpose of this letter is to propose an intelligent metrology architecture with an in situ metrology (ISM) module and an enhanced automatic virtual metrology (AVM) system. The ISM module can extract the melt pool features with a coaxial camera and a pyrometer. On the other hand, the AVM system is improved with a feature selection method to solve the issue of limited samples in the component modeling quality. The examples with different metals are adopted to illustrate how the system works for estimating surface roughness and density of components, and, in the future, the system can even serve as the feedback signal for adaptive control of the process parameters by layering in an additive manufacturing system.","2377-3766","","10.1109/LRA.2019.2921927","Intelligent Manufacturing Research Center; Ministry of Education in Taiwan; Ministry of Science and Technology of Taiwan, R.O.C.(grant numbers:MOST 107-2218-E-992-307,MOST 107-2218-E-006-055,MOST 105-2221-E-006-255-MY3); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8733865","Metal additive manufacturing;intelligent metrology architecture;in-situ metrology;melt pool;AVM","Metrology;Feature extraction;Metals;Cameras;Temperature measurement;Three-dimensional printing","","17","","22","OAPA","10 Jun 2019","","","IEEE","IEEE Journals"
"Redefining Monitoring Rules for Intelligent Fault Detection and Classification via CNN Transfer Learning for Smart Manufacturing","C. -F. Chien; W. -T. Hung; E. T. -Y. Liao","Ministry of Science and Technology and the Department of Industrial Engineering and Engineering Management, Artificial Intelligence for Intelligent Manufacturing Systems Research Center, National Tsing Hua University, Hsinchu, Taiwan; Artificial Intelligence for Intelligent Manufacturing Systems Research Center, Ministry of Science and Technology, and the International Intercollegiate Ph.D. Program, National Tsing Hua University, Hsinchu, Taiwan; Ministry of Science and Technology and the Department of Industrial Engineering and Engineering Management, Artificial Intelligence for Intelligent Manufacturing Systems Research Center, National Tsing Hua University, Hsinchu, Taiwan",IEEE Transactions on Semiconductor Manufacturing,"5 May 2022","2022","35","2","158","165","Fault detection and classification has been employed to enhance yield and product quality for smart semiconductor manufacturing. For early detection of abnormal events that cause defects, the status variables identification data collected by the sensors embedded in advanced machines can be analyzed to derive the actions for advanced process control and advanced equipment control. However, the validity and effectiveness of fault detection and classification technologies may highly depend on domain knowledge and experience of the process engineers who should redefine the monitoring rules quickly when new process excursion occurred especially when ramping up new technologies and products. Motivated by realistic needs, this study aims to propose a novel strategy to empower intelligent fault detection and classification that employed convolutional neural network to analyze the feature SVID data and determine the conditions of the wafers, while shorten the cycle time for self-learning from domain knowledge and redefining new monitoring rules for fault classification in real time. This approach is validated with an empirical study in a leading semiconductor manufacturing company in Taiwan. The results have demonstrated the practical viability of the developed solution.","1558-2345","","10.1109/TSM.2022.3164904","Ministry of Science and Technology, Taiwan(grant numbers:MOST 110-2634-F-007-017,MOST 110-2634-F-007-027,MOST 110-2221-E-007-105-MY3); Micron Foundation, USA; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9749610","Fault detection and classification;convolutional neural networks;machine learning;yield ramping;real time decision","Monitoring;Feature extraction;Fault diagnosis;Fault detection;Convolutional neural networks;Process control;Data models","","18","","35","IEEE","5 Apr 2022","","","IEEE","IEEE Journals"
"Uncertainty Quantification of CMOS Active Filter Circuits: A Non-Intrusive Computational Approach Based on Generalized Polynomial Chaos","M. E. Duman; O. Suvak","Department of Electronics Engineering, Gebze Technical University, Kocaeli, Turkey; Department of Electronics Engineering, Gebze Technical University, Kocaeli, Turkey",IEEE Access,"23 Oct 2020","2020","8","","189246","189261","Semiconductor fabrication technologies as applies to the nanometer-era paradigms of nowadays have rendered uncertainty quantification analyses through component-level parameters compulsory and indispensable. Frequency responses of CMOS active filters are invariably observed to be affected by probabilistically modelled parameter deviations, and in this article the focus is on the fast and accurate quantification of the uncertainties pervading CMOS active filters in terms of their magnitude frequency responses. Previous work dominantly has preference for the widely recognized non-intrusive Monte Carlo methods, which bring about a disproportionately high computational burden. Also discomfitures are observed to arise due to apparently inadequate ensemble volumes and a limited variety of distribution functions that are chosen to be utilized, along with seemingly insufficient means of resulting data visualization and the lack of accurate probabilistic quantification. Generalized Polynomial Chaos (gPC) based stochastic spectral techniques, which usually offer reduced computational complexity with respect to Monte Carlo, targeting CMOS active filters do not seem to have drawn much attention; the few related publications offer utility in a limited scope of electronic components. In this article, we carry out uncertainty quantification analyses in order to compute partial or approximate stochastic characterizations of the magnitude frequency responses of several multi-component CMOS active filter circuits with the gPC-based stochastic collocation technique. The pertaining inherent non-intrusive nature is exploited, and the stated issues associated with the previous work are addressed. We utilize a stokhos-based MATLAB/C++ toolbox of our own design, on whose software architecture, features, and facilities we provide profound details, and present performance comparisons with Monte Carlo along with intuitive and insightful comments, in an endeavor to suggest that such observations may prove to be beneficial to circuit designers.","2169-3536","","10.1109/ACCESS.2020.3031215","Scientific and Technological Research Council of Turkey (TUBITAK); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9223680","Active CMOS filter;generalized polynomial chaos;magnitude response;Monte Carlo methods;stochastic collocation;stokhos;software interface;toolbox;uncertainty quantification","Monte Carlo methods;Uncertainty;Stochastic processes;CMOS technology;Chaos;Matlab;Integrated circuit modeling","","3","","43","CCBY","14 Oct 2020","","","IEEE","IEEE Journals"
"System of Systems for Quality-of-Service Observation and Response in Cloud Computing Environments","P. C. Hershey; S. Rao; C. B. Silio; A. Narayan","Raytheon Intelligence, Information and Services, Dulles, VA, USA; International Institute of Information Technology, Bangalore, India; University of Maryland, College Park, MD, USA; School of Computing, National University of Singapore, Singapore",IEEE Systems Journal,"3 Mar 2015","2015","9","1","212","222","As military, academic, and commercial computing systems evolve from autonomous entities that deliver computing products into network centric enterprise systems that deliver computing as a service, opportunities emerge to consolidate computing resources, software, and information through cloud computing. Along with these opportunities come challenges, particularly to service providers and operations centers that struggle to monitor and manage quality of service (QoS) for these services in order to meet customer service commitments. Traditional approaches fall short in addressing these challenges because they examine QoS from a limited perspective rather than from a system-of-systems (SoS) perspective applicable to a net-centric enterprise system in which any user from any location can share computing resources at any time. This paper presents a SoS approach to enable QoS monitoring, management, and response for enterprise systems that deliver computing as a service through a cloud computing environment. A concrete example is provided for application of this new SoS approach to a real-world scenario (viz., distributed denial of service). Simulated results confirm the efficacy of the approach.","1937-9234","","10.1109/JSYST.2013.2295961","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6729062","Cloud computing;distributed denial of service (DDoS);enterprise systems;information assurance;net centric;quality of service (QoS);security;service-oriented architecture (SOA);systems of systems (SoS);Cloud computing;distributed denial of service (DDoS);enterprise systems;information assurance;net centric;quality of service (QoS);security;service-oriented architecture (SOA);systems of systems (SoS)","Quality of service;Cloud computing;Monitoring;Security;Delays","","18","","29","IEEE","30 Jan 2014","","","IEEE","IEEE Journals"
"Homogeneous Stream Processors With Embedded Special Function Units for High-Utilization Programmable Shaders","Y. -J. Kim; H. -E. Kim; S. -H. Kim; J. -S. Park; S. Paek; L. -S. Kim","School of Electrical Engineering and Computer Science, Korea Advanced Institute of Science and Technology, Daejeon, South Korea; School of Electrical Engineering and Computer Science, Korea Advanced Institute of Science and Technology, Daejeon, South Korea; School of Electrical Engineering and Computer Science, Korea Advanced Institute of Science and Technology, Daejeon, South Korea; School of Electrical Engineering and Computer Science, Korea Advanced Institute of Science and Technology, Daejeon, South Korea; School of Electrical Engineering and Computer Science, Korea Advanced Institute of Science and Technology, Daejeon, South Korea; School of Electrical Engineering and Computer Science, Korea Advanced Institute of Science and Technology, Daejeon, South Korea",IEEE Transactions on Very Large Scale Integration (VLSI) Systems,"10 Jul 2012","2012","20","9","1691","1704","We embed special function units (SFUs) in homogeneous stream processors (SPs) within a graphics processing unit (GPU), to improve its performance in running modern programmable shaders, which make poor use of a single-instruction multiple-data (SIMD) architecture. We also compact instructions, so as to reduce the size of the instruction memory, and reduce area requirements by using a partial SFU in SPs, and a lookup table which is shared between multiple SFUs. The result is an increase of 88% in utilization and a reduction in the normalized area-delay product of 27%, compared to a baseline SIMD architecture. We verified our architecture on an field-programmable gate-array evaluation platform with an ARM9 host processor and a full 3-D graphics pipeline.","1557-9999","","10.1109/TVLSI.2011.2161499","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5970104","3-D graphics;graphics processing unit (GPU);mobile device;programmable shader;special function unit (SFU);stream processor (SP)","Graphics processing unit;Table lookup;Resource management;VLIW;Graphics","","17","","23","IEEE","1 Aug 2011","","","IEEE","IEEE Journals"
"Discrete Complex Image Method With Automatic Order Selection","E. P. Karabulut; A. T. Erdogan; M. I. Aksun","Department of Electrical and Electronics Engineering, Koc University, Sariyer, Istanbul, Turkey; Department of Electrical and Electronics Engineering, Koc University, Sariyer, Istanbul, Turkey; Department of Electrical and Electronics Engineering, Koc University, Sariyer, Istanbul, Turkey",IEEE Transactions on Microwave Theory and Techniques,"10 Oct 2011","2011","59","10","2385","2393","The discrete complex image method (DCIM) has been well-established and widely employed as a tool to compute spatial-domain Green's functions in planar multilayered media. Although the use of the DCIM in conjunction with the method of moments has been quite satisfactory for the efficient analysis of printed structures in layered media, it has not been considered much as a legitimate tool for commercial applications. Up until recently, there has been mainly two reasons for the reluctance of its acceptance in commercial products: the lack of a proper error criterion in the spatial domain and the manual selection of the order of images. As the former shortcoming has recently been eliminated by establishing a proper error criterion in the spatial domain, this paper intends to propose a viable solution for the latter problem, i.e., for the choice of the number of images. Note that, thus far, this choice has been based on the number of significant singular values obtained as a by-product of the method, which is neither rigorous, nor optimum in any sense, and renders it nonrobust and unreliable. As a remedy for this remaining shortcoming, a model selection approach known as minimum description length (MDL) has been introduced into the algorithm of the DCIM with success. The MDL approach, exploiting the regularities in the data, selects the order of the model based on the tradeoff between the quality of fitting and complexity of the model.","1557-9670","","10.1109/TMTT.2011.2163804","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5995276","Closed-form Green's functions;discrete complex image method (DCIM);layered media;minimum description length (MDL)","Green's function methods;Data models;Spectral analysis;Accuracy;Approximation methods;Computational modeling;Complexity theory","","2","","39","IEEE","22 Aug 2011","","","IEEE","IEEE Journals"
"Physics-Driven Data Collection in 3-D Printing: Traversing the Realm of Social Manufacturing","T. S. Tamir; G. Xiong; Z. Shen; J. Leng","State Key Laboratory of Precision Electronic Manufacturing Technology and Equipment, Guangdong University of Technology, Guangzhou, China; State Key Laboratory of Multimodal Artificial Intelligence Systems, Beijing Engineering Research Center of Intelligent Systems and Technology, Institute of Automation, Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Multimodal Artificial Intelligence Systems, Beijing Engineering Research Center of Intelligent Systems and Technology, Institute of Automation, Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Precision Electronic Manufacturing Technology and Equipment, Guangdong University of Technology, Guangzhou, China",IEEE Transactions on Computational Social Systems,"2 Dec 2024","2024","11","6","7909","7928","Additive manufacturing (AM), also called 3-D printing, is a supporting technology in social manufacturing that has gained significant attention recently. As the AM industry grows, collecting and analyzing data are essential to ensure product quality, process efficiency, and cost-effectiveness. However, obtaining experimental data is challenging owing to cost and time constraints. Therefore, cost-effective and time-efficient strategies for collecting AM data are urgently required. This study proposes a novel data-collection approach that integrates the concept of finite element analysis (FEA) and physics-informed machine learning (PIML). We begin by discussing the importance of data collection in AM and the associated challenges. We then present various types of data that can be collected in AM, including the 3-D models and end-to-end data. End-to-end data comprise experimental data (i.e., sensors and images) and simulation data. Moreover, we present a case study that demonstrates the generation of simulation data and provides a detailed analysis of warpage. The STereoLithography (STL) file format of the BeltClip object from the Thingiverse possesses slicing through the Ultimaker© Cura software. The resulting G-code file is input to the Digimat-AM platform for virtual simulation of the BeltClip printing process. Digimat-AM, as a FEA simulation tool, then generates observational sample data. These data function as a roadmap for understanding the application of physical information for learning, which constitutes the observational bias aspect of PIML. The observational data obtained from the Digimat-AM is suggested for building a machine-learning model. Finally, we conclude with a discussion of inductive and learning biases in the prediction, control, and optimization aspects of AM.","2329-924X","","10.1109/TCSS.2024.3407823","National Key Research and Development Program of China(grant numbers:2022YFF0606005); National Natural Science Foundation of China(grant numbers:92267103,92360307,22108041); Beijing Natural Science Foundation(grant numbers:L233005); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10577439","3-D printing;experimental data;physics-informed machine learning (PIML), simulation data;social manufacturing;warpage analysis","Printing;Manufacturing;Prediction algorithms;Industries;Optimization;Data collection;Process control;Three-dimensional printing;Machine learning;Smart manufacturing;Social factors;Manufacturing processes;Manufacturing systems","","","","80","IEEE","28 Jun 2024","","","IEEE","IEEE Journals"
"Requirements for Adaptive Consumer Gateways in Residential Learning Healthcare Systems: Bringing Intelligence to the Edge","N. Fares; R. S. Sherratt","Department of Biomedical Engineering, The University of Reading, Reading, U.K.; Department of Biomedical Engineering, The University of Reading, Reading, U.K.",IEEE Transactions on Consumer Electronics,"29 Apr 2024","2024","70","1","4457","4469","A gateway is a key component in residential healthcare systems. Enabling adaptability and applying intelligence to the gateway will promote residential healthcare systems to become Learning Healthcare Systems (LHSs) that can perform real-time decision making. This leads to the exciting potential of a new research field inconsumer-oriented gateways and consumer products that can adapt to the consumer’s healthcare needs, learn about the consumer, and over time can adapt accordingly. While consumer healthcare gateways exist, they have tended to be fixed on specific medical conditions and are not upgradeable or adaptive. To be able to create adaptive consumer gateways for consumer healthcare applications, this paper identifies a set of requirements concerning scalability, energy efficiency, reliability, availability, interoperability, and privacy that need to be fulfilled before any product or service can be created. Intervention in local data processing, local data storage, embedded data mining, security, interoperability, and configurability that serve the development process are also discussed. The goal of this paper isto provide the requirements for the innovation of a one-for-all smart adaptive consumer gateway in residential learning healthcare systems and to influence the consumer healthcare field to consider the benefits of moving to adaptive gateways for future developments.","1558-4127","","10.1109/TCE.2023.3326570","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10290908","Adaptive gateways;residential healthcare systems;learning healthcare systems;edge computing;machine learning","Medical services;Logic gates;Adaptive systems;Decision support systems;Soft sensors;Predictive models;Real-time systems","","","","91","IEEE","23 Oct 2023","","","IEEE","IEEE Journals"
"Predictive Formal Analysis of Resilience in Cyber-Physical Systems","S. Mouelhi; M. -E. Laarouchi; D. Cancila; H. Chaouchi","ECE Paris.Lyon–École d’ingénieurs, INSEEC U., Paris, France; CEA LIST, CEA Saclay, Gif-sur-Yvette, France; CEA LIST, CEA Saclay, Gif-sur-Yvette, France; Télécom SudParis, Institut Mines-Télécom, Évry, France",IEEE Access,"26 Mar 2019","2019","7","","33741","33758","The behavioral analysis of cyber-physical systems in safety-critical scenarios is a challenging task. In this paper, the endogenous and exogenous aspects of resilience are of cornerstone importance in system design and verification. Endogenous resilience is the inherent ability of the system to detect and process internal faults and malicious attacks. Exogenous resilience is the permanent capability of the system to maintain a safe operation within its ambient environment. In this paper, we present a predictive dual-sided contract-based formal methodology to address both aspects of resilience on top of a distributed object-oriented component-based software model. It is illustrated by a case study of urban drone rescue systems. We exploit the formalism of timed automat a and the toolbox UPPAAL to predict by abstraction and analyze (simulate and verify) endogenous resilience. Instead of presenting the final models of the case study, we reflect our experience with UPPAAL in generic patterns of system design and contract specification, reusable in other contexts with adaptations. The analysis of exogenous resilience is specific to the considered drone rescue system. It consists of synthesizing by iterative model-checking safe flight paths for the drones within a 3D virtual model of urban surroundings true to modern cities.","2169-3536","","10.1109/ACCESS.2019.2903153","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8668400","Resilience;safety;distributed control;object-oriented software;component-based architectures;design by contracts;timed automata;3D models;model-checking;temporal logic;fairness","Resilience;Drones;Object oriented modeling;Software;Safety;Computational modeling;Analytical models","","18","","54","OAPA","17 Mar 2019","","","IEEE","IEEE Journals"
"A Blockchain-Based IoT Framework for Oil Field Remote Monitoring and Control","Y. Zuo; Z. Qi","Department of Accountancy and Information Systems, University of North Dakota, Grand Forks, ND, USA; Department of Accountancy and Information Systems, University of North Dakota, Grand Forks, ND, USA",IEEE Access,"7 Jan 2022","2022","10","","2497","2514","The oil and gas industry involves a high level of operational expenditure and often faces high risks of asset safety and operational failures. It has never been so important to monitor and control the oil field operations remotely in real-time to ensure safety and efficiency. The traditional monitoring and control systems for oil field operations are typically centralized, prone to failure, and lack efficiency. Blockchain technology mitigates the centralization problem by creating a decentralized, immutable and transparent control environment for automatic monitoring and control of industrial operations. In this study, we propose a blockchain-based IoT framework for real-time monitoring and control to increase oil field operation and asset efficiency and safety. We present the key components of the framework, including the system architecture, operation flows, algorithms, and smart contracts. As a proof-of-concept modeling, a smart contract is developed and validated on a blockchain test platform. A comparative analysis shows the advantages of using blockchain technology and smart contract to provide trustworthy and automatic monitoring and control for oil field operations.","2169-3536","","10.1109/ACCESS.2021.3139582","North Dakota Established Program to Stimulate Competitive Research (ND EPSCoR); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9665728","Internet of Things;blockchain;smart contract;remote monitoring;control;industrial operations","Blockchains;Oils;Smart contracts;Remote monitoring;Peer-to-peer computing;Natural gas industry;Internet of Things","","13","","51","CCBY","30 Dec 2021","","","IEEE","IEEE Journals"
"An Analysis of the Thermal Behavior and Effects of Circular Quartz Crystal Resonators for Microbalance Applications","Q. Huang; J. Wang; N. Gan; T. Ma; B. Huang; B. Neubig; D. Johannsmann","Piezoelectric Device Laboratory, School of Mechanical Engineering and Mechanics, Ningbo University, Zhejiang, Ningbo, China; Piezoelectric Device Laboratory, School of Mechanical Engineering and Mechanics, Ningbo University, Zhejiang, Ningbo, China; Piezoelectric Device Laboratory, School of Mechanical Engineering and Mechanics, Ningbo University, Zhejiang, Ningbo, China; Piezoelectric Device Laboratory, School of Mechanical Engineering and Mechanics, Ningbo University, Zhejiang, Ningbo, China; Piezoelectric Device Laboratory, School of Mechanical Engineering and Mechanics, Ningbo University, Zhejiang, Ningbo, China; AXTAL GmbH & Company KG, Lobbach, Germany; Institute of Physical Chemistry, Clausthal University of Technology, Clausthal Zellerfel, Germany","IEEE Transactions on Ultrasonics, Ferroelectrics, and Frequency Control","29 Jul 2022","2022","69","8","2569","2578","The accurate calculation of vibration frequency is essential in design of circular quartz crystal resonators which are the core elements of high-precision microbalances used for testing and measurement. Currently, the prediction of thermal effects on frequency through an analytical analysis is still in its developmental stage, mainly due to the complexity of solving the 3-D equations with the consideration of asymmetric structure of resonators and electrodes along with material anisotropy. By using a scalar differential equation for vibrations with the eigen-displacement of thickness mode, the eigen-frequency of a plano-convex AT-cut circular quartz crystal plate with asymmetric electrodes is determined. Furthermore, the temperature effect in the scalar differential equation is successfully obtained by incorporating the incremental thermal field theory into the 1-D analysis. The theoretical results agree well with the experimental data. The combination of the thermal field and the thickness model for circular quartz crystal resonators can realize a full analysis of thermal properties in vital applications such as high-sensitivity microbalance sensors.","1525-8955","","10.1109/TUFFC.2022.3182878","National Natural Science Foundation of China(grant numbers:12172183,11672142); Technology Innovation 2025 Program of Municipality of Ningbo(grant numbers:2019B10122); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796590","Circular;microbalance;quartz;resonator;temperature;vibration","Resonators;Quartz crystals;Resonant frequency;Vibrations;Mathematical models;Temperature sensors;Electrodes","Computer Simulation;Electrodes;Quartz;Vibration","3","","52","IEEE","15 Jun 2022","","","IEEE","IEEE Journals"
"Space-Crossing: Community-Based Data Forwarding in Mobile Social Networks Under the Hybrid Communication Architecture","Z. Li; C. Wang; S. Yang; C. Jiang; I. Stojmenovic","College of Information Science and Technology, Donghua University, Shanghai, China; Department of Computer Science, Tongji University, Shanghai, China; Department of Computer Science, Tongji University, Shanghai, China; Department of Computer Science, Tongji University, Shanghai, China; School of Electrical Engineering and Computer Science (SEECS), University of Ottawa, Ottawa, ON, Canada",IEEE Transactions on Wireless Communications,"7 Sep 2015","2015","14","9","4720","4727","In this paper, we study two tightly coupled issues, space-crossing community detection and its influence on data forwarding in mobile social networks (MSNs). We propose a communication framework containing the hybrid underlying network with access point (AP) support for data forwarding and the base stations for managing most of control traffic. The concept of physical proximity community can be extended to be one across the geographical space, because APs can facilitate the communication among long-distance nodes. Space-crossing communities are obtained by merging some pairs of physical proximity communities. Based on the space-crossing community, we define two cases of node local activity and use them as the input of inner product similarity measurement. We design a novel data forwarding algorithm Social Attraction and Infrastructure Support (SAIS), which applies similarity attraction to route to neighbor more similar to destination, and infrastructure support phase to route the message to other APs within common connected components. We evaluate our SAIS algorithm on real-life datasets from MIT Reality Mining and University of Illinois Movement (UIM). Results show that space-crossing community plays a positive role in data forwarding in MSNs. Based on this new type of community, SAIS achieves a better performance than existing popular social community-based data forwarding algorithms in practice, including Simbet, Bubble Rap and Nguyen's Routing algorithms.","1558-2248","","10.1109/TWC.2015.2424965","Integrated Project for Major Research Plan of the National Natural Science Foundation of China(grant numbers:91218301); Key Program for International S&T Cooperation Projects of China(grant numbers:2012DFG11580); Shanghai ShuGuang Project(grant numbers:14SG20); Shanghai Rising-Star Program(grant numbers:14QA1403700); National Natural Science Foundation of China (NSFC)(grant numbers:61202383); Program for New Century Excellent Talents in University (NCET)(grant numbers:NCET-12-0414); Natural Science Foundation of Shanghai(grant numbers:12ZR1451200); Research Fund for the Doctoral Program of Higher Education of China (RFDP)(grant numbers:20120072120075); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7091032","mobile social networks;infrastructure support;space-crossing community;data forwarding;Mobile social networks;infrastructure support;space-crossing community;data forwarding","Communities;Mobile communication;Local activities;Mobile computing;Base stations;Ad hoc networks;Social network services","","13","","59","IEEE","21 Apr 2015","","","IEEE","IEEE Journals"
"Learning-Based Application-Agnostic 3D NoC Design for Heterogeneous Manycore Systems","B. K. Joardar; R. G. Kim; J. R. Doppa; P. P. Pande; D. Marculescu; R. Marculescu","Washington State University, Pullman, WA, USA; Colorado State University, Fort Collins, CO, USA; Washington State University, Pullman, WA, USA; Washington State University, Pullman, WA, USA; Carnegie Mellon University, Pittsburgh, PA, USA; Carnegie Mellon University, Pittsburgh, PA, USA",IEEE Transactions on Computers,"8 May 2019","2019","68","6","852","866","The rising use of deep learning and other big-data algorithms has led to an increasing demand for hardware platforms that are computationally powerful, yet energy-efficient. Due to the amount of data parallelism in these algorithms, high-performance three-dimensional (3D) manycore platforms that incorporate both CPUs and GPUs present a promising direction. However, as systems use heterogeneity (e.g., a combination of CPUs, GPUs, and accelerators) to improve performance and efficiency, it becomes more pertinent to address the distinct and likely conflicting communication requirements (e.g., CPU memory access latency or GPU network throughput) that arise from such heterogeneity. Unfortunately, it is difficult to quickly explore the hardware design space and choose appropriate tradeoffs between these heterogeneous requirements. To address these challenges, we propose the design of a 3D Network-on-Chip (NoC) for heterogeneous manycore platforms that considers the appropriate design objectives for a 3D heterogeneous system and explores various tradeoffs using an efficient machine learning (ML)-based multi-objective optimization (MOO) technique. The proposed design space exploration considers the various requirements of its heterogeneous components and generates a set of 3D NoC architectures that efficiently trades off these design objectives. Our findings show that by jointly considering these requirements (latency, throughput, temperature, and energy), we can achieve 9.6 percent better Energy-Delay Product on average at nearly iso-temperature conditions when compared to a thermally-optimized design for 3D heterogeneous NoCs. More importantly, our results suggest that our 3D NoCs optimized for a few applications can be generalized for unknown applications as well. Our results show that these generalized 3D NoCs only incur a 1.8 percent (36-tile system) and 1.1 percent (64-tile system) average performance loss compared to application-specific NoCs.","1557-9956","","10.1109/TC.2018.2889053","National Science Foundation(grant numbers:CNS-1564014,CNS-1564022,CCF 1514269); Army Research Office(grant numbers:W911NF-17-1-0485); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8585068","Heterogeneous architectures;manycore systems;multi-objective optimization;network-on-chip","Three-dimensional displays;Graphics processing units;Traffic control;Optimization;Throughput;Data transfer;Integrated circuits","","48","","44","IEEE","21 Dec 2018","","","IEEE","IEEE Journals"
"CasCADe: A Novel 4D Visualization System for Virtual Construction Planning","P. Ivson; D. Nascimento; W. Celes; S. D. Barbosa","Tecgraf Institute, PUC-Rio; Tecgraf Institute, PUC-Rio; Tecgraf Institute, PUC-Rio; Informatics Department, PUC-Rio",IEEE Transactions on Visualization and Computer Graphics,"4 Dec 2017","2018","24","1","687","697","Building Information Modeling (BIM) provides an integrated 3D environment to manage large-scale engineering projects. The Architecture, Engineering and Construction (AEC) industry explores 4D visualizations over these datasets for virtual construction planning. However, existing solutions lack adequate visual mechanisms to inspect the underlying schedule and make inconsistencies readily apparent. The goal of this paper is to apply best practices of information visualization to improve 4D analysis of construction plans. We first present a review of previous work that identifies common use cases and limitations. We then consulted with AEC professionals to specify the main design requirements for such applications. These guided the development of CasCADe, a novel 4D visualization system where task sequencing and spatio-temporal simultaneity are immediately apparent. This unique framework enables the combination of diverse analytical features to create an information-rich analysis environment. We also describe how engineering collaborators used CasCADe to review the real-world construction plans of an Oil & Gas process plant. The system made evident schedule uncertainties, identified work-space conflicts and helped analyze other constructability issues. The results and contributions of this paper suggest new avenues for future research in information visualization for the AEC industry.","1941-0506","","10.1109/TVCG.2017.2745105","Conselho Nacional de Desenvolvimento Científico e Tecnológico(grant numbers:140933/2014-0,311620/2014-0,309828/2015-5,453996/2014-0); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8019847","Visualization in physical sciences and engineering;design studies;integrating spatial and non-spatial data visualization;task and requirements analysis","Three-dimensional displays;Visualization;Data visualization;Solid modeling;Schedules;Animation","","41","","119","IEEE","29 Aug 2017","","","IEEE","IEEE Journals"
"RAPID: Approximate Pipelined Soft Multipliers and Dividers for High Throughput and Energy Efficiency","Z. Ebrahimi; M. Zaid; M. Wijtvliet; A. Kumar","Department of Computer Science, Technische Universität Dresden, Dresden, Germany; Department of Computer Science, Technische Universität Dresden, Dresden, Germany; Department of Computer Science, Technische Universität Dresden, Dresden, Germany; Department of Computer Science, Technische Universität Dresden, Dresden, Germany",IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems,"17 Feb 2023","2023","42","3","712","725","The rapid updates in error-resilient applications along with their quest for high throughput has motivated designing fast approximate functional units for field-programmable gate arrays (FPGAs). Studies have proposed various imprecise functional techniques, albeit posed with three shortcomings: first, most existing inexact multipliers and dividers are specialized for application-specific integrated circuit (ASIC) platforms. Therefore, due to the architectural differences of underlying building blocks in FPGA and ASIC, ASIC-customized designs have not yielded comparable improvements when directly synthesized and ported to FPGAs. Second, state-of-the-art (SoA) approximate units are substituted, mostly in a single kernel of a multikernel application. Moreover, the end-to-end assessment is adopted on the quality of results (QoR), but not on the overall gained performance. Finally, the existing imprecise components are not designed to support a pipelined approach, which could boost the operating frequency/throughput of, e.g., division-included applications. In this article, we propose RAPID, the first pipelined approximate multiplier and divider architectures, customized for FPGAs. The proposed units efficiently utilize 6-input look-up tables (6-LUTs) and fast carry chains to implement Mitchell’s approximate algorithms. Our novel error-refinement scheme not only has negligible overhead over the baseline Mitchell’s approach but also boosts its accuracy to 99.4% for arbitrary size of multiplication and division. Experimental results obtained with Xilinx Vivado demonstrate the efficiency of the proposed pipelined and nonpipelined RAPID multipliers and dividers over accurate counterparts. In particular, the 4-stage pipelined architecture of a 32-bit RAPID multiplier (divider) enables  $3.3\times $  ( $5.1\times $ ) higher throughput,  $2.3\times $  ( $6.8\times $ ) higher throughput/Watt, and 52% (31%) savings of look-up tables (LUTs), over their 4-stage pipelined, accurate Intellectual Property (IP) counterparts. Moreover, the end-to-end evaluations of nonpipelined RAPID, deployed in three multikernel applications in the domains of biosignal processing, image processing, and moving object tracking for unmanned aerial vehicles (UAVs) indicate up to 35%, 33%, and 45% improvements in area, latency, and area-delay-product (ADP), respectively, over accurate kernels, with negligible loss in QoR. To springboard future research in reconfigurable and approximate computing communities, our implementations will be available and opensourced at https://cfaed.tu-dresden.de/pd-downloads.","1937-4151","","10.1109/TCAD.2022.3184928","German Research Foundation Deutsche Forschungsgemeinschaft (DFG) through the Project X-ReAp: Cross(X)-Layer Runtime Reconfigurable Approximate Architecture(grant numbers:380524764); European Social Fund (ESF) through the Project Re-Learning: Self-Learning and Flexible Electronics Through Inherent Component Reconfiguration(grant numbers:100382146); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9802734","Approximate computing;biosignal processing;divider;energy efficiency;field-programmable gate arrays (FPGAs);high throughput;Mitchell’s algorithm;multiplier;pipeline;unmanned aerial vehicles (UAVs)","Field programmable gate arrays;Table lookup;Pipeline processing;Computer architecture;Compressors;Approximation algorithms;Throughput","","10","","76","IEEE","21 Jun 2022","","","IEEE","IEEE Journals"
"A Non-Exclusive Multi-Class Convolutional Neural Network for the Classification of Functional Requirements in AUTOSAR Software Requirement Specification Text","S. Jp; V. K. Menon; K. Soman; A. K. R. Ojha","Center for Computational Engineering and Networking, Amrita School of Engineering, Amrita Vishwa Vidyapeetham, Coimbatore, India; KeepFlying, 5 Tampines Central 6, Singapore; Center for Computational Engineering and Networking, Amrita School of Engineering, Amrita Vishwa Vidyapeetham, Coimbatore, India; Data Science Institute, National University of Ireland Galway, Galway, Ireland",IEEE Access,"15 Nov 2022","2022","10","","117707","117714","Software Requirement Specification (SRS) describes a software system to be developed that captures the functional, non-functional, and technical aspects of the stakeholder’s requirements. Retrieval and extraction of software information from SRS are essential to the development of software product line (SPL). Albeit Natural Language Processing (NLP) techniques, such as information retrieval and standard machine learning, have been advocated in the recent past as a semi-automatic means of optimising requirements specifications, they have not been widely embraced. The complexity in the organization’s information makes requirement analysis intricately a challenging task. The interdependence of subsystems and within an organisation drives this complexity. A plain multi-class classification framework may not address this issue. Hence, this paper propounds an automated non-exclusive approach for classification of functional requirements from SRS, using a deep learning framework. Specifically, Word2Vec and FastText word embeddings are utilised for document representation for training a convolutional neural network (CNN). The study was carried out by the compilation of manually categorised relevant enterprise data (AUTomotive Open System ARchitecture (AUTOSAR)), which were also employed for model training. Over a convolutional neural network, the impact of data trained with Word2Vec and FastText word embeddings from SRS documentation were compared to pre-trained word embeddings models, available online.","2169-3536","","10.1109/ACCESS.2022.3217752","Science Foundation Ireland (SFI)(grant numbers:SFI/12/RC/2289_P2 Insight_2); Panlingua Language Processing LLP; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9931679","Functional requirement;software requirement specification;convolutional neural network;multi-layer perceptron;word embedding","Software engineering;Convolutional neural networks;Documentation;Support vector machines;Semantics;Automotive engineering;Embedded systems","","2","","26","CCBY","28 Oct 2022","","","IEEE","IEEE Journals"
"Hierarchical Fault Diagnosis and Health Monitoring in Satellites Formation Flight","A. Barua; K. Khorasani","Department of Electrical and Computer Engineering, Concordia University, Montreal, QUE, Canada; Department of Electrical and Computer Engineering, Concordia University, Montreal, QUE, Canada","IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)","17 Feb 2011","2011","41","2","223","239","Current spacecraft health monitoring and fault-diagnosis practices involve around-the-clock limit-checking and trend analysis on large amount of telemetry data. They do not scale well for future multiplatform space missions due the size of the telemetry data and an increasing need to make the long-duration missions cost-effective by limiting the operations team personnel. The need for efficient utilization of telemetry data achieved by employing machine learning and reasoning algorithms has been pointed out in the literature for enhancing diagnostic performance and assisting the less-experienced personnel in performing monitoring and diagnosis tasks. In this paper, we develop a systematic and transparent fault-diagnosis methodology within a hierarchical fault-diagnosis framework for a satellites formation flight. We present our proposed hierarchical decomposition framework through a novel Bayesian network, whose structure is developed from the knowledge of component health-state dependencies. We have developed a methodology for specifying the network parameters that utilizes both node fault-diagnosis performance data and domain experts' beliefs. Our proposed model development procedure reduces the demand for expert's time in eliciting probabilities significantly. Our proposed approach provides the ground personnel with an ability to perform diagnostic reasoning across a number of subsystems and components coherently. Due to the unavailability of real formation flight data, we demonstrate the effectiveness of our proposed methodology by using synthetic data of a leader-follower formation flight architecture. Although our proposed approach is developed from the satellite fault-diagnosis perspective, it is generic and is targeted toward other types of cooperative fleet vehicle diagnosis problems.","1558-2442","","10.1109/TSMCC.2010.2049994","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5499154","Bayesian networks (BN);decision support systems (DSS);fault diagnosis;integrated vehicle health management (IVHM);model-based reasoning (MBR);spacecraft formation flight","Fault diagnosis;Satellites;Telemetry;Personnel;Space vehicles;Space missions;Machine learning;Machine learning algorithms;Condition monitoring;Bayesian methods","","28","","51","IEEE","1 Jul 2010","","","IEEE","IEEE Journals"
"Framework for Performance Assessment of Heterogeneous Robotic Systems","Z. Bi; Z. Miao; B. Zhang; C. W. J. Zhang","School of Mechatronic Engineering and Automation, Shanghai University, Shanghai, China; School of Mechatronic Engineering and Automation, Shanghai University, Shanghai, China; School of Mechatronic Engineering and Automation, Shanghai University, Shanghai, China; Department of Mechanical Engineering, University of Saskatchewan, Saskatoon, SK, Canada",IEEE Systems Journal,"9 Mar 2021","2021","15","1","1191","1201","In a dynamic environment, a manufacturing system should be reconfigurable to make the products with lot size of one and a high product mix in mass customization. A manufacturing system is continuously evolved to make new products at different time scales and ensure uninterrupted productions when internal or external changes occur. System evolution relates to add, remove, upgrade components, and reconfigure the system at different levels and scopes. However, scientific methods and tools are lacking to support designers in reconfiguring a system subject to given changes. This becomes a big hurdle to adopt automated solutions in small- and medium-sized enterprises. To support system reconfiguration, we propose a generic framework and methods to assess the performance of heterogeneous robotic systems or components. The proposed methods can also help 1) designers to select components for an integrated solution based on the needs and 2) robot manufacturers to identify the weaknesses of their products.","1937-9234","","10.1109/JSYST.2020.2990892","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9095364","Composability;model-driven engineering;modularity;object-oriented framework;performance assessment;robotic testing standards;small- and medium-sized enterprises (SMEs)","Manufacturing systems;Tools;Robot sensing systems;Complexity theory;Object oriented modeling","","12","","66","IEEE","18 May 2020","","","IEEE","IEEE Journals"
"Deep Multimodal Complementarity Learning","D. Wang; T. Zhao; W. Yu; N. V. Chawla; M. Jiang","Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN, USA; Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN, USA; Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN, USA; Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN, USA; Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN, USA",IEEE Transactions on Neural Networks and Learning Systems,"30 Nov 2023","2023","34","12","10213","10224","Complementarity plays a significant role in the synergistic effect created by different components of a complex data object. Complementarity learning on multimodal data has fundamental challenges of representation learning because the complementarity exists along with multiple modalities and one or multiple items of each modality. Also, an appropriate metric is needed for measuring the complementarity in the representation space. Existing methods that rely on similarity-based metrics cannot adequately capture the complementarity. In this work, we propose a novel deep architecture for systematically learning the complementarity of components from multimodal multi-item data. The proposed model consists of three major modules: 1) unimodal aggregation for extracting the intramodal complementarity; 2) cross-modal fusion for extracting the intermodal complementarity at the modality level; and 3) interactive aggregation for extracting the intermodal complementarity at the item level. To quantify complementarity, we utilize the TUBE distance metric to measure the difference between the composited data object and its label in the representation space. Experiments on three real datasets show that our model outperforms the state-of-the-art by +6.8% of mean reciprocal rank (MRR) on object classification and +3.0% of MRR on hold-out item prediction. Qualitative analyses reveal that complementarity is significantly different from similarity.","2162-2388","","10.1109/TNNLS.2022.3165180","NSF(grant numbers:IIS-1849816,CCF-1901059,IIS-2119531,IIS-2146761); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9758834","Complementarity modeling;deep learning;multimodal machine learning","Electron tubes;Measurement;Data models;Task analysis;Learning systems;Visualization;Representation learning;Deep learning;Multisensory integration","","9","","45","IEEE","18 Apr 2022","","","IEEE","IEEE Journals"
"Scattering Matrix Retrieval Using Full-Polarimetric GNSS-R","J. F. Munoz-Martin; N. Rodriguez-Alvarez; X. Bosch-Lluis; K. Oudrhiri","Signal Processing and Networks Group, Jet Propulsion Laboratory/California Institute of Technology, Pasadena, CA, USA; Planetary Radar Radio Science Systems Group, Jet Propulsion Laboratory/California Institute of Technology, Pasadena, CA, USA; Signal Processing and Networks Group, Jet Propulsion Laboratory/California Institute of Technology, Pasadena, CA, USA; Communication Architectures and Research Section, Jet Propulsion Laboratory/California Institute of Technology, Pasadena, CA, USA",IEEE Transactions on Geoscience and Remote Sensing,"25 Jun 2024","2024","62","","1","15","This article presents the mathematical background and modeling for full-polarimetric Global Navigation Satellite System Reflectometry (GNSS-R) receivers for nonnegligible cross-polar component in the scattered signal. A signal model is presented to retrieve the Stokes parameters using the Mironov model to estimate the soil surface’s dielectric constant. This article compares data collected by the SMAP-Reflectometry (SMAP-R) receiver and the proposed signal model, emphasizing the need to consider the cross-polar component ( $S_{\mathrm {hv}}$ ). Simulations obtained without considering the cross-polar component have poor agreement in all Stokes parameters. A model is implemented using a complex cross-polar component resulting in notable improvements in the bias and unbiased root mean square difference (ubRMSD) between the modeled and measured SMAP-R Stokes parameters. Furthermore, a methodology is proposed for estimating the  $S_{\mathrm {hv}}$  component using SMAP-R and a soil moisture (SM) reference dataset. An analysis of  $S_{\mathrm {hv}}$  reveals a moderate correlation with vegetation water content (VWC) and surface roughness ( $\sigma _{\mathrm {slp}}$ ). We developed an SM model by estimating  $S_{\mathrm {hv}}$  using both VWC and  $\sigma _{\mathrm {slp}}$ , showing the potential of full-polarimetric GNSS-R to provide SM estimates upon proper characterization of the cross-polar component. Results show the ubRMSD of 0.09 m3/m3 with respect to the in situ soil moisture network (ISMN). Finally, this study establishes that an RMSD better than 0.02 when estimating  $S_{\mathrm {hv}}$  is required for an SM product accuracy better than 0.07 m3/m3 for polarimetric GNSS-R SM retrievals.","1558-0644","","10.1109/TGRS.2024.3414261","Earth Sciences Division(grant numbers:80NM0018F0618,NNH19ZDA001N-SMAP); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10556619","Global Navigation Satellite System Reflectometry (GNSS-R);sensor design/calibration;soil;vegetation","Stokes parameters;Scattering;Soil moisture;Receivers;Vegetation mapping;Radar;Radar antennas","","","","42","IEEE","13 Jun 2024","","","IEEE","IEEE Journals"
"Design of an Optimal Scheduling Control System for Smart Manufacturing Processes in Tobacco Industry","X. Liu; J. Li; H. Wang; W. Jia; J. Yang; Z. Guo","Qingzhou Cigarette Factory, China Tobacco Shandong Industrial Co.Ltd., Qingzhou, China; Qingzhou Cigarette Factory, China Tobacco Shandong Industrial Co.Ltd., Qingzhou, China; Qingzhou Cigarette Factory, China Tobacco Shandong Industrial Co.Ltd., Qingzhou, China; Qingzhou Cigarette Factory, China Tobacco Shandong Industrial Co.Ltd., Qingzhou, China; School of Artificial Intelligence, Chongqing Technology and Business University, Chongqing, China; School of Artificial Intelligence, Chongqing Technology and Business University, Chongqing, China",IEEE Access,"6 Apr 2023","2023","11","","33027","33036","The whole process of tobacco production is composed of many components, in which their operation and administration are currently independent. It is required to deploy smart manufacturing workflow for the whole production process, in order to realize centralized effective global scheduling. This requires an advanced administration control platform that has strong abilities of multisource data integration and automatic decision support. To bridge such research gap, this paper designs an optimal scheduling control system for smart manufacturing processes of tobacco industry. First of all, this work discusses major characteristics of future-generation production control patterns in intelligent tobacco factories (ITF). Then, a five-layer architecture for optimal scheduling control of ITF is proposed, which contains Internet-of-Things layer, centralized control layer, model layer, platform layer and operation layer. In addition, a production scheduling optimization strategy is also developed for the proposed system to serve as the software algorithm that drives the running of whole smart manufacturing processes. Finally, this paper presents a comparative analysis of the proposed system’s transformation in a cigarette factory. Naturally, the effectiveness of the proposed production optimization scheduling strategy is verified through simulation.","2169-3536","","10.1109/ACCESS.2023.3261883","China Tobacco Shandong Industrial Co., Ltd.; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10081360","Smart manufacturing;optimal scheduling control;Internet of Things;production decision","Production;Manufacturing;Industries;Production facilities;Centralized control;Data models;Process control","","","","30","CCBY","27 Mar 2023","","","IEEE","IEEE Journals"
"A New Model Based on Soft Computing for Evaluation and Selection of Software Products","Y. Fernandez Perez; C. Cruz Corona; J. L. Verdegay Galdeano","Univ. de Cienc. Informaticas, Havana, Cuba; Universidad de Granada, Granada, AndalucÃ­a, ES; Universidad de Granada, Granada, AndalucÃ­a, ES",IEEE Latin America Transactions,"21 May 2018","2018","16","4","1186","1192","This paper proposes a new model for assessment and selection of software products according to their quality. This model is able to implement elements such as the manipulation of heterogeneous, ambiguous, imprecise information coming from different sources; the analysis of the interdependence between criteria; the incorporation of essential criteria and the independence of data in the aggregation process. The assessment model was applied to three products of software demonstrating it is operable, reliable, precise and easy to understand for its application to industry.","1548-0992","","10.1109/TLA.2018.8362155","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8362155","evaluation and selection of software products;multi-criteria decision methods;quality model;soft computing","Software;Computational modeling;IEEE transactions;ISO Standards;Adaptation models;Analytical models;Data models","","5","","","IEEE","21 May 2018","","","IEEE","IEEE Journals"
"Artificial Intelligence-Based Sensors for Next Generation IoT Applications: A Review","S. C. Mukhopadhyay; S. K. S. Tyagi; N. K. Suryadevara; V. Piuri; F. Scotti; S. Zeadally","Macquarie University, Sydney, NSW, Australia; Zhongyuan University of Technology, Zhengzhou, China; University of Hyderabad, Hyderabad, India; Università degli Studi di Milano, Milan, Italy; Università degli Studi di Milano, Milan, Italy; University of Kentucky, Lexington, KY, USA",IEEE Sensors Journal,"12 Nov 2021","2021","21","22","24920","24932","Sensors play a vital role in our daily lives and are an essential component for Internet of Things (IoT) based systems as they enable the IoT to collect data to take smart and intelligent decisions. Recent advances in IoT systems, applications, and technologies, including industrial Cyber-Physical Systems (CPSs), are being supported by a wide range of different types of sensors based on artificial intelligence (AI). These smart AI-based sensors are typically characterized by onboard intelligence and have the ability to communicate collaboratively or through the Internet. To achieve the high level of automation required in today’s smart IoT applications, sensors incorporated into nodes must be efficient, intelligent, context-aware, reliable, accurate, and connected. Such sensors must also be robust, safety- and privacy-aware for users interacting with them. Sensors leveraging advanced AI technologies, new capabilities have recently emerged which have the potential to detect, identify, and avoid performance degradation and discover new patterns. Along with knowledge from complex sensor datasets, they can promote product innovation, improve operation level, and open up novel business models. We review sensors, smart data processing, communication protocol, and artificial intelligence which will enable the deployment of AI-based sensors for next-generation IoT applications.","1558-1748","","10.1109/JSEN.2021.3055618","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9340338","Artificial intelligence;Internet of Things;sensors;smart sensors;wireless sensor networks;network;protocol","Sensors;Intelligent sensors;Internet of Things;Computer architecture;Artificial intelligence;Wireless sensor networks;Sensor systems","","98","","142","IEEE","29 Jan 2021","","","IEEE","IEEE Journals"
"BASIC Codes: Low-Complexity Regenerating Codes for Distributed Storage Systems","H. Hou; K. W. Shum; M. Chen; H. Li","Shenzhen Key Lab of Information theory and Future Internet architecture, School of Electronic and Computer Engineering, Peking University Shenzhen Graduate School, Shenzhen, China; Institute of Network Coding, The Chinese University of Hong Kong, Hong Kong; Department of Information Engineering, The Chinese University of Hong Kong, Hong Kong; Shenzhen Key Lab of Information theory and Future Internet architecture, Shenzhen Engineering Laboratory of Converged Networks, School of Electronic and Computer Engineering, Peking University Shenzhen Graduate School, Shenzhen, China",IEEE Transactions on Information Theory,"19 May 2016","2016","62","6","3053","3069","In distributed storage systems, regenerating codes can achieve the optimal tradeoff between storage capacity and repair bandwidth. However, a critical drawback of existing regenerating codes, in general, is the high coding and repair complexity, since the coding and repair processes involve expensive multiplication operations in finite field. In this paper, we present a design framework of regenerating codes, which employ binary addition and bitwise cyclic shift as the elemental operations, named BASIC regenerating codes. The proposed BASIC regenerating codes can be regarded as a concatenated code with the outer code being a binary parity-check code, and the inner code being a regenerating code utilizing the binary parity-check code as the alphabet. We show that the proposed functional-repair BASIC regenerating codes can achieve the fundamental tradeoff curve between the storage and repair bandwidth asymptotically of functional-repair regenerating codes with less computational complexity. Furthermore, we demonstrate that the existing exact-repair product-matrix construction of regenerating codes can be modified to exact-repair BASIC product-matrix regenerating codes with much less encoding, repair, and decoding complexity from the theoretical analysis, and with less encoding time, repair time, and decoding time from the implementation results.","1557-9654","","10.1109/TIT.2016.2553670","National Basic Research Program of China(grant numbers:2012CB315904,2013CB336700); Natural Fund of Guangdong Province(grant numbers:S2013020012822); Shenzhen Basic Research Project(grant numbers:SZJCYJ20150331100723974,SZJCYJ20140417144423192); University Grants Committee, Hong Kong, through the Area of Excellence Grant Project(grant numbers:AoE/E-02/08,14209115,CUHK14209515); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7452376","Regenerating codes;distributed storage systems;low complexity;binary parity-check code;Regenerating codes;distributed storage systems;low complexity;binary parity-check code","Maintenance engineering;Encoding;Bandwidth;Computational complexity;Parity check codes;Decoding","","72","2","35","IEEE","13 Apr 2016","","","IEEE","IEEE Journals"
"Prediction of Myopia Eye Axial Elongation With Orthokeratology Treatment via Dense I2I Based Corneal Topography Change Analysis","D. Rong; Z. Zhao; Y. Wu; B. Ke; B. Ni","Department of Electrical Engineering, Shanghai Jiao Tong University, Shanghai, China; Department of Electrical Engineering, Shanghai Jiao Tong University, Shanghai, China; Department of Ophthalmology, Shanghai General Hospital, School of Medicine, Shanghai Jiao Tong University, Shanghai, China; Department of Ophthalmology, Shanghai General Hospital, School of Medicine, Shanghai Jiao Tong University, Shanghai, China; Department of Electrical Engineering, Shanghai Jiao Tong University, Shanghai, China",IEEE Transactions on Medical Imaging,"5 Mar 2024","2024","43","3","1149","1164","While orthokeratology (OK) has shown effective to slow the progression of myopia, it remains unknown how spatially distributed structural stress/tension applying to different regions affects the change of corneal geometry, and consecutive the outcome of myopia control, at fine-grained detail. Acknowledging that the underlying working mechanism of OK lens is essentially mechanics induced refractive parameter reshaping, in this study, we develop a novel mechanics rule guided deep image-to-image learning framework, which densely predicts patient’s corneal topography change according to treatment parameters (lens geometry, wearing time, physiological parameters, etc.), and consecutively predicts the influence on eye axial length change after OK treatment. Encapsulated in a U-shaped multi-resolution map-to-map architecture, the proposed model features two major components. First, geometric and wearing parameters of OK lens are spatially encoded with convolutions to form a multi-channel input volume/tensor for latent encodings of external stress/tension applied to different regions of cornea. Second, these external latent force maps are progressively down-sampled and injected into this multi-scale architecture for predicting the change of corneal topography map. At each feature learning layer, we formally derive a mathematic framework that simulates the physical process of corneal deformation induced by lens-to-cornea interaction and corneal internal tension, which is reformulated into parameter learnable cross-attention/self-attention modules in the context of transformer architecture. A total of 1854 eyes of myopia patients are included in the study and the results show that the proposed model precisely predicts corneal topography change with a high PSNR as 28.45dB, as well as a significant accuracy gain for axial elongation prediction (i.e., 0.0276 in MSE). It is also demonstrated that our method provides interpretable associations between various OK treatment parameters and the final control effect. Our project code package is available at https://github.com/Rongdingyi/PhyIntNet.","1558-254X","","10.1109/TMI.2023.3331488","National Natural Science Foundation of China(grant numbers:82070992); Medical Engineering Cross Research of Shanghai Jiao Tong University(grant numbers:YG2021ZD18); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10313298","Image-to-image;myopia progression control;transformer;U-Former;physics-inspired model","Lenses;Surfaces;Cornea;Force;Elongation;Geometry;Predictive models","Humans;Corneal Topography;Orthokeratologic Procedures;Myopia;Cornea;Refraction, Ocular","","","75","IEEE","8 Nov 2023","","","IEEE","IEEE Journals"
"Role of Coherent Systems in the Next DCI Generation","D. Tauber; B. Smith; D. Lewis; E. Muhigana; M. Nissov; D. Govan; J. Hu; Y. Zhou; J. Wang; W. -J. Jiang; R. Galeotti; F. Dell'Orto; R. Siano","R&D, Lumentum Operations LLC, San Jose, CA, USA; CTO Office, Lumentum Operations, LLC, Ottawa, ON, Canada; CTO Office, Lumentum Operations, LLC, San Jose, CA, USA; CTO Office, Lumentum Operations, LLC, San Jose, CA, USA; Product Line Management, Lumentum Operations LLC, San Jose, CA, USA; R&D, Lumentum Operations LLC, Paignton, U.K.; R&D, Lumentum Operations LLC, Paignton, U.K.; R&D, Lumentum Operations LLC, San Jose, CA, USA; R&D, Lumentum Operations LLC, San Jose, CA, USA; R&D, Lumentum Operations LLC, San Jose, CA, USA; R&D, Lumentum Operations LLC, Milan, Italy; R&D, Lumentum Operations LLC, Milan, Italy; R&D, Lumentum Operations LLC, Milan, Italy",Journal of Lightwave Technology,"31 Jan 2023","2023","41","4","1139","1151","Coherent transmission has been the standard for fiber optic communications for 100 Gbps rates and higher at distances of 40 km and above for more than a decade. In this paper, we review the continuing role of coherent systems for data center interconnect (DCI) networks at 400 Gbps, 800 Gbps and higher rates, including 1.6 and 3.2 Tbps. We review market factors driving demand for coherent DCI transmission solutions today and over the next five years, with attention to the transition to an IP over DWDM (IPoDWDM) architecture. Implications for small form factor, multi-vendor interoperable, low power consumption transceivers are investigated. We discuss in detail the technical challenges for compact pluggable transceivers operating at symbol rates of 120 Gbaud and above, including speed, interconnect, packaging and power consumption.","1558-2213","","10.1109/JLT.2023.3235820","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10013360","Coherent transmission;data center interconnect;DCI;optical fiber communications;optical networks;transceivers","Optical switches;Transceivers;Optical noise;Optical fiber networks;Optical fiber amplifiers;Optical amplifiers;Signal to noise ratio","","28","","39","IEEE","10 Jan 2023","","","IEEE","IEEE Journals"
"Efficient Online Self-Checking Modulo 2^n+1 Multiplier Design","W. Hong; R. Modugu; M. Choi","Department of Electrical and Electronic Engineering, Ulsan College, Ulsan, South Korea; Department of Electrical and Computer Engineering, Missouri University of Science and Technology, Rolla, MO, USA; Department of Electrical and Computer Engineering, Missouri University of Science and Technology, Rolla, MO, USA",IEEE Transactions on Computers,"28 Jul 2011","2011","60","9","1354","1365","Modulo 2n + 1 multiplier is one of the critical components in the area of data security applications such as International Data Encryption Algorithm (IDEA), digital signal processing, and fault-tolerant systems that demand high reliability and fault tolerance. Transient faults caused by electrical noise or external interference are resulting in soft errors which should be detected online. The effectiveness of the residue codes in the self-checking implementation of the modulo multipliers has been rarely explored. In this paper, an efficient hardware implementation of the self-checking modulo 2n + 1 multiplier is proposed based on the residue codes. Different check bases in the form 2c -1 or 2c + 1 (c ϵσ N) are selected for various values of the input operands. In the implementation of the modulo generators and modulo multipliers, novel multiplexor-based compressors are applied for efficient modulo 2n + 1 multipliers with less area and lower power consumption. In the final addition stage of the modulo multipliers and modulo generators, efficient sparse-tree-based inverted end around carry adders are used. The proposed architecture is capable of online detecting errors caused by faults on a single gate at a time. The experimental results show that the proposed self-checking modulo 2n + 1 multipliers have less area overhead and low performance penalty.","1557-9956","","10.1109/TC.2010.49","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5962404","Modulo 2^n+1 multiplier;residue arithmetic;arithmetic circuit design;compressor;online self-checking;international data encryption algorithm (IDEA).","Compressors;Adders;Circuit faults;Delay;Logic gates;Generators;Hardware","","14","","38","IEEE","28 Jul 2011","","","IEEE","IEEE Journals"
"Automatic Inspection of Seal Integrity in Sterile Barrier Packaging: A Deep Learning Approach","J. Z. Diaz; M. A. Farooq; P. Corcoran","Department of Electrical and Electronic Engineering, University of Galway, Galway, Ireland; Department of Electrical and Electronic Engineering, University of Galway, Galway, Ireland; Department of Electrical and Electronic Engineering, University of Galway, Galway, Ireland",IEEE Access,"15 Feb 2024","2024","12","","22904","22927","The digitalisation of visual tasks through imaging techniques and Computer Vision has the potential to disrupt the manner in which Advanced Manufacturing processes are deployed. In this study we collaborated with the manufacturing industry to investigate the effective usage of end-to-end convolutional neural networks (CNNs) to enable advanced manufacturing processes by inspecting the seal integrity of sterile barrier packaging in highly regulated products, such as Medical Devices. For this purpose, a novel ‘DS1’ dataset of labelled images representative of production samples was acquired in an industrial-like environment which is an open source for future research work. The core focus of this research is to address the common challenges associated with performing quality inspections in advanced manufacturing environments with the aim of detecting defects with very high impact but very low occurrence rates, by incorporating a set of pre-trained deep learning architectures. The performance of state-of-the-art CNNs is validated on unseen test data when trained in small and imbalanced datasets with low image variation and low pixel complexity. The study indicated that while CNN performance drops when datasets are imbalanced, some architectures are more resilient and capable of successfully classifying defects in small datasets in the order of a few hundred samples wherein as little as 5% of the samples are defective. Furthermore, this study also discusses the marginal impact of training with basic data augmentations and the tendency for models to overfit when trained with manufacturing datasets such as “DS1.”","2169-3536","","10.1109/ACCESS.2023.3348779","Boston Scientific Manufacturing Facility, Galway; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10378691","Machine vision;fault detection;neural networks;advanced manufacturing;quality control","Inspection;Medical devices;Biomedical imaging;Packaging;Manufacturing;Image segmentation;Machine vision;Quality control","","1","","43","CCBYNCND","1 Jan 2024","","","IEEE","IEEE Journals"
"A Bayesian Networks Approach to Estimate Engineering Change Propagation Risk and Duration","F. N. Yeasin; M. Grenn; B. Roberts","George Washington University, Washington, USA; George Washington University, Washington, USA; George Washington University, Washington, USA",IEEE Transactions on Engineering Management,"16 Jul 2020","2020","67","3","869","884","An engineering change (EC) is an alteration made to a system that has been released following a system design process. EC propagation is a series of ECs occurring due to dependencies among components of a product. ECs can consume up to 50% of the overall engineering efforts during the development of a complex system. Therefore, EC propagation prediction received considerable attention in past decades as the product development industries started to suffer from the negative impacts of change propagation. This paper evaluates the current approaches to EC propagation prediction and presents a dynamic Bayesian networks (DBNs) approach to estimate change propagation risk (CPR) as well as a novel approach to estimate EC durations. Literature research shows that although some studies have used design structure matrices to estimate CPR and the total redesign duration (TRD) due to change propagation, an approach that allows iteration while accounting for the conjunction of all impacts has not been explored. This paper aims to fill the gaps for calculating CPR using DBN and evaluating change propagation paths from a Split-and task outcome logic, which accounts for the conjunction of all component relationships. This paper compares the proposed method results with the existing CPR and engineering change duration estimation methods using a real-world dataset from a U.S. Navy shipbuilding program. The results indicate that the CPR can be calculated using the proposed method without the shortcomings of the existing method and the accuracy for estimating engineering change durations is increased.","1558-0040","","10.1109/TEM.2018.2884242","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8624331","Bayesian networks;engineering change duration;engineering change propagation","Bayes methods;Estimation;Industries;Task analysis;Predictive models","","18","","41","IEEE","23 Jan 2019","","","IEEE","IEEE Journals"
"An Empirical Evaluation of Enhanced Performance Softmax Function in Deep Learning","S. Mehra; G. Raut; R. D. Purkayastha; S. K. Vishvakarma; A. Biasizzo","Department of Electrical Engineering, Indian Institute of Technology Indore, Indore, India; Department of Electrical Engineering, Indian Institute of Technology Indore, Indore, India; Department of Electrical Engineering, Indian Institute of Technology Indore, Indore, India; Department of Electrical Engineering, Indian Institute of Technology Indore, Indore, India; Jožef Stefan Institute, Ljubljana, Slovenia",IEEE Access,"13 Apr 2023","2023","11","","34912","34924","This article present a highly efficient and performance-enhanced Softmax Function (SF) designed for a deep neural network accelerator. The SF is an essential component of deep learning models, primarily used in the classification layer, and also in hidden layers of advanced neural networks like Transformer and Capsule networks. The primary challenge of designing an efficient hardware architecture for SF is the complex exponential and division computational sub-blocks. To address this challenge, a hardware-optimized pipelined CORDIC-based architecture is proposed, leveraging the mutual exclusivity of the CO-ordinate Rotational DIgital Computer (CORDIC) algorithm, designed for enhanced throughput, area, and power. To maintain good accuracy in deep learning models, the proposed SF design undergoes a Pareto study that evaluates the variation of accuracy concerning the number of pipeline stages. The proposed design is quantized to 16-bit precision, and inference accuracy is validated for different datasets. The SF is prototyped using Xilinx Zynq FPGA, operating at 685MHz, and ASIC implementation is performed for 45nm technology node at 5GHz of maximum operating frequency. The design achieves a validation accuracy loss of less than 2% while reducing silicon area and Energy-Delay-Product (EDP) by  $12\times $ . Post-synthesis simulation results indicate that the proposed design outperforms state-of-the-art architectures, achieving  $3\times $  better performance in terms of area, power, and logic delay.","2169-3536","","10.1109/ACCESS.2023.3265327","Slovenian Research Agency (research core funding)(grant numbers:P2-0098); “Electronics Components and Systems for European Leadership” Joint Undertaking (ECSEL JU)(grant numbers:101007273 (DAIS),876038 (InSecTT),876659 (iRel40)); Ministry of Education, India; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10093848","Softmax function (SF);CORDIC algorithm;deep learning;hardware optimization;performance enhancement;pipeline stages","Computer architecture;Throughput;Hardware;Pipeline processing;Computational modeling;Iterative algorithms;Propagation delay","","7","","30","CCBY","6 Apr 2023","","","IEEE","IEEE Journals"
"Communication-Avoiding Fusion of GEMM-Based Convolutions for Deep Learning in the RISC-V GAP8 MCU","C. Ramírez; A. Castelló; H. Martínez; E. S. Quintana-Ortí","DISCA, Universitat Politècnica de València, Valencia, Spain; DISCA, Universitat Politècnica de València, Valencia, Spain; Electronic and Computer Engineering, Universidad de Córdoba, Córdoba, Spain; DISCA, Universitat Politècnica de València, Valencia, Spain",IEEE Internet of Things Journal,"25 Oct 2024","2024","11","21","35640","35653","Incorporating deep learning (DL) technologies to the edge is crucial for improving the security, privacy, and energy efficiency of the Internet of Things (IoT). In this scenario, the limitations of edge devices in terms of power dissipation, memory capacity, and processing power require a careful selection and optimization of algorithms for IoT DL applications. In this line, our work focuses on the convolution operator, a key component in deep neural networks for signal processing and computer vision. Specifically, the work aims at the efficient implementation of the lowering-based implementation of this operator, on the GAP8 parallel ultralow power platform (PULP), with the goal of mitigating the data transfer costs across the memory hierarchy. Our contributions include 1) an analytical model for estimating the parallel execution time, 2) the exploration of different configuration options, and 3) four variants of the algorithm that fuse several components to address memory bottlenecks in the method. Overall, our best fused variant provides a speedup of up to  $1.25\times $  over the baseline algorithm when applied to infer MobileNet-v1+ImageNet and VGG9+CIFAR10 using eight threads, and up to  $1.34\times $  for ResNet18+ImageNet.","2327-4662","","10.1109/JIOT.2024.3436937","MCIN/AEI/10.13039/501100011033(grant numbers:PID2020-113656RB,TED2021-129334B-I00); “EU NextGenerationEU/PRTR.”; Junta de Andalucía (POSTDOC_21_00025); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10620227","Convolution;convolutional neural networks (CNNs);cost analysis;deep learning (DL);edge processors;high performance","Convolution;Tensors;Transforms;Internet of Things;Signal processing algorithms;Memory management;Matrix decomposition","","","","22","CCBY","1 Aug 2024","","","IEEE","IEEE Journals"
"An Extended Building-In Reliability Methodology on Evaluating SRAM Reliability by Wafer-Level Reliability Systems","W. -T. K. Chien; F. Hao","Corporate Manufacturing SVP, Centrillion Technologies Taiwan, Hsinchu, Taiwan; Quality and Reliability Center, Semiconductor Manufacture International Corporation, Shanghai, China",IEEE Transactions on Device and Materials Reliability,"6 Mar 2020","2020","20","1","106","118","Advancement in integrated circuit (IC) brings a series of challenges on product reliability. In order to meet these challenges and fulfill customers' requirements, we introduced the methodology of building-in reliability (BIR) into whole stages during IC manufacturing. The wafer-level reliability (WLR) is an essential element of the BIR system. Significant amount of costs, resources, and times are saved from the early detections on reliability deficiencies at design and development stages. After successful mass production, hidden reliability risks can also be timely identified before shipment. Currently, the process reliability has been successfully evaluated by WLR platform. However, the product reliability, which covers much wider reliability factors, has not been effectively covered by WLR. Currently, we still rely on the conventional package-level reliability (PLR) tests to assess product reliability. In this paper, we report how the classical static random access memory (SRAM) is transplanted into the WLR system, which serves as an efficient platform to detect reliability weakness. In our extended BIR methodology, by reasonable test structure and pattern designs, proper electric parameters selections, test methods optimizations, we can thoughtfully consider inherent failure mechanisms and process fluctuations in order to build quantitative reliability models, which are essential to our proposed system. The quantitative reliability model was not seen in the similar WLR approaches and this may explain why these previous proposals failed. Finally, we report the obtained robust correlations between single-bit cell wear-out and package-level SRAM degradations, which is further validated by conventional HTOL tests. Our approaches provide opportunities not only on early detecting reliability weakness, but also on reliability assurance after product deliveries. These two contributions are essential and especially crucial for advanced technology developments.","1558-2574","","10.1109/TDMR.2020.2964999","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952800","Building-in reliability;process reliability;wafer-level reliability;product reliability;SRAM;package-level reliability","Semiconductor device reliability;Random access memory;Integrated circuit reliability;Reliability engineering;Stress;Aging","","6","","25","IEEE","8 Jan 2020","","","IEEE","IEEE Journals"
"A Quality Prediction and Parameter Optimization Approach for Turbine Blade Multistage Manufacturing","Q. Liu; V. S. Vassiliadis; Y. Wu; J. Zhang; C. Cheng; Y. Yuan","Institute of Artificial Intelligence, Huazhong University of Science and Technology, Wuhan, China; Retired Senior Lecturer, University of Cambridge, Cambridge, U.K.; MOE Key Lab of Intelligent Control and Image Processing, School of Artificial Intelligence and Automation, Huazhong University of Science and Technology, Wuhan, China; Wuxi Turbine Blade Company Ltd., Wuxi, China; MOE Key Lab of Intelligent Control and Image Processing, School of Artificial Intelligence and Automation, Huazhong University of Science and Technology, Wuhan, China; MOE Key Lab of Intelligent Control and Image Processing, School of Artificial Intelligence and Automation, Huazhong University of Science and Technology, Wuhan, China",IEEE/ASME Transactions on Mechatronics,"21 Feb 2024","2024","29","1","3","15","As core components of an aircraft engine, turbine blades are featured by complex curved surface with strict precision requirements in multistage manufacturing processes (MMPs). Hence, reliable quality prediction and parameter optimization strategy on MMPs have long been in great demand. However, most techniques focus on the precision improving of single-stage single-product manufacturing systems; these improvements are difficult to implement in MMPs with coordinate transformations among multiple machines. In this article, we propose a noninvasive feature-based quality prediction and parameter optimization framework for high-precision MMPs. In particular, rather than retrofitting sensors onto machinery after installation, this study presents an executable and noninvasive solution by using coordinate measuring machine (CMM) data as input features for prediction. Based on features of different stages of machining, a sequential multistep deep learning architecture is developed to predict the final product quality. A preheating optimization algorithm, modified from a local gradient search method, is used for the optimization of key initial machining features, which results are further improved by the L-BFGS method, thus increasing the final production quality. To estimate the effectiveness of the proposed framework, experiments are carried out on two series of aviation turbine blades with complex curved surfaces from the Wuxi Turbine Blade Company Ltd. China. CMM data at key stages (i.e., blade root milling and comprehensive accurate milling) are used as inputs to predict the final geometrical errors. Comparison results verify that the proposed framework achieves the smallest root mean square error at 0.030 mm and 0.032 mm for two blades, respectively.","1941-014X","","10.1109/TMECH.2023.3260884","National Key R&D Program of China(grant numbers:2018YFB1701202); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10098263","Deep learning;intelligence optimization;multistage manufacturing processes (MMPs);quality prediction;turbine blade machining","Blades;Optimization;Turbines;Production;Milling;Prediction algorithms;Manufacturing","","1","","36","IEEE","10 Apr 2023","","","IEEE","IEEE Journals"
"P$^{2}$ CySeMoL: Predictive, Probabilistic Cyber Security Modeling Language","H. Holm; K. Shahzad; M. Buschle; M. Ekstedt","Department of Industrial Information and Control Systems, The Royal Institute of Technology, Stockholm, Sweden; Department of Industrial Information and Control Systems, The Royal Institute of Technology, Stockholm, Sweden; Department of Industrial Information and Control Systems, The Royal Institute of Technology, Stockholm, Sweden; Department of Industrial Information and Control Systems, The Royal Institute of Technology, Stockholm, Sweden",IEEE Transactions on Dependable and Secure Computing,"9 Nov 2015","2015","12","6","626","639","This paper presents the Predictive, Probabilistic Cyber Security Modeling Language (P2CySeMoL), an attack graph tool that can be used to estimate the cyber security of enterprise architectures. P2CySeMoL includes theory on how attacks and defenses relate quantitatively; thus, users must only model their assets and how these are connected in order to enable calculations. The performance of P2CySeMoL enables quick calculations of large object models. It has been validated on both a component level and a system level using literature, domain experts, surveys, observations, experiments and case studies.","1941-0018","","10.1109/TDSC.2014.2382574","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6990572","Computer security;security metrics;attack graphs;risk management;Computer security;security metrics;attack graphs;risk management","Computer architecture;Computer security;Probabilistic logic;Computational modeling;Predictive models;Data models","","55","","58","IEEE","18 Dec 2014","","","IEEE","IEEE Journals"
"Quadratic Residual Multiplicative Filter Neural Networks for Efficient Approximation of Complex Sensor Signals","M. U. Demirezen","Department of Data Products, UDemy Inc., San Francisco, CA, USA",IEEE Access,"26 Jul 2023","2023","11","","75236","75268","In this research, we present an innovative Quadratic Residual Multiplicative Filter Neural Network (QRMFNN) to effectively learn extremely complex sensor signals as a low-dimensional regression problem. Based on this novel neural network model, we introduce two enhanced architectures, namely FourierQResNet and GaborQResNet. These networks integrate the benefits of quadratic residual neural networks, multiplicative filter neural networks, and several filters in signal processing to effectively capture complex signal patterns, thereby addressing issues associated with convergence speed, precision, and spectral bias. These architectures indicate effectiveness in reducing spectral bias, thereby improving the accuracy of signal approximation. After conducting comprehensive experiments on ten very complex test signals from diverse application domains, the proposed architectures have demonstrated superior ability in approximating intricate sensor signals and mitigating spectral bias effectively. The numerical results of the experiments reveal that FourierQResNet and GaborQResNet exhibit excellent performance compared to other existing neural network architectures and models in accurately estimating complicated sensor signals, with admiringly small errors. In addition, the findings emphasize the importance of mitigating spectral bias in order to achieve reliable learning from sensor data. The implications of these results are significant in various domains that require precise and reliable sensor data analysis, including healthcare, environmental monitoring, aviation, IoT applications, and industrial automation. This research significantly advances the field of sensor signal approximation and opens new avenues for enhancing data interpretation reliability and accuracy in complex signal environments.","2169-3536","","10.1109/ACCESS.2023.3297724","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10189900","Multiplicative filter neural networks;quadratic residual neural networks;spectral bias frequency principle;regression;implicit neural representations;neural networks;machine learning;deep learning","Gabor filters;Artificial neural networks;Biological neural networks;Mathematical models;Estimation;Convergence;Adaptation models;Neural networks;Machine learning;Deep learning","","1","","58","CCBYNCND","21 Jul 2023","","","IEEE","IEEE Journals"
"Frequency Interleaving IF Transmitter and Receiver for 240-GHz Communication in SiGe:C BiCMOS","M. H. Eissa; N. Maletic; L. Lopacinski; A. Malignaggi; G. Panic; R. Kraemer; G. Fischer; D. Kissinger","Leibniz-Institut für innovative Mikroelektronik, Frankfurt (Oder), Germany; Leibniz-Institut für innovative Mikroelektronik, Frankfurt (Oder), Germany; Leibniz-Institut für innovative Mikroelektronik, Frankfurt (Oder), Germany; Leibniz-Institut für innovative Mikroelektronik, Frankfurt (Oder), Germany; Leibniz-Institut für innovative Mikroelektronik, Frankfurt (Oder), Germany; Leibniz-Institut für innovative Mikroelektronik, Frankfurt (Oder), Germany; Leibniz-Institut für innovative Mikroelektronik, Frankfurt (Oder), Germany; Institute for Electronic Components and Circuits, Ulm University, Ulm, Germany",IEEE Transactions on Microwave Theory and Techniques,"14 Jan 2020","2020","68","1","239","251","This article presents a fully integrated modular wideband frequency interleaving (FI) transmitter and receiver for high data rate communication applications. At the transmitter side, three independent in-phase and quadrature-phase (IQ) baseband channels are upconverted to different intermediate frequencies (IFs) and then interleaved. At the receiver side, the interleaved signals are downconverted and separated back to each independent channel. Single-ended inputs and outputs are utilized to reduce the pin count, for a more practical realization and higher potential toward future system scaling. Special design techniques are followed to minimize crosstalk and intermodulation products between the channels. All circuits are manufactured and measured in a 130-nm SiGe:C BiCMOS technology with fT/fmax =300/500 GHz. The FI transmitter achieves a channel bandwidth of 2.5 GHz with less than 3-dB difference across different channels until 15-GHz IF. It consumes 560 mW from 2.5 and 3.3 V supplies and occupies a silicon area of 1.9 mm2. The FI receiver achieves a baseband channel bandwidth of 2.5 GHz with a 1-dB difference between the channels until the same IF. It consumes 860 mW from 2.5 and 3.3 V supplies and has a chip area of 1.55 mm2. The circuits are deployed in a communication experiment; first, in a back-toback test with a direct cable connection, demonstrating a data rate of 15.6 Gb/s across the three IQ channels with a 16-QAM modulation scheme and a worst case transmitter-to-receiver error vector magnitude (EVM) of -18.6 dB. Then, a wireless experiment is performed with a 240-GHz front end with on-chip antenna, demonstrating a data rate of 7.8 Gb/s with QPSK modulation and a worst case EVM of -8.3 dB, across a wireless link of 15 cm. To the best of our knowledge, this is the first article that demonstrates a wireless transmission at sub-terahertz (sub-THz) carrier frequencies utilizing FI architectures.","1557-9670","","10.1109/TMTT.2019.2940018","German Federal Ministry of Education and Research in the Research Project Fast-Spot(grant numbers:03ZZ0512A); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8851406","Broadband circuits;broadband communication;frequency interleaving (FI);ultra-wideband communication","Mixers;Transmitters;Bandwidth;Baluns;Receivers;Broadband communication","","19","","20","IEEE","27 Sep 2019","","","IEEE","IEEE Journals"
"The ReadoutCard Userspace Driver for the New Alice O2 Computing System","K. Alexopoulos; F. Costa","European Organization for Nuclear Research, CERN, Geneva, Switzerland; European Organization for Nuclear Research, CERN, Geneva, Switzerland",IEEE Transactions on Nuclear Science,"16 Aug 2021","2021","68","8","1876","1883","A large ion collider experiment (ALICE) experiment focuses on the study of the quark-gluon plasma as a product of heavy-ion collisions at the CERN large hadron collider (LHC). During the long shutdown 2 of the LHC in 2019-2020, a major upgrade is underway in order to cope with a hundredfold input data rate increase with peaks of up to 3.5 TB/s. This upgrade includes the new online-offline computing system called O2. The O2 readout chain runs on commodity Linux servers equipped with custom peripheral component interconnect express (PCIe) field-programmable gate array (FPGA)-based readout cards: the PCIe Gen 3 ×16, Intel Arria 10-based common readout unit (CRU), and the PCIe Gen 2 ×8, Xilinx Vertex 6-based Common ReadOut Receiver Card (CRORC). Access to the cards is provided through the O2 ReadoutCard userspace driver, which handles synchronization and communication for direct memory access (DMA) transfers, provides base address registers (BAR) access, and facilitates card configuration and monitoring. The ReadoutCard driver is the lowest level interface to the readout cards within O2 and is in use by all central systems and detector teams of the ALICE experiment. This communication presents the architecture of the driver and the suite of tools used for card configuration and monitoring. It also discusses its interaction with the tangent subsystems within the O2 framework.","1558-1578","","10.1109/TNS.2021.3098185","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9491011","Base address register (BAR);data acquisition systems;direct memory access (DMA);drivers;field-programmable gate arrays","Field programmable gate arrays;Detectors;Registers;Data acquisition;Device drivers;Large Hadron Collider","","2","","20","CCBY","20 Jul 2021","","","IEEE","IEEE Journals"
"Developing Web-Based Geographic Information Systems with a DSL: Proposal and Case Study","S. H. Alvarado; A. Cortiñas; M. R. Luaces; O. Pedreira; Á. S. Places","Laboratorio de Bases de Datos, Facultade de Informática, Universidade da Coruña, Centro de Investigación CITIC, A Coruña, Spain; Laboratorio de Bases de Datos, Facultade de Informática, Universidade da Coruña, Centro de Investigación CITIC, A Coruña, Spain; Laboratorio de Bases de Datos, Facultade de Informática, Universidade da Coruña, Centro de Investigación CITIC, A Coruña, Spain; Laboratorio de Bases de Datos, Facultade de Informática, Universidade da Coruña, Centro de Investigación CITIC, A Coruña, Spain; Laboratorio de Bases de Datos, Facultade de Informática, Universidade da Coruña, Centro de Investigación CITIC, A Coruña, Spain",Journal of Web Engineering,"22 Sep 2023","2020","19","2","167","193","In this paper, we present a declarative domain-specific language (DSL) for the development of Geographic Information Systems (GIS). GIS applications manage information with a spatial component, usually in the form of points, lines, polygons, or variants of these basic data types, in domains where the spatial information plays a central role. They provide the user with different functionalities on different application domains, but they are usually developed according to a common architecture and using a common set of technologies. Hence, they share a significant number of elements that make some aspects of their development quite repetitive. Our DSL allows developers to specify the entities, geographic layers, and maps of the applications using a declarative language. Then, the specification is transformed into a working GIS application. We present the language, its implementation, and a case study on two sample projects that allowed us to evaluate the resulting software, paying special attention to the savings in the development effort.","1544-5976","","10.13052/jwe1540-9589.1923","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10247304","Domain specific language;geographic information systems","Visualization;Codes;Source coding;Urban planning;Computer architecture;Software;DSL","","1","","19","","22 Sep 2023","","","River Publishers","River Publishers Journals"
"Memory-Efficient High-Speed Convolution-Based Generic Structure for Multilevel 2-D DWT","B. K. Mohanty; P. K. Meher","Department of Electronics and Communication Engineering, Jaypee University of Engineering and Technology, Guna, Madhya Pradesh, India; Institute for Infocomm Research, Singapore",IEEE Transactions on Circuits and Systems for Video Technology,"1 Feb 2013","2013","23","2","353","363","In this paper, we have proposed a design strategy for the derivation of memory-efficient architecture for multilevel 2-D DWT. Using the proposed design scheme, we have derived a convolution-based generic architecture for the computation of three-level 2-D DWT based on Daubechies (Daub) as well as biorthogonal filters. The proposed structure does not involve frame-buffer. It involves line-buffers of size 3(K-2)M/4 which is independent of throughput-rate, where K is the order of Daubechies/biorthogonal wavelet filter and M is the image height. This is a major advantage when the structure is implemented for higher throughput. The structure has regular data-flow, small cycle period TM and 100% hardware utilization efficiency. As per theoretical estimate, for image size 512 × 512, the proposed structure for Daub-4 filter requires 152 more multipliers and 114 more adders, but involves 82 412 less memory words and takes 10.5 times less time to compute three-level 2-D DWT than the best of the existing convolution-based folded structures. Similarly, compared with the best of the existing lifting-based folded structures, proposed structure for 9/7-filter involves 93 more multipliers and 166 more adders, but uses 85 317 less memory words and requires 2.625 times less computation time for the same image size. It involves 90 (nearly 47.6%) more multipliers and 118 (nearly 40.1%) more adders, but requires 2723 less memory words than the recently proposed parallel structure and performs the computation in nearly half the time of the other. Inspite of having more arithmetic components than the lifting-based structures, the proposed structure offers significant saving of area and power over the other due to substantial reduction in memory size and smaller clock-period. ASIC synthesis result shows that, the proposed structure for Daub-4 involves 1.7 times less area-delay-product (ADP) and consumes 1.21 times less energy per image (EPI) than the corresponding best available convolution-based structure. It involves 2.6 times less ADP and consumes 1.48 times less EPI than the parallel lifting-based structure.","1558-2205","","10.1109/TCSVT.2012.2203745","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6213522","2-D discrete wavelet transform (DWT);DWT;lifting;systolic array;very large scale integration (VLSI)","Discrete wavelet transforms;Complexity theory;Memory management;System-on-a-chip;Random access memory;Hardware","","52","","19","IEEE","7 Jun 2012","","","IEEE","IEEE Journals"
"Disaster Recovery Layer for Distributed OpenStack Deployments","L. Tomás; P. Kokkinos; V. Anagnostopoulos; O. Feder; D. Kyriazis; K. Meth; E. Varvarigos; T. Varvarigou","Department of Computing Science, Umeå University, Umeå, Sweden; Computer Technology Institute and Press Diophantus, Patras University Campus, Rio Patras, Greece; National Technical University of Athens, Athens, Greece; IBM Haifa Research Lab, Petach Tikva, Israel; Department of Digital Systems, University of Piraeus, Piraeus, Greece; IBM Haifa Research Lab, Petach Tikva, Israel; Computer Technology Institute and Press Diophantus, Patras University Campus, Rio Patras, Greece; National Technical University of Athens, Athens, Greece",IEEE Transactions on Cloud Computing,"6 Mar 2020","2020","8","1","112","123","We present the Disaster Recovery Layer (DRL) that enables OpenStack-managed datacenter workloads, Virtual Machines (VMs) and Volumes, to be protected and recovered in another datacenter, in case of a disaster. This work has been carried out in the context of the EU FP7 ORBIT project that develops technologies for enabling business continuity as a service. The DRL framework is based on a number of autonomous components and extensions of OpenStack modules, while its functionalities are available through OpenStack's Horizon UI and command line interface. Also, the DRL's architecture is extensible, allowing for the easy and dynamic integration of protection, restoration and orchestration plug-ins that adopt new approaches. A distributed disaster detection mechanism was also developed for identifying datacenter disasters and alerting the DRL. For the evaluation of the DRL, a two (active and backup) datacenters testbed has been setup in respective sites in Umea and Lulea, 265km apart and connected through the Swedish national research and education network. In case of a disaster, traffic is redirected between the datacenters utilizing the BGP anycast scheme. The experiments performed, show that DRL can efficiently protect VMs and Volumes, with minimum service disruption in case of failures and low overhead, even when the available bandwidth is limited.","2168-7161","","10.1109/TCC.2017.2745560","European Commission(grant numbers:609828); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8017473","Disaster recovery;OpenStack;disaster detection;traffic redirection;testbed;MAN/WAN;inter-datacenter network","Cloud computing;Wide area networks;Disaster management;Business continuity;Computer architecture;Metadata","","9","","39","IEEE","29 Aug 2017","","","IEEE","IEEE Journals"
"Multimodal 4DVarNets for the Reconstruction of Sea Surface Dynamics From SST-SSH Synergies","R. Fablet; Q. Febvre; B. Chapron","IMT Atlantique and the UMR CNRS Lab-STICC, INRIA Team Odyssey, Brest, France; IMT Atlantique and the UMR CNRS Lab-STICC, INRIA Team Odyssey, Brest, France; IFREMER, UMR CNRS LOPS, INRIA Team Odyssey, Brest, France",IEEE Transactions on Geoscience and Remote Sensing,"22 May 2023","2023","61","","1","14","The space-time reconstruction of sea surface dynamics from satellite observations is a challenging inverse problem due to the associated irregular sampling. Satellite altimetry provides direct observation of the sea surface height (SSH), which relates to the divergence-free component of sea surface currents. The associated sampling pattern prevents operational schemes from retrieving fine-scale dynamics, typically below 10 days. By contrast, other satellite sensors provide higher-resolution observations of sea surface tracers such as sea surface temperature (SST). Multimodal inversion schemes then arise as appealing approaches. Though theoretical evidence supports the existence of an explicit relationship between SST and sea surface dynamics under specific dynamical regimes, the generalization to the variety of upper ocean dynamical regimes is complex. Here, we investigate this issue from a physics-informed learning perspective. We introduce a trainable multimodal inversion scheme for the reconstruction of sea surface dynamics from multisource satellite-derived observations, namely satellite-derived SSH and SST data. The proposed multimodal 4DVarNet schemes combine a variational formulation involving trainable observation and a priori terms with a trainable gradient-based solver. An observing system simulation experiment (OSSE) for a Gulf stream region supports the relevance of our approach compared with state-of-the-art schemes. We report a relative improvement greater than 60% compared with the operational altimetry product in terms of root mean square error (MSE) and resolved space-time scales. We discuss further the potential and the limitations of the proposed approach for the reconstruction and forecasting of geophysical dynamics from irregularly-sampled satellite observations.","1558-0644","","10.1109/TGRS.2023.3268006","Les Enveloppes Fluides et Environnement (LEFE) Program through LEFE MANU(grant numbers:IA-OAC); Centre National d’Etudes Spatiales (CNES)(grant numbers:OSTST DUACS-HR,SWOT ST DIEGO); Agence Nationale de la Recherche (ANR) Projects Melody(grant numbers:ANR-19-CE46-0011); OceaniX(grant numbers:ANR-19-CHIA-0016); HPC and GPU Resources from Azure (Microsoft Azure grant) and from GENCI-Grand Equipement National de Calcul Intensif (IDRIS)(grant numbers:2021-101030); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10103682","End-to-end learning scheme;inverse problem;meta-learning;multimodal observations;satellite imaging;sea surface dynamics;variational models","Sea surface;Ocean temperature;Surface reconstruction;Temperature sensors;Satellites;Image reconstruction;Data models","","10","","61","IEEE","17 Apr 2023","","","IEEE","IEEE Journals"
"A Low Power and High Sensing Margin Non-Volatile Full Adder Using Racetrack Memory","K. Huang; R. Zhao; Y. Lian","Department of Engineering Product Design, Singapore University of Technology and Design, Singapore; Department of Engineering Product Design, Singapore University of Technology and Design, Singapore; Department of Electrical Engineering and Computer Science, York University, Canada",IEEE Transactions on Circuits and Systems I: Regular Papers,"27 Mar 2015","2015","62","4","1109","1116","The continuing miniaturization of complementary metal oxide semiconductor (CMOS) technology has brought in two critical issues-the high power and long global interconnection delay. Magnetic tunnel junction (MTJ) nanopillar with the advantages of non-volatility, fast switching speed, and high density promises new designs and architectures to significantly alleviate the power and delay issues. This paper presents a new design of the key component in processors-multi-bit full adder, whose input and output data are stored in perpendicular magnetic anisotropy (PMA) domain wall (DW) racetrack memory (RTM). The MTJ sharing technique with demultiplexing approach is used in the proposed non-volatile full adder (NVFA) to greatly reduce the area and power, and improve the speed and sensing margin as well. The proposed NVFA scheme can also apply to the other types of non-volatile memory (NVM). Compared to the state-of-art magnetic full adder (MFA), our proposed NVFA has reduced the power and area by 5.9 times and 50%, respectively. It also accelerates the speed by 10% and increases the sensing margin by more than 66%.","1558-0806","","10.1109/TCSI.2015.2388833","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7042845","Demultiplexing;logic in memory;non-volatile memory;non-volatile full adder;racetrack memory","Resistance;Nonvolatile memory;Strips;Adders;Magnetic tunneling;Sensors;Transistors","","15","","22","IEEE","16 Feb 2015","","","IEEE","IEEE Journals"
"The Automatic Definition of the Intuitive Linguistic Heuristics Set to Recognize the Elements of UML Analysis and Design Models in English","A. T. Imam","Faculty of Information Technology, Isra University, Amman, Jordan",IEEE Access,"4 Sep 2023","2023","11","","93381","93392","Elicitation of the elements of Unified Modelling Language (UML) analysis and design models from sentences written in scripted English is essential in the production of analysis and design models. The correct elicitation of these elements depends on the intuitive, manually defined set of linguistic heuristics, which is used to map a word in the sentence to its correct semantics in the domain of UML analysis and design models. This paper proposes a Genetic Algorithm-based classification rule discovery approach and a developed Enhanced Intuitive Linguistic Heuristics (EILH) dataset to automate the definition of the intuitive linguistic heuristics set to elicit five elements of UML analysis and design models from English sentences. These elements are the use case, the actor, the sender, the receiver, and the message. The automatically defined intuitive linguistic heuristics set was evaluated by developing an Artificial Neural Network (ANN) to recognize the elements of the UML analysis and design models using both manually defined and automatically defined sets. This comparison shows the superiority of the automatically defined set over the manually defined one.","2169-3536","","10.1109/ACCESS.2023.3310394","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10234620","Automatic programming;computer aided software engineering;decision support systems;feature extraction;knowledge discovery;requirements engineering;semantic search;semiotics","Unified modeling language;Analytical models;Genetic algorithms;Linguistics;Biological cells;Production;Classification algorithms;Automatic programming;Computer aided analysis;Decision support systems;Knowledge discovery;Requirements engineering","","2","","50","CCBYNCND","30 Aug 2023","","","IEEE","IEEE Journals"
"Architecture for Hard Disk Drives","K. Gao","International Business and Technology Service, North Oaks, MN, USA",IEEE Magnetics Letters,"16 Mar 2018","2018","9","","1","5","Magnetic data storage has made rapid progress in terms of areal density over the past few decades. Current products have areal density levels that exceed 1012 bits per square inch, about 1000 times greater than areal densities of the mid-1990s. Five component technologies have become hard-disk-drive industry standards over the past two decades: read heads based on giant magnetoresistance or tunneling magnetoresistance, perpendicular write heads, perpendicular recording media, heaters, and contact detection sensors. At the recording system level, shingled magnetic recording has been implemented by all disk-drive companies, but it has not become a new standard due to the additional penalty in access time (or latency). Here, interlaced magnetic recording and blocked magnetic recording are introduced and compared with conventional and shingled magnetic recording.","1949-3088","","10.1109/LMAG.2018.2789888","International Business and Technology Service(grant numbers:DST201706001); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8247209","Information storage;shingled magnetic recording;blocked magnetic recording;interlaced magnetic recording","Magnetic heads;Media;Standards;Heating systems;Heat-assisted magnetic recording;Industries","","14","","26","IEEE","5 Jan 2018","","","IEEE","IEEE Journals"
"On the Effectiveness of OTFS for Joint Radar Parameter Estimation and Communication","L. Gaudio; M. Kobayashi; G. Caire; G. Colavolpe","Department of Engineering and Architecture, University of Parma, Parma, Italy; Department of Electrical and Computer Engineering, Technical University of Munich, Munich, Germany; Department of Electrical Engineering and Computer Science, Technical University of Berlin, Berlin, Germany; Department of Engineering and Architecture, University of Parma, Parma, Italy",IEEE Transactions on Wireless Communications,"9 Sep 2020","2020","19","9","5951","5965","We consider a joint radar parameter estimation and communication system using orthogonal time frequency space (OTFS) modulation. The scenario is motivated by vehicular applications where a vehicle (or the infrastructure) equipped with a mono-static radar wishes to communicate data to its target receiver, while estimating parameters of interest related to this receiver. Provided that the radar-equipped transmitter is ready to send data to its target receiver, this setting naturally assumes that the receiver has been already detected. In a point-to-point communication setting over multipath time-frequency selective channels, we study the joint radar and communication system from two perspectives, i.e., the radar parameter estimation at the transmitter as well as the data detection at the receiver. For the radar parameter estimation part, we derive an efficient approximated Maximum Likelihood algorithm and the corresponding Cramér-Rao lower bound for range and velocity estimation. Numerical examples demonstrate that multi-carrier digital formats such as OTFS can achieve as accurate radar estimation as state-of-the-art radar waveforms such as frequency-modulated continuous wave (FMCW). For the data detection part, we focus on separate detection and decoding and consider a soft-output detector that exploits efficiently the channel sparsity in the Doppler-delay domain. We quantify the detector performance in terms of its pragmatic capacity, i.e., the achievable rate of the channel induced by the signal constellation and the detector soft-output. Simulations show that the proposed scheme outperforms concurrent state-of-the-art solutions. Overall, our work shows that a suitable digitally modulated waveform enables to efficiently operate joint radar parameter estimation and communication by achieving full information rate of the modulation and near-optimal radar estimation performance. Furthermore, OTFS appears to be particularly suited to the scope.","1558-2248","","10.1109/TWC.2020.2998583","MIUR under the PRIN Liquid_Edge Contract; Lorenzo Gaudio, Giuseppe Caire, and Giulio Colavolpe; Fondazione Cariparma through the TeachInParma Project; Alexander von Humboldt Research Fellowship; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9109735","OTFS;joint radar parameter estimation and communication;maximum likelihood detection;message-passing;achievable rate","Receivers;Parameter estimation;Transmitters;Detectors;Radar detection;Estimation","","238","","48","IEEE","5 Jun 2020","","","IEEE","IEEE Journals"
"Realization of a Robust Fog-Based Green VANET Infrastructure","Q. I. Ali","Department of Computer Engineering, Mosul University, Mosul, Iraq",IEEE Systems Journal,"8 Jun 2023","2023","17","2","2465","2476","This article proposes an efficient employment of a self-powered fog-based vehicular ad hoc network (VANET) infrastructure. Miscellaneous techniques and algorithms are suggested to help the realization of such framework. In the current work, we decided to enhance the network architecture of the traditional VANET by adopting the concept of self-powered fog computing concepts for better networking, computing, and storage performance. The green fog layer consists of three components: a self-powered edge server, wireless solar routers, and a new device resulted from the integration between a solar-powered smart camera and a solar-powered road side unit in order to create a better sensing mechanism of the road traffic. A proper power management strategy is suggested to be installed locally in the self-powered devices to decrease their power utilization and lengthen the lifetime of their batteries. On the system level, the design steps concentrate on building a sustainable, secured, reliable, and scalable communication infrastructure and this was done by adopting several approaches, such as VANET fog clustering, malicious nodes detection, and a combination of various security methods. The performance of the different methods and algorithms suggested in this article is evaluated using different simulation and experimental tools to discover their impact on enhancing the robustness of the fog-based Green VANET.","1937-9234","","10.1109/JSYST.2022.3215845","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9942726","Fog computing (FC);green infrastructure;power management;road side unit (RSU);smart camera (SC);solar energy harvesting;VANET","Vehicular ad hoc networks;Cloud computing;Computer architecture;Green products;Servers;Clouds;Security","","3","","30","IEEE","8 Nov 2022","","","IEEE","IEEE Journals"
"Managing Pattern-Specific Fixed Costs in Integrated Device Manufacturing","C. M. Weber; J. Yang","Department of Engineering and Technology Management, Portland State University, Portland, OR, USA; Department of Engineering and Technology Management, Portland State University, Portland, OR, USA",IEEE Transactions on Semiconductor Manufacturing,"27 Oct 2016","2016","29","4","275","282","This paper presents an empirically grounded model, which links organizational learning to pattern-specific fixed costs in integrated device manufacturing. The approach described in this paper helps fab managers make fundamental strategic decisions concerning product design and product mix by engaging in scenario planning. Four critical aspects of managing pattern-specific fixed cost are analyzed in detail-sensitivity to time, design cost, and production volume; platform designs; process postponement solutions; and design penalties. The model suggests that designers and fabrication facilities must collaborate extensively on the design and realizations of product platforms for state-of-the-art integrated circuit products to remain economically viable.","1558-2345","","10.1109/TSM.2016.2593741","National Science Foundation (Enabling Timely Revolutions in Organizational Performance)(grant numbers:0822062); Xerox Foundation under a grant on Researching Synchronized Innovation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7519085","Foundry;fabless;design;cost;photomask","Semiconductor device modeling;Production;Semiconductor process modeling;Integrated circuit modeling;Profitability;Economics;Semiconductor device manufacture","","5","","41","IEEE","22 Jul 2016","","","IEEE","IEEE Journals"
"Hybrid Beamforming via the Kronecker Decomposition for the Millimeter-Wave Massive MIMO Systems","G. Zhu; K. Huang; V. K. N. Lau; B. Xia; X. Li; S. Zhang","Department of EEE, The University of Hong Kong, Hong Kong; Department of EEE, The University of Hong Kong, Hong Kong; Department of ECE, The Hong Kong University of Science and Technology, Hong Kong; Department of EE, Shanghai Jiao Tong University, Shanghai, China; Shenzhen Institute of Radio Testing & Tech, Shenzhen, China; Shenzhen Institute of Radio Testing & Tech, Shenzhen, China",IEEE Journal on Selected Areas in Communications,"18 Aug 2017","2017","35","9","2097","2114","Millimeter-wave (mmWave) massive multiple-input multiple-output (MIMO) seamlessly integrates two wireless technologies, mmWave communications and massive MIMO, which provides spectrums with tens of GHz of total bandwidth and supports aggressive space division multiple access using large-scale arrays. Though it is a promising solution for next-generation systems, the realization of mmWave massive MIMO faces several practical challenges. In particular, implementing massive MIMO in the digital domain requires hundreds to thousands of radio frequency chains and analog-to-digital converters matching the number of antennas. Furthermore, designing these components to operate at the mmWave frequencies is challenging and costly. These motivated the recent development of the hybrid-beamforming architecture, where MIMO signal processing is divided for separate implementation in the analog and digital domains, called the analog and digital beamforming, respectively. Analog beamforming using a phase array introduces uni-modulus constraints on the beamforming coefficients. They render the conventional MIMO techniques unsuitable and call for new designs. In this paper, we present a systematic design framework for hybrid beamforming for multi-cell multiuser massive MIMO systems over mmWave channels characterized by sparse propagation paths. The framework relies on the decomposition of analog beamforming vectors and path observation vectors into Kronecker products of factors being uni-modulus vectors. Exploiting properties of Kronecker mixed products, different factors of the analog beamformer are designed for either nulling interference paths or coherently combining data paths. Furthermore, a channel estimation scheme is designed for enabling the proposed hybrid beamforming. The scheme estimates the angles-of-arrival (AoA) of data and interference paths by analog beam scanning and data-path gains by analog beam steering. The performance of the channel estimation scheme is analyzed. In particular, the AoA spectrum resulting from beam scanning, which displays the magnitude distribution of paths over the AoA range, is derived in closed form. It is shown that the inter-cell interference level diminishes inversely with the array size, the square root of pilot sequence length, and the spatial separation between paths, suggesting different ways of tackling pilot contamination.","1558-0008","","10.1109/JSAC.2017.2720099","Hong Kong Innovation and Technology Commission(grant numbers:GHP01213SZ); Hong Kong Research Grants Council(grant numbers:17209917,17259416); Shenzhen-Hong Kong Innovative Technology Cooperation Funding(grant numbers:SGLH20131009154139588); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7959175","Millimeter-wave;massive MIMO;analog beamforming;channel estimation;interference cancellation","Array signal processing;MIMO;Interference;Channel estimation;Computer architecture;Radio frequency;Algorithm design and analysis","","71","","39","IEEE","27 Jun 2017","","","IEEE","IEEE Journals"
"Intelligent Platform-Management Controller for Low-Level RF Control System ATCA Carrier Board","P. Predki; D. Makowski; A. Napieralski","Department of Microelectronics and Computer Science, Technical University of Łódź, Lodz, Poland; Department of Microelectronics and Computer Science, Technical University of Łódź, Lodz, Poland; Department of Microelectronics and Computer Science, Technical University of Łódź, Lodz, Poland",IEEE Transactions on Nuclear Science,"18 Aug 2011","2011","58","4","1538","1543","High availability and reliability are among the most desirable features of control systems in modern high-energy physics (HEP) and other big-scale scientific experiments. One of the recent developments that has influenced this field has been the emergence of the Advanced Telecommunications Computing Architecture (ATCA). Designed for the telecommunications industry, it has been successfully applied in other domains, such as accelerator control systems. A good example is the application of ATCA standard for the design of the low-level RF (LLRF) control system for the X-Ray Free Electron Laser (XFEL) being developed in Deutsches Elektronen Synchrotron (DESY). Reliability and availability requirements for such a facility play a crucial role among other parameters. Thus, the ATCA standard, with five-nines availability, is considered to be one of the best candidates for this system. This paper focuses on the central-management unit of every ATCA board, namely, the intelligent platform-management controller (IPMC), developed for the LLRF ATCA carrier board. It is also argued that it is possible to create a fully functional IPMC using base specifications which is only a more economical solution than acquiring such products from ATCA vendors. This work supports the concept of an open-source community solution under the xTCA for physics collaboration dealing with IPMC/MMC development and wishes to contribute to it. The IPMC solution presented here is mainly hardware independent as proper code organization allowed to separate low-level device drivers and high-level application logic dealing with the ATCA standard, which makes it portable for new carrier-board designs. It also follows the latest trends in xTCA development introduced by the xTCA for Physics initiative. A firmware upgrade of programmable devices (field-programmable gate arrays and digital signal processors) has been proposed. Currently, this is not included in the standard. However, this functionality is needed in HEP applications by using xTCA and is useful in these cases.","1558-1578","","10.1109/TNS.2011.2143427","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5778959","Advanced telecommunications computing architecture (ATCA);electronic keying;high-energy physics;intelligent platform-management controller;intelligent platform-management interface;intelligent platform-management controller (IPMC);X-Ray-free electron laser (XFEL);xTCA","Sensors;Physics;Hardware;Field programmable gate arrays;Driver circuits;Software;Control systems","","4","","21","IEEE","27 May 2011","","","IEEE","IEEE Journals"
"Green Networking With Packet Processing Engines: Modeling and Optimization","R. Bolla; R. Bruschi; A. Carrega; F. Davoli","Department of Electrical, Electronic and Telecommunication Engineering, and Naval Architecture (DITEN), University of Genoa; National Inter-University Consortium for Telecommunications (CNIT), University of Genoa Research Unit, Genova, Italy; Department of Electrical, Electronic and Telecommunication Engineering, and Naval Architecture (DITEN), University of Genoa; Department of Electrical, Electronic and Telecommunication Engineering, and Naval Architecture (DITEN), University of Genoa",IEEE/ACM Transactions on Networking,"12 Feb 2014","2014","22","1","110","123","With the aim of controlling power consumption in metro/transport and core networks, we consider energy-aware devices able to reduce their energy requirements by adapting their performance. In particular, we focus on state-of-the-art packet processing engines, which generally represent the most energy-consuming components of network devices, and which are often composed of a number of parallel pipelines to “divide and conquer” the incoming traffic load. Our goal is to control both the power configuration of pipelines and the way to distribute traffic flows among them. We propose an analytical model to accurately represent the impact of green network technologies (i.e., low power idle and adaptive rate) on network- and energy-aware performance indexes. The model has been validated with experimental results, performed by using energy-aware software routers loaded by real-world traffic traces. The achieved results demonstrate how the proposed model can effectively represent energy- and network-aware performance indexes. On this basis, we propose a constrained optimization policy, which seeks the best tradeoff between power consumption and packet latency times. The procedure aims at dynamically adapting the energy-aware device configuration to minimize energy consumption while coping with incoming traffic volumes and meeting network performance constraints. In order to deeply understand the impact of such policy, a number of tests have been performed by using experimental data from software router architectures and real-world traffic traces.","1558-2566","","10.1109/TNET.2013.2242485","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6462001","Adaptive rate;forwarding engine;green networking;low power idle;multipipeline","Pipelines;Engines;Performance evaluation;Power demand;Green products;Servers;Optimization","","38","","41","IEEE","14 Feb 2013","","","IEEE","IEEE Journals"
"PLUS: Open-Source Toolkit for Ultrasound-Guided Intervention Systems","A. Lasso; T. Heffter; A. Rankin; C. Pinter; T. Ungi; G. Fichtinger","Laboratory for Percutaneous Surgery, School of Computing, Queen’s University, Kingston, ON, Canada; Laboratory for Percutaneous Surgery, School of Computing, Queen’s University, Kingston, ON, Canada; Laboratory for Percutaneous Surgery, School of Computing, Queen’s University, Kingston, ON, Canada; Laboratory for Percutaneous Surgery, School of Computing, Queen’s University, Kingston, ON, Canada; Laboratory for Percutaneous Surgery, School of Computing, Queen’s University, Kingston, ON, Canada; Laboratory for Percutaneous Surgery, School of Computing, Queen’s University, Kingston, ON, Canada",IEEE Transactions on Biomedical Engineering,"16 Sep 2014","2014","61","10","2527","2537","A variety of advanced image analysis methods have been under the development for ultrasound-guided interventions. Unfortunately, the transition from an image analysis algorithm to clinical feasibility trials as part of an intervention system requires integration of many components, such as imaging and tracking devices, data processing algorithms, and visualization software. The objective of our paper is to provide a freely available open-source software platform—PLUS: Public software Library for Ultrasound—to facilitate rapid prototyping of ultrasound-guided intervention systems for translational clinical research. PLUS provides a variety of methods for interventional tool pose and ultrasound image acquisition from a wide range of tracking and imaging devices, spatial and temporal calibration, volume reconstruction, simulated image generation, and recording and live streaming of the acquired data. This paper introduces PLUS, explains its functionality and architecture, and presents typical uses and performance in ultrasound-guided intervention systems. PLUS fulfills the essential requirements for the development of ultrasound-guided intervention systems and it aspires to become a widely used translational research prototyping platform. PLUS is freely available as open source software under BSD license and can be downloaded from http://www.plustoolkit.org.","1558-2531","","10.1109/TBME.2014.2322864","Applied Cancer Research Unit program of Cancer Care Ontario; Cancer Ontario Research Chair; Queen¿s University¿Ontario Ministry of Research and Innovation Postdoctoral Fellow; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6813647","Live image streaming;open-source;spatial calibration;temporal calibration;tool navigation;tracked ultrasound;volume reconstruction","Imaging;Calibration;Software;Ultrasonic imaging;Hardware;Transducers;Software algorithms","Calibration;Database Management Systems;Humans;Image Processing, Computer-Assisted;Imaging, Three-Dimensional;Internet;Radiography;Software;Ultrasonography","314","","43","Crown","9 May 2014","","","IEEE","IEEE Journals"
"Leveraging Power-Performance Relationship of Energy-Efficient Modern DRAM Devices","S. Lee; H. Cho; Y. H. Son; Y. Ro; N. S. Kim; J. H. Ahn","Department of Transdisciplinary Studies, Seoul National University, Seoul, South Korea; Samsung Electronics, Suwon, South Korea; Samsung Electronics, Suwon, South Korea; Department of Transdisciplinary Studies, Seoul National University, Seoul, South Korea; Department of Electrical and Computer Engineering, University of Illinois at Urbana–Champaign, Urbana, IL, USA; Inter-university Semiconductor Research Center, Seoul National University, Seoul, South Korea",IEEE Access,"25 Jun 2018","2018","6","","31387","31398","Computer servers are equipped with an increasing number of memory modules each with more capacity, making main-memory systems now the second most energy-consuming component trailing only processors in big-memory servers. These big-memory servers and their main-memory systems should offer high energy efficiency. In pursuit of energy-efficient main-memory systems, prior work exploited mobile low power double data rate (LPDDR) devices' advantages (lower power than DDR devices) while attempting to surmount their limitations (longer latency, lower bandwidth, or both). However, we show that such main-memory architectures (based on the latest LPDDR4 devices) are no longer effective and even hurt overall energy efficiency of servers by 49% on memory-intensive workloads compared with ones based on DDR4 devices. The reason is that the power consumption of modern DDR4 devices has substantially reduced by adopting the strength of mobile and graphics memory whereas LPDDR4 has focused more on increasing data transfer rates while sacrificing energy efficiency; the power consumption of DDR4 devices can significantly vary across manufacturers in this analysis. Moreover, exploring new energy-saving features of DDR4 devices in depth, we show that activating these features often hurts overall energy efficiency of servers because of their performance penalties. Subsequently, we propose a simple but effective scheme that adaptively exploits DRAM power-down modes and hence improves the system energy-delay product by 4.0%.","2169-3536","","10.1109/ACCESS.2018.2845861","Samsung Electronics, NSF(grant numbers:CNS-1557245); National Research Foundation of Korea through the Korea Government(grant numbers:NRF-2017R1A2B2005416); Research and Development Program of MOTIE/KEIT(grant numbers:10077609); Future Semiconductor Device Technology Development Program through MOTIE and KSRC(grant numbers:10044735); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8377983","Computer performance;energy efficiency;SDRAM","Random access memory;Servers;Bandwidth;Data transfer;Power demand;Performance evaluation;Wires","","19","","53","OAPA","11 Jun 2018","","","IEEE","IEEE Journals"
"Deep Learning for Adverse Event Detection From Web Search","F. Ahmad; A. Abbasi; B. Kitchens; D. Adjeroh; D. Zeng","Computer Science, University of Virginia, Charlottesville, VA, USA; IT, Analytics, and Operations, University of Notre Dame, Notre Dame, IN, USA; Information Technology, University of Virginia, Charlottesville, VA, USA; Lane Department of Computer Science and Electrical Engineering, West Virginia University, Morgantown, WV, USA; Institute for Automation, Chinese Academy of Sciences, China",IEEE Transactions on Knowledge and Data Engineering,"29 Apr 2022","2022","34","6","2681","2695","Adverse event detection is critical for many real-world applications including timely identification of product defects, disasters, and major socio-political incidents. In the health context, adverse drug events account for countless hospitalizations and deaths annually. Since users often begin their information seeking and reporting with online searches, examination of search query logs has emerged as an important detection channel. However, search context - including query intent and heterogeneity in user behaviors – is extremely important for extracting information from search queries, and yet the challenge of measuring and analyzing these aspects has precluded their use in prior studies. We propose DeepSAVE, a novel deep learning framework for detecting adverse events based on user search query logs. DeepSAVE uses an enriched variational autoencoder encompassing a novel query embedding and user modeling module that work in concert to address the context challenge associated with search-based detection of adverse events. Evaluation results on three large real-world event datasets show that DeepSAVE outperforms existing detection methods as well as comparison deep learning auto encoders. Ablation analysis reveals that each component of DeepSAVE significantly contributes to its overall performance. Collectively, the results demonstrate the viability of the proposed architecture for detecting adverse events from search query logs.","1558-2191","","10.1109/TKDE.2020.3017786","National Science Foundation(grant numbers:IIS-1553109,IIS-1816504,BDS-1636933,CCF-1629450,IIS-1552860,IIS-1816005); MOST(grant numbers:2019AAA0103405,2016QY02D0305); NNSFC Innovative Team(grant numbers:71621002); CAS(grant numbers:XDC02060600,ZDRW-XH-2017-3); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9171579","Adverse event detection;search queries;deep learning;auto encoders;query embeddings;user modeling","Event detection;Drugs;Deep learning;Twitter;Data mining;Context modeling;Automotive engineering","","10","","62","CCBY","19 Aug 2020","","","IEEE","IEEE Journals"
"How to Design Scheduling Solutions for Smart Manufacturing Environments Using RAMI 4.0?","D. Alemão; A. D. Rocha; S. Nikghadam-Hojjati; J. Barata","Department of Electrical and Computer Engineering, NOVA School of Science and Technology, NOVA University of Lisbon, Caparica, Portugal; Department of Electrical and Computer Engineering, NOVA School of Science and Technology, NOVA University of Lisbon, Caparica, Portugal; Department of Electrical and Computer Engineering, NOVA School of Science and Technology, NOVA University of Lisbon, Caparica, Portugal; Department of Electrical and Computer Engineering, NOVA School of Science and Technology, NOVA University of Lisbon, Caparica, Portugal",IEEE Access,"12 Jul 2022","2022","10","","71284","71298","The scheduling applied to manufacturing represents a huge opportunity for companies to stand out in a world of fast and big changes. Having a reliable scheduling system will allow factories to deal with the significant demand for highly customized products. Although manufacturing scheduling has been deeply studied for decades, there is still a gap between academia and industry, namely because the lack of flexibility and homogeneity among scheduling solutions, which makes them very use case-oriented. Furthermore, the absence of standardization is also making it difficult to implement smart scheduling solutions in industrial scenarios. Thus, this work presents a set of requirements and design principles based on axiomatic design concept, to make the first steps to standardize the designing and development of manufacturing scheduling solutions in the context of Industry 4.0. At the end, is presented a scheduling generic framework targeting smart manufacturing and evaluated in a practical use case.","2169-3536","","10.1109/ACCESS.2022.3187974","European Union (EU) Project Advanced Manufacturing Solutions Tightly Aligned With Business Needs (AVANGARD); European Union’s Horizon 2020 Research and Innovation Program(grant numbers:869986); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9813725","Manufacturing scheduling;scheduling framework;industry 4.0;cyber-physical production systems;RAMI4.0;design principles","Job shop scheduling;Manufacturing;Computer architecture;Business;Smart manufacturing;Production facilities;Production","","4","","36","CCBY","4 Jul 2022","","","IEEE","IEEE Journals"
"Machine Learning Operations (MLOps): Overview, Definition, and Architecture","D. Kreuzberger; N. Kühl; S. Hirschl","IBM, Ehningen, Germany; IBM, Ehningen, Germany; IBM, Ehningen, Germany",IEEE Access,"4 Apr 2023","2023","11","","31866","31879","The final goal of all industrial machine learning (ML) projects is to develop ML products and rapidly bring them into production. However, it is highly challenging to automate and operationalize ML products and thus many ML endeavors fail to deliver on their expectations. The paradigm of Machine Learning Operations (MLOps) addresses this issue. MLOps includes several aspects, such as best practices, sets of concepts, and development culture. However, MLOps is still a vague term and its consequences for researchers and professionals are ambiguous. To address this gap, we conduct mixed-method research, including a literature review, a tool review, and expert interviews. As a result of these investigations, we contribute to the body of knowledge by providing an aggregated overview of the necessary principles, components, and roles, as well as the associated architecture and workflows. Furthermore, we provide a comprehensive definition of MLOps and highlight open challenges in the field. Finally, this work provides guidance for ML researchers and practitioners who want to automate and operate their ML products with a designated set of technologies.","2169-3536","","10.1109/ACCESS.2023.3262138","Deutsche Forschungsgemeinschaft (DFG, German Research Foundation)(grant numbers:491183248); Open Access Publishing Fund of the University of Bayreuth; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10081336","CI/CD;DevOps;machine learning;MLOps;operations;workflow orchestration","Interviews;Machine learning;Training;Collaboration;Bibliographies;Automation;Codes","","162","","66","CCBYNCND","27 Mar 2023","","","IEEE","IEEE Journals"
"The PetscSF Scalable Communication Layer","J. Zhang; J. Brown; S. Balay; J. Faibussowitsch; M. Knepley; O. Marin; R. T. Mills; T. Munson; B. F. Smith; S. Zampini","Argonne National Laboratory, Lemont, IL, USA; University of Colorado Boulder, Boulder, CO, USA; Argonne National Laboratory, Lemont, IL, USA; University of Illinois at Urbana-Champaign, Urbana, IL, USA; University at Buffalo, Buffalo, NY, USA; Argonne National Laboratory, Lemont, IL, USA; Argonne National Laboratory, Lemont, IL, USA; Argonne National Laboratory, Lemont, IL, USA; Argonne Associate of Global Empire, LLC, Argonne National Laboratory, Lemont, IL, USA; King Abdullah University of Science and Technology, Thuwal, Saudi Arabia",IEEE Transactions on Parallel and Distributed Systems,"15 Oct 2021","2022","33","4","842","853","PetscSF, the communication component of the Portable, Extensible Toolkit for Scientific Computation (PETSc), is designed to provide PETSc's communication infrastructure suitable for exascale computers that utilize GPUs and other accelerators. PetscSF provides a simple application programming interface (API) for managing common communication patterns in scientific computations by using a star-forest graph representation. PetscSF supports several implementations based on MPI and NVSHMEM, whose selection is based on the characteristics of the application or the target architecture. An efficient and portable model for network and intra-node communication is essential for implementing large-scale applications. The Message Passing Interface, which has been the de facto standard for distributed memory systems, has developed into a large complex API that does not yet provide high performance on the emerging heterogeneous CPU-GPU-based exascale systems. In this article, we discuss the design of PetscSF, how it can overcome some difficulties of working directly with MPI on GPUs, and we demonstrate its performance, scalability, and novel features.","1558-2183","","10.1109/TPDS.2021.3084070","Exascale Computing(grant numbers:17-SC-20-SC); U.S. Department of Energy; National Nuclear Security Administration; U.S. Department of Energy(grant numbers:DE-AC02-06CH11357); Office of Science(grant numbers:DE-SC0016140,DE-AC02-0000011838); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9442258","Communication;GPU;extreme-scale;MPI;PETSc","Libraries;Programming;Graphics processing units;Forestry;Electronics packaging;Arrays;Scalability","","16","","26","IEEE","26 May 2021","","","IEEE","IEEE Journals"
"An Overview of Trust Standards for Communication Networks and Future Digital World","H. Wang; X. Kang; T. Li; Z. Lei; C. -K. Chu; H. Wang","Huawei Singapore Research Center, Fusionopolis Walk, Singapore; Huawei Singapore Research Center, Fusionopolis Walk, Singapore; Huawei Singapore Research Center, Fusionopolis Walk, Singapore; Huawei Singapore Research Center, Fusionopolis Walk, Singapore; Huawei Singapore Research Center, Fusionopolis Walk, Singapore; Huawei Singapore Research Center, Fusionopolis Walk, Singapore",IEEE Access,"11 May 2023","2023","11","","42991","42998","Trust is an essential concept in various scenarios enabled by Information and Communication Technologies (ICT). To facilitate the implementation of trust in these scenarios, different organizations have published a series of trust frameworks. However, most existing works on trust standards only focus on a specific application domain. Unlike these works, in this paper, we provide a comprehensive overview of the current available trust standards related to communication networks and future digital world from several main organizations. We categorize these trust standards into three layers: trust foundation, trust elements, and trust applications. We then analyze these trust standards and discuss their contributions in a systematic way. We also examine the motivations behind each enforced standard, analyze their frameworks and solutions, and present their role and impact on communication works and future digital world. Finally, we offer our suggestions on the trust work that needs to be standardized in the future.","2169-3536","","10.1109/ACCESS.2023.3270042","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10107593","Trust;trust management;trust standards","Trust management;Security;Communication networks;Hardware;Information and communication technology;Biological system modeling;Law","","3","","16","CCBYNCND","24 Apr 2023","","","IEEE","IEEE Journals"
"Memory-Efficient Multiplier-Less 2-D DWT Design Using Combined Convolution and Lifting Schemes for Wireless Visual Sensors","B. K. Mohanty","Department of Electronics and Communication Engineering, Sambalpur University Institute of Information Technology, Sambalpur University, Burla, Odisha, India",IEEE Transactions on Very Large Scale Integration (VLSI) Systems,"21 Mar 2024","2024","32","4","695","703","In this article, the combined convolution–lifting scheme is explored to address the design issues of 2-D discrete wavelet transform (DWT) structures. We found that the combined convolution–lifting scheme of type-1 (convolution followed by lifting) is more suitable than convolution or lifting schemes to design 2-D DWT structures with less on-chip memory. Furthermore, the canonic signed digit (CSD)-based multiplier-less designs are presented for convolution-DWT and lifting-DWT using  $9/7$  biorthogonal filters, and they have identical resource requirements for 12-bit coefficients. The proposed multiplier-less designs of convolution-DWT and lifting-DWT are used to derive a 2-D DWT structure to take advantage of the combined convolution–lifting scheme. The comparison result shows that the proposed combined 2-D DWT structure involves  $24\times $  less area-delay-product (ADP) and  $17\times $  less energy per image (EPI) compared with the best of the existing fractional wavelet transform (FrWT)-based structure and provides reconstructed images of 14 dB higher peak signal-to-noise ratio (PSNR). Compared with the recently proposed approximate lifting (ALF) 2-D DWT structure, the proposed combined 2-D DWT structure involves  $4.5\times $  less ADP,  $2.2\times $  less EPI, less on-chip memory by  $4N$  words and provides reconstructed images of PSNR higher by 7 dB, where  $N$  is the image width or height. Therefore, the proposed combined 2-D DWT structure is a better alternative to the existing 2-D DWT structures for low-complexity and low-memory realization of 2-D DWT especially for the visual sensor node applications.","1557-9999","","10.1109/TVLSI.2024.3367817","Science and Engineering Research Board (SERB), India(grant numbers:CRG/2020/005162); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10445279","Discrete wavelet transform (DWT);image encoder;VLSI architecture;visual sensor","Discrete wavelet transforms;Convolution;Visualization;Sensors;Image reconstruction;Transforms;Memory management","","","","18","IEEE","26 Feb 2024","","","IEEE","IEEE Journals"
"A social analytics platform for smarter commerce solutions","M. Desmond; H. L. Guo; F. F. Heath; S. Bao; E. Khabiri; S. Krasikov; N. Modani; S. Nagar; M. Ohno; H. Srinivasan; H. Takeuchi; R. Vaculín; S. W. Zhao; T. Hamid","IBM Research Division, Thomas J. Watson Research Center, Yorktown Heights, NY, USA; IBM Research-China, Zhongguancun Software Park, Beijing, China; IBM Research Division, Thomas J. Watson Research Center, Yorktown Heights, NY, USA; IBM Research-China, Building 19 Zhongguancun Software Park, Haidian District,, Beijing; IBM Research Division, Thomas J. Watson Research Center, Yorktown Heights, NY, USA; IBM Research Division, Thomas J. Watson Research Center, Yorktown Heights, NY, USA; IBM Research-India, New Delhi; IBM Research-India, Manyata Embassy Tech Park,, Bangalore, India; IBM Research-Tokyo, Koto-ku Tokyo, Japan; IBM Research Division, Thomas J. Watson Research Center, Yorktown Heights, NY, USA; IBM Research-Tokyo, Koto-ku Tokyo, Japan; NA; IBM Research - China, Zhongguancun Software Park, Haidian District, Beijing, China; IBM Global Business Services, Dublin, OH, USA",IBM Journal of Research and Development,"21 Nov 2014","2014","58","5/6","10:1","10:14","When providing customers with a personalized shopping experience, there is tremendous value in understanding and applying social data shared by those consumers. Understanding this data and how best to generate business value from it is the core challenge of many businesses today. Friends, family, and experts alike influence consumers in their shopping preferences and purchase decisions. Yet, the ability of a business to analyze data on such influence, and recommend products and services that best respond to its customers' needs or aspirations, is typically limited by fragmented capabilities; a business relies heavily on the use of spreadsheets, manual market analysis, isolated software, or reactive messaging. This paper offers a solution to this fragmentary approach by introducing a social analytics platform for smarter commerce. This platform provides a holistic understanding of the customer by making use of social and enterprise data to present recommendations and related opinions, and to isolate influencers so as to ultimately provide customers with a personalized shopping experience. The functionality described in this paper is in the context of the retail industry but can be applied to other industries. The paper describes the architecture of the social analytics platform and the various analytics components currently implemented as part of the platform.","0018-8646","","10.1147/JRD.2014.2346262","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6964897","","Electronic commerce;Sales and marketing;Internet;Electronic commerce;Customer purchases;Consumer behavior;Social factors;Behavioral science","","","1","64","IBM","21 Nov 2014","","","IBM","IBM Journals"
"Interoperable Infrastructure for Flood Monitoring: SensorWeb, Grid and Cloud","N. Kussul; D. Mandl; K. Moe; J. -P. Mund; J. Post; A. Shelestov; S. Skakun; J. Szarzynski; G. Van Langenhove; M. Handy","Space Research Institute, NASU-NSAU, Kyiv, Ukraine; NASA Goddard Space Flight Center, USA; Earth Science Technology Office, Goddard Space Flight Center, National Aeronautics and Space Administration, USA; Department of GIS and Remote Sensing, University for Sustainable Development in Eberswalde (HNEE), Germany; German Remote Sensing Data Center, German Aerospace Center (DLR), Oberpfaffenhofen, Germany; Space Research Institute, NASU-NSAU, Kyiv, Ukraine; Space Research Institute, NASU-NSAU, Kyiv, Ukraine; Institute for Environment and Human Security (UNU-EHS), United Nations University, Bonn, Germany; Hydrological Services Namibia, Department of Water Affairs, Namibian Ministry of Agriculture, Water and Forestry, Windhoek, Namibia; Goddard Space Flight Center, National Aeronautics and Space Administration, USA",IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing,"28 Dec 2012","2012","5","6","1740","1745","The paper presents an international multi-disciplinary initiative, a Namibia SensorWeb Pilot Project, that was created as a testbed for evaluating and prototyping key technologies for rapid acquisition and distribution of data products for decision support systems to monitor floods. Those key technologies include SensorWebs, Grids and Computation Clouds. This pilot project aims at developing an operational trans-boundary flood management decision support system for the Southern African region to provide useful flood and water-borne disease forecasting tools for local decision makers. This effort integrates space-based and ground sensor data along with higher level geospatial data products to enable risk assessment and ultimately risk maps related to flood disaster management and water-related disease management. We present an overall architecture of the Pilot along with components and services being developed. Additionally, case-studies and results achieved so far are discussed. The presented work is being carried out within GEO 2009-2011 Work Plan as CEOS WGISS contribution.","2151-1535","","10.1109/JSTARS.2012.2192417","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6202724","Earth observation;remote sensing;floods;sensor web;risk analysis;Grid;cloud computing;GEOSS","Satellites;Cloud computing;Floods;Global Earth Observation System of Systems;Remote sensing;Risk analysis","","35","","24","IEEE","18 May 2012","","","IEEE","IEEE Journals"
"OPRC: An Online Personalized Reputation Calculation Model in Service-Oriented Computing Environments","X. Du; J. Xu; W. Cai; C. Zhu; Y. Chen","Department of Computer Science, Shantou University, Shantou, China; Key Laboratory of Intelligent Manufacturing Technology, Ministry of Education, Shantou University, Shantou, China; Key Laboratory of Intelligent Manufacturing Technology, Ministry of Education, Shantou University, Shantou, China; Department of Computer Science, Shantou University, Shantou, China; Department of Computer Science, Shantou University, Shantou, China",IEEE Access,"15 Jul 2019","2019","7","","87760","87768","Cloud applications based on service-oriented architectures usually integrate many component services to implement specific application logic. In service-oriented computing environments, many Web services are provided for users to build service-oriented systems. Since the performance of the same Web service varies according to different users’ perspectives, the users have to personally select the optimal Web services according to the quality-of-service (QoS) data observed by other similar users. However, users with a low reputation provide unreliable data, which has a negative impact on service selection. Moreover, the QoS data vary over time due to changes in user reputation; and therefore, how to calculate a personalized reputation for each user at runtime remains a substantial problem. To address this critical challenge, this paper proposes an online reputation calculation method, called the OPRC, to efficiently provide a personalized reputation for each user. Based on the users’ observed QoS data, the OPRC employs MF and online learning techniques to calculate personalized reputations. To validate the approach, large-scale experiments are conducted, which contain two QoS attributes from 142 reliable users and 15 unreliable users. The results show that OPRC has high accuracy and effectiveness compared to other approaches.","2169-3536","","10.1109/ACCESS.2019.2925778","National Natural Science Foundation of China(grant numbers:61702318); Science and Technology Planning Project of Guangdong Province(grant numbers:2019B010116001,2016B010124012); Shantou University(grant numbers:NTF18024); the 2018 Provincial and Municipal Vertical Coordination Management Science and Technology Planning Project; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8750782","Service-oriented systems;Web services;quality of service (QoS);user reputation;online learning","Quality of service;Web services;Computational modeling;Adaptation models;Data models;Reliability;Sparse matrices","","23","","33","CCBY","28 Jun 2019","","","IEEE","IEEE Journals"
"Parallel-Amplitude Architecture and Subset Ranking for Fast Distribution Matching","T. Fehenberger; D. S. Millar; T. Koike-Akino; K. Kojima; K. Parsons","Mitsubishi Electric Research Laboratories, Cambridge, Germany; Mitsubishi Electric Research Laboratories, Cambridge, Germany; Mitsubishi Electric Research Laboratories, Cambridge, Germany; Mitsubishi Electric Research Laboratories, Cambridge, Germany; Mitsubishi Electric Research Laboratories, Cambridge, Germany",IEEE Transactions on Communications,"16 Apr 2020","2020","68","4","1981","1990","A distribution matcher (DM) maps a binary input sequence into a block of nonuniformly distributed symbols. To facilitate the implementation of shaped signaling, fast DM solutions with high throughput and low serialism are required. We propose a novel DM architecture with parallel amplitudes (PA-DM) for which m-1 component DMs, each with a different binary output alphabet, are operated in parallel in order to generate a shaped sequence with m amplitudes. With negligible rate loss compared to a single nonbinary DM, PA-DM has a parallelization factor that grows linearly with m, and the component DMs have reduced output lengths. For such binary-output DMs, a novel constant-composition DM (CCDM) algorithm based on subset ranking (SR) is proposed. We present SR-CCDM algorithms that are serial in the minimum number of occurrences of either binary symbol for mapping, and fully parallel for demapping. For distributions that are optimized for the additive white Gaussian noise (AWGN) channel, we numerically show that PA-DM combined with SR-CCDM can reduce the number of sequential processing steps by more than an order of magnitude, while having a rate loss that is comparable to conventional nonbinary CCDM with arithmetic coding.","1558-0857","","10.1109/TCOMM.2020.2966693","German Ministry of Education and Research in the project PEARLS(grant numbers:#13N14937); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8960288","Constant composition distribution matching;subset ranking;probabilistic amplitude shaping;coded modulation","Probabilistic logic;Modulation;AWGN channels;Throughput;Encoding;Forward error correction;Decoding","","19","","35","IEEE","15 Jan 2020","","","IEEE","IEEE Journals"
"Toward Integrating Intelligence and Programmability in Open Radio Access Networks: A Comprehensive Survey","A. Arnaz; J. Lipman; M. Abolhasan; M. Hiltunen","School of Electrical and Data Engineering, University of Technology Sydney, Ultimo, NSW, Australia; School of Electrical and Data Engineering, University of Technology Sydney, Ultimo, NSW, Australia; School of Electrical and Data Engineering, University of Technology Sydney, Ultimo, NSW, Australia; AT&T Labs Research, Bedminster, NJ, USA",IEEE Access,"30 Jun 2022","2022","10","","67747","67770","Open RAN is an emerging vision and an advancement of the Radio Access Network (RAN). Its purpose is to implement a vendor and network-generation agnostic RAN, provide networking solutions across all service requests, and implement artificial intelligence solutions in different stages of an end-to-end communication path. The 5th Generation (5G) and beyond the 5th Generation (B5G) of networking introduce and support new use cases, such as tactile internet and autonomous driving. The complexity and innovative nature of these use cases require continuous innovation at a high pace in the RAN. The traditional approach of building end-to-end RAN solutions by only one vendor hampers the speed of innovation—furthermore, the lack of a standard approach to implementing artificial intelligence complicates the compatibility of products with the RAN ecosystem. O-RAN Alliance, a community of industry and academic experts in RAN, works on writing Open RAN specifications on top of the 3rd Generation Partnership Project (3GPP) standards. Founded on these specifications, the aim of this paper is to introduce open research topics in Open RAN that overlap the interests of both AI and telecommunication researchers. The paper provides an overview of the architecture and components of Open RAN, then explores AI use cases in Open RAN. Also, this survey includes some plausible AI deployment scenarios that the specifications have not covered. Open RAN in future cities creates opportunities for various use cases across different sectors, including engineering, operations, and research that this paper addresses.","2169-3536","","10.1109/ACCESS.2022.3183989","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9798822","5G;B5G;artificial intelligence;intelligent systems;machine learning;open RAN;radio access networks","Computer architecture;Artificial intelligence;5G mobile communication;Radio access networks;Communications technology;3G mobile communication;Machine learning","","29","","98","CCBYNCND","17 Jun 2022","","","IEEE","IEEE Journals"
"Deploying Fog Computing in Industrial Internet of Things and Industry 4.0","M. Aazam; S. Zeadally; K. A. Harras","Department of Computer Science, Carnegie Mellon University, Doha, Qatar; University of Kentucky, Lexington, KY, USA; Department of Computer Science, Carnegie Mellon University, Doha, Qatar",IEEE Transactions on Industrial Informatics,"4 Oct 2018","2018","14","10","4674","4682","Rapid technological advances have revolutionized the industrial sector. These advances range from automation of industrial processes to autonomous industrial processes, where a human input is not required. Internet of Things (IoT), which has emerged a few years ago, has been embraced by industry, resulting in what is known as the Industrial Internet of Things (IIoT). IIoT refers to making industrial processes and entities part of the Internet. Restricting the definition of IIoT to manufacturing yields another subset of IoT, known as Industry 4.0. IIoT and Industry 4.0, will consist of sensor networks, actuators, robots, machines, appliances, business processes, and personnel. Hence, a lot of data of diverse nature would be generated. The industrial process requires most of the tasks to be performed locally because of delay and security requirements and structured data to be communicated over the Internet to web services and the cloud. To achieve this task, middleware support is required between the industrial environment and the cloud/web services. In this context, fog is a potential middleware that can be very useful for different industrial scenarios. Fog can provide local processing support with acceptable latency to actuators and robots in a manufacturing industry. Additionally, as industrial big data are often unstructured, it can be trimmed and refined by the fog locally, before sending it to the cloud. We present an architectural overview of IIoT and Industry 4.0. We discuss how fog can provide local computing support in the IIoT environment and the core elements and building blocks of IIoT. We also present a few interesting prospective use cases of IIoT. Finally, we discuss some emerging research challenges related to IIoT.","1941-0050","","10.1109/TII.2018.2855198","NPRP(grant numbers:8-1645-1-289); Qatar National Research Fund; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8410462","Cloud of Things (CoT);fog computing;industrial internet of things (IIoT);industry 4.0;middleware","Robot sensing systems;Industries;Internet of Things;Task analysis;Actuators;Middleware","","442","","20","IEEE","12 Jul 2018","","","IEEE","IEEE Journals"
"The TerraSAR-X Ground Segment","S. Buckreuss; B. Schattler","Microwaves and Radar Institute, German Aerospace Center, Germany; Remote Sensing Technology Institute (IMF), German Aerospace Center, Germany",IEEE Transactions on Geoscience and Remote Sensing,"19 Jan 2010","2010","48","2","623","632","TerraSAR-X, the first national German remote-sensing satellite, was launched on June 15, 2007. It carries an X-band high-resolution synthetic aperture radar (SAR) instrument featuring imaging modes like StripMap, ScanSAR, and, particularly, SpotLight in a variety of different polarization modes. Primary mission goal is the provision of both science and commercial users with a variety of products from advanced SAR modes. The TerraSAR-X Ground Segment, which is provided by the German Aerospace Center (DLR), constitutes the central element for controlling and operating the TerraSAR-X satellite, for calibrating its SAR instrument, and for archiving the SAR data, as well as generating and distributing the basic data products. This paper depicts the ground-segment layout and describes its major elements. The ordering and product-generation workflow is presented. It introduces the applied prelaunch integration, testing, verification, and validation approach, a major key to the completion not only of the SAR technical-verification program but also the operational qualification of the ground segment itself within the commissioning phase.","1558-0644","","10.1109/TGRS.2009.2031432","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5308272","Ground segment;remote sensing;synthetic aperture radar (SAR);TerraSAR-X","Image segmentation;Satellites;Instruments;Remote sensing;Synthetic aperture radar;High-resolution imaging;Polarization;Aerospace control;Centralized control;Testing","","38","","33","IEEE","3 Nov 2009","","","IEEE","IEEE Journals"
"Analyzing Crosstalk-Induced Effects in Rough On-Chip Copper Interconnects","S. Pathania; S. Kumar; R. Sharma","Department of Electrical Engineering, IIT Ropar, Rupnagar, India; ABV-Indian Institute of Information Technology and Management, Gwalior, India; Department of Electrical Engineering, IIT Ropar, Rupnagar, India","IEEE Transactions on Components, Packaging and Manufacturing Technology","17 Oct 2019","2019","9","10","1984","1992","Aggressive scaling of on-chip interconnects results in significantly higher coupling capacitance, which results in crosstalk effects as we enter the end-of-the-roadmap era. Moreover, surface roughness is seen as a major contributor to conductor losses that further exacerbates these crosstalk-induced effects. This article reports an exhaustive analysis of crosstalk-induced effects, considering interconnect surface roughness at current and future technology nodes (i.e., 13 and 7 nm), for on-chip global copper interconnects. The role of repeater insertion in rough interconnects is also presented in our work. For our analysis, we have used an aggressor-victim-aggressor three-line bus architecture and FINFET-based driver circuits with binary input logic. Our results show that surface roughness degrades typical interconnect performance metrics i.e., worst case delay, bandwidth density (BWD), power consumption, and power-delay product. At a 7-nm technology node, average worst case crosstalk delay and power consumption increase by 17× and 9×, respectively, when compared to smooth interconnects. Similarly, due to surface roughness, BWD reduces by nearly 17× for 7-nm global interconnects. For data rates of 0.2 Mb/s, eye height and eye width are reduced by 73% and 54%, respectively, in the worst case scenario for 7-nm global lines. Finally, we showcase the role of repeater insertion in enhancing performance metrics, in which crosstalk delay and power delay products are significantly improved (by 85% and 99%, respectively) at a 7-nm technology node.","2156-3985","","10.1109/TCPMT.2019.2941871","Ministry of Electronics and Information technology(grant numbers:9(1/2014-MMD)); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8840871","Bandwidth density (BWD);crosstalk;delay;global interconnects;repeaters;surface roughness;technology node","Integrated circuit interconnections;Crosstalk;Rough surfaces;Surface roughness;System-on-chip;Repeaters;Delays","","8","","26","IEEE","17 Sep 2019","","","IEEE","IEEE Journals"
"Algorithm-Hardware Co-Design of Split-Radix Discrete Galois Transformation for KyberKEM","G. Li; D. Chen; G. Mao; W. Dai; A. I. Sanka; R. C. C. Cheung","Department of Electrical Engineering, City University of Hong Kong, Kowloon Tong, Hong Kong SAR; Faculty of Science and Technology, BNU-HKBU United International College, Zhuhai, Guangdong, China; Department of Electrical Engineering, City University of Hong Kong, Kowloon Tong, Hong Kong SAR; Zhejiang Lab, Hangzhou, Zhejiang, China; Department of Electrical Engineering, City University of Hong Kong, Kowloon Tong, Hong Kong SAR; Department of Electrical Engineering, City University of Hong Kong, Kowloon Tong, Hong Kong SAR",IEEE Transactions on Emerging Topics in Computing,"8 Dec 2023","2023","11","4","824","838","KyberKEM is one of the final round key encapsulation mechanisms in the NIST post-quantum cryptography competition. Number theoretic transform (NTT), as the computing bottleneck of KyberKEM, has been widely studied. Discrete Galois Transformation (DGT) is a variant of NTT that reduces transform length into half but requires more multiplication operations than the latest NTT algorithm in theoretical analysis. This paper proposes the split-radix DGT, a novel DGT variant utilizing the split-radix method, to reduce the computing complexity without compromising the transform length. Specifically, for length-128 polynomial, the split-radix DGT algorithm saves at least 10% multiplication operations compared with the latest NTT algorithm in theoretical analysis. Furthermore, we proposed a unified split-radix DGT processor with the dedicated stream permutation network for KyberKEM and implemented it on the Xilinx Artix-7 FPGA. The processor achieves at least 49.4% faster transformation and 65.3% faster component-wise multiplication, with at most 87% and 32% LUT-NTT area-time product and LUT-CWM area-time product, compared with the state-of-the-art polynomial multipliers in KyberKEM with the same BFU setting on similar platforms. Lastly, we designed a highly efficient KyberKEM architecture using the proposed split-radix DGT processor. The implementation results on Artix-7 FPGA show significant performance improvements over the state-of-the-art KyberKEM designs.","2168-6750","","10.1109/TETC.2023.3270971","Hong Kong Innovation and Technology Commission(grant numbers:ITS/216/19); City University of Hong Kong(grant numbers:9440242 9678187); National Natural Science Foundation of China(grant numbers:62002023,62002239); Guangdong Provincial Key Laboratory of Interdisciplinary Research and Application for Data Science; BNU-HKBU United International College(grant numbers:2022B1212010006); UIC research(grant numbers:R0400001-22); Zhejiang Lab open research(grant numbers:K2022PD0AB03); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10114669","Discrete galois transform;split-radix;negative wrapped convolution;post-quantum cryptography;key encapsulation mechanism;hardware;FPGA","Transforms;Field programmable gate arrays;Hardware;NIST;Convolution;Computer architecture;Complexity theory","","2","","38","IEEE","2 May 2023","","","IEEE","IEEE Journals"
"Single-Point Detection Architecture via Liquid Crystal Modulation for Hyperspectral Imaging Systems","C. H. Brodie; C. M. Collier","Applied Optics and Microsystems Laboratory, University of Guelph, Guelph, Canada; Applied Optics and Microsystems Laboratory, University of Guelph, Guelph, Canada",IEEE Access,"19 Oct 2020","2020","8","","185012","185020","Hyperspectral imaging (HSI) architectures can acquire one-dimension of spatial information and one-dimension of spectral information on a two-dimensional image sensor for an image, such as in the traditional line-scan HSI architecture. However, development of HSI architectures for multiple spatial dimensions is challenging as there is not a third dimension on a two-dimensional image sensor on which to store spectral information. The presented work introduces a snapshot HSI architecture to alleviate this issue. The snapshot HSI architecture incorporates single-point detection via liquid crystal modulation and a single photodiode. Mixing of hyperspectral data is expressed as intermodulation frequency products within the Fourier-domain. Spatial information can be recorded through spatial frequencies and spectral information can be recorded through spectral frequencies. Such modulation is achieved through liquid crystal spatial and spectral arrays of an image beam. The spatial and spectral modulation frequencies form intermodulation frequency products that are recorded on the single photodiode and can be uncovered through Fourier-domain filtering.","2169-3536","","10.1109/ACCESS.2020.3029550","Natural Sciences and Engineering Research Council of Canada under Discovery(grant numbers:04022); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9217432","Frequency-domain analysis;multispectral imaging;optical diffraction;photodiode","Frequency modulation;Hyperspectral imaging;Digital images;Amplitude modulation;Photodiodes;Diffraction","","4","","45","CCBY","8 Oct 2020","","","IEEE","IEEE Journals"
"Scene Categorization Using Deeply Learned Gaze Shifting Kernel","X. Sun; L. Zhang; Z. Wang; J. Chang; Y. Yao; P. Li; R. Zimmermann","Department of CSIE, Hefei University of Technology, Hefei, China; Department of CSIE, Hefei University of Technology, Hefei, China; Department of CSIE, Hefei University of Technology, Hefei, China; School of Medical information, Wannan Medical College Research Center of Health Big Data Mining and Applications, Wannan Medical College, Wuhu, China; State Grid Zhejiang Electric Power Company, Ltd., Information and Telecommunication Company, Quzhou, China; School of Computer Science and Technology, Hangzhou Dianzi University, Hangzhou, China; School of Computing, National University of Singapore, Singapore",IEEE Transactions on Cybernetics,"28 Mar 2019","2019","49","6","2156","2167","Accurately recognizing sophisticated sceneries from a rich variety of semantic categories is an indispensable component in many intelligent systems, e.g., scene parsing, video surveillance, and autonomous driving. Recently, there have emerged a large quantity of deep architectures for scene categorization, wherein promising performance has been achieved. However, these models cannot explicitly encode human visual perception toward different sceneries, i.e., the sequence of humans sequentially allocates their gazes. To solve this problem, we propose deep gaze shifting kernel to distinguish sceneries from different categories. Specifically, we first project regions from each scenery into the so-called perceptual space, which is established by combining color, texture, and semantic features. Then, a novel non-negative matrix factorization algorithm is developed which decomposes the regions' feature matrix into the product of the basis matrix and the sparse codes. The sparse codes indicate the saliency level of different regions. In this way, the gaze shifting path from each scenery is derived and an aggregation-based convolutional neural network is designed accordingly to learn its deep representation. Finally, the deep representations of gaze shifting paths from all the scene images are incorporated into an image kernel, which is further fed into a kernel SVM for scene categorization. Comprehensive experiments on six scenery data sets have demonstrated the superiority of our method over a series of shallow/deep recognition models. Besides, eye tracking experiments have shown that our predicted gaze shifting paths are 94.6% consistent with the real human gaze allocations.","2168-2275","","10.1109/TCYB.2018.2820731","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8358008","Gaze shifting;image kernel;machine learning;non-negative matrix factorization (NMF);scene categorization","Semantics;Kernel;Feature extraction;Image color analysis;Sparse matrices;Image segmentation;Visualization","","21","","88","IEEE","11 May 2018","","","IEEE","IEEE Journals"
"Building Roof Superstructures Classification From Imbalanced and Low Density Airborne LiDAR Point Cloud","B. E. Aissou; A. B. Aissa; A. Dairi; F. Harrou; A. Wichmann; M. Kada","Image Processing and Radiation Laboratory, University of Sciences and Technology Houari Boumediene (USTHB), Bab Ezzouar, Algeria; Image Processing and Radiation Laboratory, University of Sciences and Technology Houari Boumediene (USTHB), Bab Ezzouar, Algeria; Computer Science Department, University of Oran 1 Ahmed Ben Bella, Oran, Algeria; Computer, Electrical and Mathematical Sciences and Engineering Division (CEMSE), King Abdullah University of Science and Technology (KAUST), Thuwal, Saudi Arabia; Landesamt für Geoinformation und Landesvermessung Niedersachsen (LGLN), Hanover, Germany; Institute of Geodesy and Geoinformation Science, Technische Universität Berlin, Berlin, Germany",IEEE Sensors Journal,"30 Jun 2021","2021","21","13","14960","14976","Light Detection and Ranging (LiDAR), an active remote sensing technology, is becoming an essential tool for geoinformation extraction and urban planning. Airborne Laser Scanning (ALS) point clouds segmentation and accurate classification are challenging and crucial to produce different geo-information products like three-dimensional (3D) city designs. This paper introduces an effective data-driven approach to build roof superstructures classification for airborne LiDAR point clouds with very low density and imbalanced classes, covering an urban area. Notably, it focuses on building roof superstructures (especially dormers and chimneys) and mitigating nonplanar objects' problems. Also, the imbalanced class problem of LiDAR data, to the best of our knowledge, is not yet addressed in the literature; it is considered in this study. The major advantage of the proposed approach is using only raw data without assumptions on the distribution underlying data. The main methodological novelties of this work are summarized in the following key elements. (i) At first, an adapted connected component analysis for 3D points cloud is proposed. (ii) Twelve geometry-based features are extracted for each component. (iii) A Support Vector Machine (SVM)-driven procedure is applied to classify the 3D components. (iv) Furthermore, a new component size-based sampling (CSBS) method is proposed to treat the imbalanced data problem and has been compared with several existing resampling strategies. In this study, components are classified into five classes: shed and gable dormers, chimneys, ground, and others. The results of this investigation show the satisfying classification performance of the proposed approach. Results also showed that the proposed approach outperformed machine learning methods, including SVM, Random Forest, Decision Tree, and Adaboost.","1558-1748","","10.1109/JSEN.2021.3073535","Technische Universität Berlin, Institut für Geodäsie und Geoinformationstechnik; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9405642","Low-density point cloud;light detection and ranging (LiDAR);roof superstructures;3D classification;imbalanced data","Three-dimensional displays;Laser radar;Urban areas;Buildings;Image segmentation;Data mining;Feature extraction","","12","","70","IEEE","15 Apr 2021","","","IEEE","IEEE Journals"
"An RRAM-Based Computing-in-Memory Architecture and Its Application in Accelerating Transformer Inference","Z. Lu; X. Wang; M. T. Arafin; H. Yang; Z. Liu; J. Zhang; G. Qu","School of Cyber Science and Engineering, Huazhong University of Science and Technology, Wuhan, China; Department of Integrated Circuit Science and Engineering, Beihang University, Beijing, China; Department of Cyber Security Engineering, George Mason University, Fairfax, VA, USA; Department of Computer Science, Warsaw University of Technology, Warsaw, Poland; School of Cyber Science and Engineering, Huazhong University of Science and Technology, Wuhan, China; College of Semiconductors, Hunan University, Changsha, China; Department of Electrical and Computer Engineering, Institute for Systems Research, University of Maryland, College Park, MD, USA",IEEE Transactions on Very Large Scale Integration (VLSI) Systems,"26 Feb 2024","2024","32","3","485","496","Deep neural network (DNN)-based transformer models have demonstrated remarkable performance in natural language processing (NLP) applications. Unfortunately, the unique scaled dot-product attention mechanism and intensive memory access pose a significant challenge during inference on power-constrained edge devices. One emerging solution to this challenge is computing-in-memory (CIM), which uses memory cells for logic computation to reduce data movement and overcome the memory wall. However, existing CIM designs do not support high-precision computations, such as floating-point operations, which are essential for NLP applications. Furthermore, CIM architectures require complex control modules and costly peripheral circuits to harness the full potential of in-memory computation. Hence, this article proposes a scalable RRAM-based in-memory floating-point computation architecture (RIME) that uses single-cycle NOR, NAND, and minority logic to implement in-memory floating-point operations. RIME features efficient parallel and pipeline capabilities with a centralized control module and a simplified peripheral circuit to eliminate data movement during computation. Furthermore, the article proposes pipelined implementations of matrix–matrix multiplication (MatMul) and softmax functions, enabling the construction of a transformer accelerator based on RIME. Extensive experimental results show that compared with GPU-based implementation, the RIME-based transformer accelerator improves timing efficiency by  $2.3\times $  and energy efficiency by  $1.7\times $  without compromising inference accuracy.","1557-9999","","10.1109/TVLSI.2023.3345651","National Natural Science Foundation of China(grant numbers:62202178); National Natural Science Foundation of China(grant numbers:62004011); University of Maryland, Sub Task Order through ARLIS Project through Computing Instruments(grant numbers:95109-Z9634201); National Natural Science Foundation of China(grant numbers:62122023); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10375354","Accelerator;computing-in-memory (CIM);energy efficiency;resistive random access memory (RRAM);scalability;transformer","Transformers;Computational modeling;Computer architecture;Integrated circuit modeling;Common Information Model (computing);Decoding;Energy efficiency","","3","","45","IEEE","27 Dec 2023","","","IEEE","IEEE Journals"
"Accelerating Wait-Free Algorithms: Pragmatic Solutions on Cache-Coherent Multicore Architectures","J. Wang; Q. Jin; X. Fu; Y. Li; P. Shi","School of Computer Science, Nanjing University of Posts and Telecommunications, Nanjing, China; School of Computer Science, Nanjing University of Posts and Telecommunications, Nanjing, China; School of Computer Science, Nanjing University of Posts and Telecommunications, Nanjing, China; School of Computer Science, Nanjing University of Posts and Telecommunications, Nanjing, China; College of Computer Science, National University of Defense Technology, Changsha, China",IEEE Access,"17 Jun 2019","2019","7","","74653","74669","Parallelizing performance-critical applications are of critical importance for harnessing the power of multicore processors, which are now ubiquitous. Even though wait-free algorithms offer the appeal of completing each operation of a parallelized application in a finite number of steps, high-performance wait-free algorithms at high levels of concurrency are still rare. In this paper, we demonstrate one primary reason for this inefficiency: existing wait-free algorithms are not optimized for processors' caches and write buffers, two key components in modern hardware to accelerate memory accesses. As an example, a wait-free multi-producer-single-consumer queue algorithm, which faces common performance problems of wait-free algorithms, is studied in this paper. We accelerate the queue algorithm by (1) allowing producers to buffer enqueue requests in their local buffers and to write them into the shared queue in batch, to exhibit the spatial locality of the program, and (2) eliminating expensive atomic operations, by giving up some degree of internal consistency to avoid write buffers being drained frequently. The outcome is a write-buffer and cache-friendly queue algorithm which is wait-free and efficient on off-the-shelf multicore processors. The experiments show that the optimized queue algorithm outperforms prior queue algorithms on three different architectures (x86, Power8, and ARMv8). On x86, it outperforms WFQueue, the state-of-the-art solution, by 2-3x, and outperforms CCQueue, the representative of combining solution, by 4-12x. Applying the techniques presented in this paper to other wait-free algorithms is straightforward; our queue example demonstrates that these techniques can be applied to other wait-free algorithms while maintaining the control flow of the original algorithms without dramatic changes.","2169-3536","","10.1109/ACCESS.2019.2920781","National Basic Research Program of China (973 Program)(grant numbers:2018YFB1003702); National Natural Science Foundation of China(grant numbers:61602264,61772030); Primary Research and Development Plan of Jiangsu Province(grant numbers:BE2017743); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8730368","Multicore;wait-free algorithm;MPSC queue","Multicore processing;Acceleration;Hardware;Instruction sets;Concurrent computing;Indexes","","1","","39","OAPA","4 Jun 2019","","","IEEE","IEEE Journals"
"TrueNorth: Design and Tool Flow of a 65 mW 1 Million Neuron Programmable Neurosynaptic Chip","F. Akopyan; J. Sawada; A. Cassidy; R. Alvarez-Icaza; J. Arthur; P. Merolla; N. Imam; Y. Nakamura; P. Datta; G. -J. Nam; B. Taba; M. Beakes; B. Brezzo; J. B. Kuang; R. Manohar; W. P. Risk; B. Jackson; D. S. Modha","IBM Research—Almaden, San Jose, CA, USA; IBM Research—Almaden, San Jose, CA, USA; IBM Research—Almaden, San Jose, CA, USA; IBM Research—Almaden, San Jose, CA, USA; IBM Research—Almaden, San Jose, CA, USA; IBM Research—Almaden, San Jose, CA, USA; IBM Research—Almaden, San Jose, CA, USA; IBM Research–Tokyo, Tokyo, Japan; IBM Research—Almaden, San Jose, CA, USA; IBM Research—Austin, Austin, TX, USA; IBM Research—Almaden, San Jose, CA, USA; IBM’s T. J. Watson Research Center, Yorktown Heights, NY, USA; IBM’s T. J. Watson Research Center, Yorktown Heights, NY, USA; IBM Research—Austin, Austin, TX, USA; Cornell University, Ithaca, NY, USA; IBM Research—Almaden, San Jose, CA, USA; IBM Research—Almaden, San Jose, CA, USA; IBM Research—Almaden, San Jose, CA, USA",IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems,"17 Sep 2015","2015","34","10","1537","1557","The new era of cognitive computing brings forth the grand challenge of developing systems capable of processing massive amounts of noisy multisensory data. This type of intelligent computing poses a set of constraints, including real-time operation, low-power consumption and scalability, which require a radical departure from conventional system design. Brain-inspired architectures offer tremendous promise in this area. To this end, we developed TrueNorth, a 65 mW real-time neurosynaptic processor that implements a non-von Neumann, low-power, highly-parallel, scalable, and defect-tolerant architecture. With 4096 neurosynaptic cores, the TrueNorth chip contains 1 million digital neurons and 256 million synapses tightly interconnected by an event-driven routing infrastructure. The fully digital 5.4 billion transistor implementation leverages existing CMOS scaling trends, while ensuring one-to-one correspondence between hardware and software. With such aggressive design metrics and the TrueNorth architecture breaking path with prevailing architectures, it is clear that conventional computer-aided design (CAD) tools could not be used for the design. As a result, we developed a novel design methodology that includes mixed asynchronous–synchronous circuits and a complete tool flow for building an event-driven, low-power neurosynaptic chip. The TrueNorth chip is fully configurable in terms of connectivity and neural parameters to allow custom configurations for a wide range of cognitive and sensory perception applications. To reduce the system’s communication energy, we have adapted existing application-agnostic very large-scale integration CAD placement tools for mapping logical neural networks to the physical neurosynaptic core locations on the TrueNorth chips. With that, we have successfully demonstrated the use of TrueNorth-based systems in multiple applications, including visual object recognition, with higher performance and orders of magnitude lower power consumption than the same algorithms run on von Neumann architectures. The TrueNorth chip and its tool flow serve as building blocks for future cognitive systems, and give designers an opportunity to develop novel brain-inspired architectures and systems based on the knowledge obtained from this paper.","1937-4151","","10.1109/TCAD.2015.2474396","Defense Advanced Research Projects Agency(grant numbers:HR0011-09-C-0002); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7229264","Asynchronous circuits;asynchronous communication;design automation;design methodology;image recognition;logic design;low-power electronics;neural network hardware;neural networks;neuromorphics;parallel architectures;real-time systems;synchronous circuits;very large-scale integration","Computer architecture;Synchronization;Nerve fibers;Real-time systems;Architecture;Biological neural networks","","1067","12","49","IEEE","28 Aug 2015","","","IEEE","IEEE Journals"
"Using Fuzzy Mask R-CNN Model to Automatically Identify Tomato Ripeness","Y. -P. Huang; T. -H. Wang; H. Basanta","Department of Electrical Engineering, National Taipei University of Technology, Taipei, Taiwan; Department of Electrical Engineering, National Taipei University of Technology, Taipei, Taiwan; Department of Electrical Engineering, National Taipei University of Technology, Taipei, Taiwan",IEEE Access,"24 Nov 2020","2020","8","","207672","207682","Manual inspection and harvesting of ripening tomatoes is time consuming and labor intensive. Smart agriculture can emphasize the use of digital horticultural resources for farming and can increase farm sustainability; to that end, we proposed a fuzzy Mask R-CNN model to automatically identify the ripeness levels of cherry tomatoes. First, to annotate the images automatically, a fuzzy c-means model was used to maintain the spatial information of various foreground and background elements of the image. Then, a Hough transform method was applied to locate the specific geometric edge positions of the tomatoes. Each data point of the image space was annotated to a JavaScript Object Notation file. Second, annotated images were trained with Mask R-CNN to identify each tomato precisely. Finally, to prevent preharvest abscission of tomatoes, a hue-saturation-value color model and fuzzy inference rules were used to predict the ripeness of the tomatoes. A trigonometric function with Euclidian distance was calculated from the origin of calyx and stem to the bottom of the tomato to obtain the position of the pedicle head and dissect the fruit in a timely manner. For detection of 100 tomato images, Mask R-CNN achieved an accuracy of 98.00%. The ripeness classification of tomatoes achieved overall weighted precision and recall rates of 0.9614 and 0.9591, respectively. Thus, automatic tomato harvesting applications can empower farmers to make better decisions and enhance overall production efficiency and yield.","2169-3536","","10.1109/ACCESS.2020.3038184","Ministry of Science and Technology, Taiwan(grant numbers:MOST108-2221-E-027-111-MY3,MOST108-2321-B-027-001-,MOST109-2622-E-027-001-CC3); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9260129","Automatic annotation;detection of tomato ripeness;fuzzy c-means;Mask Region-based Convolutional Neural Network (Mask R-CNN);hue--saturation--value (HSV) color model","Image color analysis;Feature extraction;Green products;Computer architecture;Shape;Production;Image segmentation","","34","","33","CCBY","16 Nov 2020","","","IEEE","IEEE Journals"
"AutomationML Meets Bayesian Networks: A Comprehensive Safety-Security Risk Assessment in Industrial Control Systems","P. Bhosale; W. Kastner; T. Sauter","Institute of Computer Engineering, TU Wien, Vienna, Austria; Institute of Computer Engineering, TU Wien, Vienna, Austria; Institute of Computer Engineering, TU Wien, Vienna, Austria",IEEE Open Journal of the Industrial Electronics Society,"16 Aug 2024","2024","5","","823","835","Industrial control systems (ICSs) play a crucial role in the smooth operation of critical infrastructures, and their increasing complexity and interconnectedness necessitate integrating safety and security measures. Thus, an integrated risk assessment approach is essential to identify and address potential hazards and vulnerabilities. However, conducting such risk assessments becomes complex and challenging due to the difficulty in data availability. Acquiring data from various sources poses a significant hurdle. To address these challenges, automation markup language (AML) provides a standardized framework that facilitates the seamless exchange of engineering information. This article uses AML libraries and connection setup techniques to generate a valuable model of a single source of data for an integrated safety and security risk assessment. The automated risk assessment employs the AML model as a data source and the Bayesian belief network (BBN) as the risk assessment method. The value of risk associated with the system is calculated using the BBN models as the product of the probability of occurrence and severity. An evaluation of the proposed risk assessment method is also provided based on ISO 31000. AML's effectiveness as a valuable information model in meeting the growing need for comprehensive safety and security risk assessment in ICSs is demonstrated.","2644-1284","","10.1109/OJIES.2024.3439388","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10623880","Automation markup language (AutomationML);industrial control systems (ICSs);Bayesian belief networks (BBN);integrated risk assessment;safety;and security","Risk management;Safety;Security;Data models;Object oriented modeling;Libraries;Hazards","","","","45","CCBYNCND","6 Aug 2024","","","IEEE","IEEE Journals"
"Universal and Dynamic Locally Repairable Codes With Maximal Recoverability via Sum-Rank Codes","U. Martínez-Peñas; F. R. Kschischang","Edward S. Rogers Sr. Department of Electrical and Computer Engineering, University of Toronto, Toronto, Canada; Edward S. Rogers Sr. Department of Electrical and Computer Engineering, University of Toronto, Toronto, Canada",IEEE Transactions on Information Theory,"20 Nov 2019","2019","65","12","7790","7805","Locally repairable codes (LRCs) are considered with equal or unequal localities, local distances, and local field sizes. An explicit two-layer architecture with a sum-rank outer code is obtained, having disjoint local groups and achieving maximal recoverability (MR) for all families of local linear codes (MDS or not) simultaneously, up to a specified maximum locality  $r $ . Furthermore, the local linear codes (thus the localities, local distances, and local fields) can be efficiently and dynamically modified without global recoding or changes in architecture or outer code, while preserving the MR property, easily adapting to new configurations in storage or new hot and cold data. In addition, local groups and file components can be added, removed or updated without global recoding. The construction requires global fields of size roughly  $g^{r} $ , for  $g $  local groups and maximum or specified locality  $r $ . For equal localities, these global fields are smaller than those of previous MR-LRCs when  $r \leq h $  (global parities). For unequal localities, they provide an exponential field size reduction on all previous best known MR-LRCs. For bounded localities and a large number of local groups, the global erasure-correction complexity of the given construction is comparable to that of Tamo–Barg codes or Reed–Solomon codes with local replication, while local repair is as efficient as for the Cartesian product of the local codes. Reed–Solomon codes with local replication and Cartesian products are recovered from the given construction when  $r=1 $  and  $h = 0 $ , respectively. The given construction can also be adapted to provide hierarchical MR-LRCs for all types of hierarchies and parameters. Finally, subextension subcodes and sum-rank alternant codes are introduced to obtain further exponential field size reductions, at the expense of lower information rates.","1557-9654","","10.1109/TIT.2019.2924888","Natur og Univers, Det Frie Forskningsråd(grant numbers:DFF-7027-00053B); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8745538","Distributed storage;hierarchical locality;linearized Reed-Solomon codes;locally repairable codes;maximally recoverable codes;partial MDS codes;sum-rank codes;unequal localities","Maintenance engineering;Reed-Solomon codes;Complexity theory;Spread spectrum communication;Information rates;Decoding;Linear codes","","65","","49","IEEE","25 Jun 2019","","","IEEE","IEEE Journals"
"Multi-Gateway Data Predistortion for Non-Linear Satellite Channels","R. Piazza; B. S. M. R.; B. Ottersten","Interdisciplinary Centre for Security, Reliability and Trust (SnT), University of Luxembourg, Luxembourg City, Luxembourg; Interdisciplinary Centre for Security, Reliability and Trust (SnT), University of Luxembourg, Luxembourg City, Luxembourg; Interdisciplinary Centre for Security, Reliability and Trust (SnT), University of Luxembourg, Luxembourg City, Luxembourg",IEEE Transactions on Communications,"15 Oct 2015","2015","63","10","3789","3802","Joint on-board amplification of multiple carriers reduces hardware and weight, enabling cost-efficient satellite architectures. However, on-board power amplification is inherently a non-linear operation and the distortion effects drastically increase when the high-power amplifier (HPA) is operated in multiple-carrier mode due to the generated inter-modulation products. In order to achieve the desired on-board power efficiency and to reduce the non-linear distortion, specific countermeasures need to be put in place. Emerging multi-gateway satellite systems where, in the most general case, each carrier is uplinked independently from a different gateway, would gain further flexibility by adopting a multicarrier architecture. While advanced predistortion techniques are already available for the single-gateway scenario, no solution has been proposed for the multi-gateway multicarrier scenario. In this work, we propose novel distributed predistortion techniques to improve spectral and power efficiency in multi-gateway non-linear satellite channels. Further, we analyze the multiple-carrier predistortion parameter estimation error with respect to noise sensitivity, proposing a robust version of the indirect learning method. Distributed processing becomes sensitive to synchronization amongst the actors, and we present an evaluation of the sensitivity of proposed techniques to imperfections.","1558-0857","","10.1109/TCOMM.2015.2460245","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7165611","Multi-gateway;multicarrier;on-board HPA;distributed predistortion;distributed processing;Non-linear satellite channel;Multi-gateway;multicarrier;on-board HPA;distributed predistortion;distributed processing;non-linear satellite channel","Predistortion;Logic gates;Satellites;Distortion;Uplink;Joints;Frequency modulation","","5","","26","IEEE","23 Jul 2015","","","IEEE","IEEE Journals"
"Automated Defect Detection for Mass-Produced Electronic Components Based on YOLO Object Detection Models","W. -L. Mao; C. -C. Wang; P. -H. Chou; Y. -T. Liu","Department of Electrical Engineering and the Graduate School of Engineering Science and Technology, National Yunlin University of Science and Technology (NYUST), Douliu, Yunlin, Taiwan; Department of Electrical Engineering and the Graduate School of Engineering Science and Technology, National Yunlin University of Science and Technology (NYUST), Douliu, Yunlin, Taiwan; Research Center for Information Technology Innovation (CITI), Academia Sinica (AS), Taipei, Taiwan; Institute of Communications Engineering (ICE), National Sun Yat-sen University (NSYSU), Kaohsiung, Taiwan",IEEE Sensors Journal,"15 Aug 2024","2024","24","16","26877","26888","Since the defect detection of conventional industry components is time-consuming and labor-intensive, it leads to a significant burden on quality inspection personnel and difficult to manage product quality. In this article, we propose an automated defect detection system for the dual in-line package (DIP) that is widely used in industry, using digital camera optics and deep learning (DL)-based model. The two most common defect categories of DIP are examined:  $\text {1)}$  surface defects and  $\text {2)}$  pin-leg defects. However, the lack of defective component images leads to a challenge for detection tasks. To solve this problem, the ConSinGAN is used to generate a suitable size dataset for training and testing. Four varieties of the you only look once (YOLO) model are investigated (v3, v4, v7, and v9), both in isolation and with the ConSinGAN augmentation. The proposed YOLOv7 with ConSinGAN is superior to the other YOLO versions in accuracy of 95.50%, detection time of 285 ms, and is far superior to threshold-based approaches. In addition, the supervisory control and data acquisition (SCADA) system is developed, and the associated sensor architecture is described. The proposed automated defect detection can be easily established with numerous types of defects or insufficient defect data.","1558-1748","","10.1109/JSEN.2024.3418618","Academia Sinica under Grant 235g Postdoctoral Scholar Program; National Science and Technology Council (NSTC) of Taiwan(grant numbers:113-2926-I-001-502-G); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10579726","Automated defect detection;automated optical inspection (AOI);camera sensor;ConSinGAN;deep learning (DL);dual in-line package (DIP) switch;you only look once (YOLO)","YOLO;Electronics packaging;Cameras;Defect detection;Sensors;Surface waves;Production","","2","","57","IEEE","1 Jul 2024","","","IEEE","IEEE Journals"
"Novel Low-Complexity Polynomial Multiplication Over Hybrid Fields for Efficient Implementation of Binary Ring-LWE Post-Quantum Cryptography","P. He; U. Guin; J. Xie","Department of Electrical and Computer Engineering, Villanova University, Villanova, PA, USA; Department of Electrical and Computer Engineering, Auburn University, Auburn, AL, USA; Department of Electrical and Computer Engineering, Villanova University, Villanova, PA, USA",IEEE Journal on Emerging and Selected Topics in Circuits and Systems,"11 Jun 2021","2021","11","2","383","394","Post-quantum cryptography (PQC) refers to the cryptosystem that can resist the attacks launched from mature quantum computers in the not far future and has recently gained intensive attention from the research community as most of the existing public-key cryptosystems are vulnerable to attacks from quantum computers. Ring-Learning-with-Errors (Ring-LWE)-based scheme is an essential type of the lattice-based PQC due to its strong security proof and ease of implementation. As the latest variant of the Ring-LWE, the binary Ring-LWE (BRLWE)-based scheme possesses even smaller computational complexity and thus is more suitable for resource-constrained applications. However, the existing works have not well covered various aspects related to this new scheme, especially on the low-complexity hardware implementation. In this paper, we aim to present a novel implementation of the BRLWE-based scheme on the hardware platform with very low-complexity with this point of view. To carry out the specified work in a successful manner, we have proposed mainly four layers of coherent interdependent efforts: (i) we have provided the necessary algorithmic derivation process in detail to formulate the desired algorithm for the polynomial multiplication over hybrid fields, which is the major arithmetic component of the BRLWE scheme; (ii) we have presented the corresponding hardware architecture in a thorough format with sufficient description of the internal structures; (iii) we have also provided the complexity analysis and implementation-based comparison to demonstrate the superior performance of the proposed polynomial multiplication over the state-of-the-art design; (iv) finally, we have extended the proposed low-complexity polynomial multiplication to the major operational phase of the BRLWE scheme. We have shown that the proposed BRLWE structure involves significantly lower area-time complexities over the existing design, e.g., the proposed design has at least 66.01% less area-delay product (ADP) than the newly reported (Straix V device). Overall, the proposed design and implementation strategies are highly efficient, and the proposed BRLWE structure is desirable for many emerging applications.","2156-3365","","10.1109/JETCAS.2021.3075456","National Science Foundation(grant numbers:CNS-2020625,CNS-1755733,NIST-60NANB20D203); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9415642","Binary Ring-Learning-with-Errors (BRLWE) scheme;field-programmable gate array (FPGA);hardware platform;low-complexity;polynomial multiplication;post-quantum cryptography (PQC)","Hardware;Complexity theory;Circuits and systems;Computers;Quantum computing;Elliptic curve cryptography;Standards","","17","","29","IEEE","26 Apr 2021","","","IEEE","IEEE Journals"
"Designing Secure and Resilient Cyber-Physical Systems: A Model-Based Moving Target Defense Approach","V. Casola; A. De Benedictis; C. Mazzocca; R. Montanari","Department of Electrical Engineering and Information Technology, University of Naples Federico II, Naples, Italy; Department of Electrical Engineering and Information Technology, University of Naples Federico II, Naples, Italy; Department of Computer Science and Engineering, Alma Mater Studiorum University of Bologna, Bologna, Italy; Department of Computer Science and Engineering, Alma Mater Studiorum University of Bologna, Bologna, Italy",IEEE Transactions on Emerging Topics in Computing,"10 Jun 2024","2024","12","2","631","642","Cyber-physical systems (CPSs) rely upon the deep integration of computation and physical processes/systems, enabled by Internet of Things (IoT), edge computing, and cloud technologies. Noticeably, cybersecurity is a major concern in CPSs, since attacks may exploit both cyber and physical vulnerabilities and damage significantly physical equipment, compromise operational safety, and impact negatively on product quality and performance. In this context, CPS design should take both security and resilience requirements into account, by identifying the needed measures not only to prevent but also to withstand, recover from, and adapt to adverse conditions and attacks. The approach proposed in this article aims at improving the security and resilience of a CPS deployment through a model-based design methodology leveraging security-by-design principles and Moving Target Defense (MTD) techniques, consisting in continually shifting a system configuration to reduce the attack success probability and survive attacks. Our methodology, in particular, is meant to support the threat modeling process of a CPS and the identification, based on spotted threats and on the properties of involved assets and data, of the security controls to include within the design to mitigate existing threats and of the MTD techniques to integrate in order to increase resilience.","2168-6750","","10.1109/TETC.2022.3197464","Università degli Studi di Napoli Federico II; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9857751","CPS threat modeling;CPS system modeling;resilient and secure CPS design;moving target defense","Security;Internet of Things;Resilience;Computer architecture;Cloud computing;Computational modeling;Safety","","1","","35","IEEE","16 Aug 2022","","","IEEE","IEEE Journals"
"Development of an Electronic Tongue Based on a Nanocomposite for Discriminating Flavor Enhancers and Commercial Salts","K. L. Fukushima; V. P. Scagion; M. H. Moreira Facure; A. C. Marques Pinheiro; D. S. Correa; C. A. Nunes; J. E. Oliveira","Department of Engineering, Universidade Federal de Lavras, Lavras, Brazil; Department of Chemistry, Programa de Pós-Graduação em Química, Universidade Federal de São Carlos, São Carlos, Brazil; Department of Chemistry, Programa de Pós-Graduação em Química, Universidade Federal de São Carlos, São Carlos, Brazil; Department of Engineering, Universidade Federal de Lavras, Lavras, Brazil; Embrapa Instrumentação, São Carlos, Brazil; Department of Engineering, Universidade Federal de Lavras, Lavras, Brazil; Department of Engineering, Universidade Federal de Lavras, Lavras, Brazil",IEEE Sensors Journal,"17 Dec 2020","2021","21","2","1250","1256","Diets with a high sodium chloride (NaCl) intake are indicated by doctors to be a factor responsible for causing cardiovascular disease. This has led to the search for NaCl substitutes used to prepare meals and process industrialized products, resulting in the food industry using new compounds. In this context, flavor enhancers appear to be able to maintain the sensory characteristics of food and reduce the amount of NaCl used. Substituting NaCl with other light commercial salts may also represent an alternative to reducing its consumption. Thus, it is of great importance to have a sensitive, portable, reliable, and cost-effective sensors for monitoring salt and flavor enhancers. For that reason, developing methodologies and devices able to chemically analyze salts and capable of establishing a relationship with human taste perception has become relevant for quality control and product development. In this context, this study proposes developing and applying an e-tongue system that can analyze aqueous solutions containing different concentrations of flavor enhancers (monosodium glutamate, disodium guanylate and disodium inosinate), light commercial salts and NaCl. The e-tongue comprised four gold interdigitated electrodes (IDEs) modified with layer-by-layer films of copper tetrasulfonated phthalocyanine (CuTsPc), polyaniline (PANI), reduced graphene oxide (rGO), poly(allylamine hydrochloride) (PAH) and silver nanoparticles (AgNPs) with different architectures. Data were statistically analyzed using principal component analysis (PCA). The e-tongue system proved to be efficient for identifying and discriminating flavor enhancers and commercial salts at different concentrations and is a possible alternative for quality control analysis and product development in the food industry.","1558-1748","","10.1109/JSEN.2020.3021653","São Paulo Research Foundation (FAPESP)(grant numbers:2017/12174-4,2017/10582-8); National Council for Scientific and Technological Development (CNPq); MCTI-SisNano(grant numbers:CNPq/402.287/2013-4); Brazilian Federal Agency for the Support and Evaluation of Graduate Education (CAPES) Financing Code 001; Minas Gerais Research Foundation (FAPEMIG); Agronano Network (EMBRAPA) of Brazil; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9186083","Commercial salts;electronic tongue;flavor enhancers;impedance spectroscopy","Sodium;Tongue;Films;Sensors;Electrodes;Food industry;Graphene","","16","","63","IEEE","3 Sep 2020","","","IEEE","IEEE Journals"
"Multiscale Residual Attention Network for Distinguishing Stationary Humans and Common Animals Under Through-Wall Condition Using Ultra-Wideband Radar","Y. Ma; F. Qi; P. Wang; F. Liang; H. Lv; X. Yu; Z. Li; H. Xue; J. Wang; Y. Zhang","Department of Medical Electronics, School of Biomedical Engineering, Fourth Military Medical University, Xi’an, China; Department of Medical Electronics, School of Biomedical Engineering, Fourth Military Medical University, Xi’an, China; Department of Medical Electronics, School of Biomedical Engineering, Fourth Military Medical University, Xi’an, China; Department of Medical Electronics, School of Biomedical Engineering, Fourth Military Medical University, Xi’an, China; Department of Medical Electronics, School of Biomedical Engineering, Fourth Military Medical University, Xi’an, China; Department of Medical Electronics, School of Biomedical Engineering, Fourth Military Medical University, Xi’an, China; Department of Medical Electronics, School of Biomedical Engineering, Fourth Military Medical University, Xi’an, China; Department of Medical Electronics, School of Biomedical Engineering, Fourth Military Medical University, Xi’an, China; Department of Medical Electronics, School of Biomedical Engineering, Fourth Military Medical University, Xi’an, China; Department of Medical Electronics, School of Biomedical Engineering, Fourth Military Medical University, Xi’an, China",IEEE Access,"10 Jul 2020","2020","8","","121572","121583","Distinguishing between humans and common animals through a wall is necessary for facilitating successful rescue of survivors and enhancing the confidence of rescuers in post-disaster search and rescue operations. However, few existing solutions are available with only dogs considered in this scenario. This poses an issue in ensuring the recognition accuracy involving different animal species. This work proposed a novel multiscale residual attention network for distinguishing between stationary humans and common animals under a through-wall condition based on ultra-wideband radar, which is yet to be performed by existing research using deep learning. Humans, dogs, cats, rabbits, and no target data are collected and distinguished. The overall architecture of the proposed method differed from conventional deep learning methods as it is constructed by parallel 3 × 3 and 5 × 5 kernels incorporated with the residual attention learning mechanism. The effect of the slow-time dimension on the classification performance is analyzed, thereby producing an optimal input size. The overall F1-score of the proposed network can reach a high value of 0.9064 and the recognition accuracy of human targets can reach 0.983 satisfying the requirements for post-disaster rescue. Then, the effectiveness and advancement of the three components of the overall network architecture are validated by ablation studies. Finally, the proposed method is compared with three state-of-the-art methods. Comparison results indicate that the proposed method achieve a better performance. The network and its results are envisioned to be applied in various practical situations, such as earthquake rescue and intelligent homecare.","2169-3536","","10.1109/ACCESS.2020.3006834","National Basic Research Program of China (973 Program)(grant numbers:2018YFC0810201); National Natural Science Foundation of China(grant numbers:31800822); Fourth Military Medical University (FMMU) Zhufeng Project(grant numbers:2018RCFC08); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9133087","Convolutional neural network (CNN);distinguishing between stationary humans and common animals;post-disaster rescue;residual attention learning mechanism;ultra-wideband (UWB) radar","Feature extraction;Ultra wideband radar;Deep learning;Dogs","","15","","33","CCBY","3 Jul 2020","","","IEEE","IEEE Journals"
"Blockchain-Based Identity Management: A Survey From the Enterprise and Ecosystem Perspective","M. Kuperberg","Blockchain and Distributed Ledgers Group, DB Systel GmbH, Frankfurt am Main, Germany",IEEE Transactions on Engineering Management,"16 Oct 2020","2020","67","4","1008","1027","Identity management is a core building block for the majority of software solutions and landscapes. Competing with existing identity-managing solutions, blockchain-based concepts and products have evolved in the context of verified claims and self-sovereign identities. The contribution of this paper is a systematic, criteria-driven survey of the solutions and technologies for this growing field and their comparison with the capabilities of established solutions. By including an extensive set of requirements covering ecosystem aspects, end-user functionality, mobility and overhead aspects, compliance/liability, EU regulations, standardization, and integration, this paper shows the highlights and the deficits of a wide array of solutions.","1558-0040","","10.1109/TEM.2019.2926471","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8792372","Blockchain;decentralization;distributed ledger technology (DLT);identity and access management (IAM);identity management;self-sovereignty;trust networks;verified claims","Standards;Ecosystems;Authentication;Distributed ledger;Blockchain;General Data Protection Regulation;International collaboration","","96","","151","IEEE","8 Aug 2019","","","IEEE","IEEE Journals"
"Towards an Ontology for Scenario Definition for the Assessment of Automated Vehicles: An Object-Oriented Framework","E. de Gelder; J. -P. Paardekooper; A. K. Saberi; H. Elrofai; O. O. d. Camp; S. Kraines; J. Ploeg; B. De Schutter","Department of Integrated Vehicle Safety, TNO, Helmond, JZ, The Netherlands; Department of Integrated Vehicle Safety, TNO, Helmond, JZ, The Netherlands; TomTom, Automated Driving Product Unit, Eindhoven, The Netherlands; Mobile Perception Systems Lab, Eindhoven University of Technology, Eindhoven, AZ, The Netherlands; Department of Integrated Vehicle Safety, TNO, Helmond, JZ, The Netherlands; Symphony Company, Tokyo, Japan; 2getthere, Utrecht, AE, The Netherlands; Delft Center for Systems and Control, Delft University of Technology, Delft, CD, The Netherlands",IEEE Transactions on Intelligent Vehicles,"11 Jul 2022","2022","7","2","300","314","The development of new assessment methods for the performance of automated vehicles is essential to enable the deployment of automated driving technologies, due to the complex operational domain of automated vehicles. One contributing method is scenario-based assessment in which test cases are derived from real-world road traffic scenarios obtained from driving data. Given the complexity of the reality that is being modeled in these scenarios, it is a challenge to define a structure for capturing these scenarios. An intensional definition that provides a set of characteristics that are deemed to be both necessary and sufficient to qualify as a scenario assures that the scenarios constructed are both complete and intercomparable. In this article, we develop a comprehensive and operable definition of the notion of scenario while considering existing definitions in the literature. This is achieved by proposing an object-oriented framework in which scenarios and their building blocks are defined as classes of objects having attributes, methods, and relationships with other objects. The object-oriented approach promotes clarity, modularity, reusability, and encapsulation of the objects. We provide definitions and justifications of each of the terms. Furthermore, the framework is used to translate the terms in a coding language that is publicly available.","2379-8904","","10.1109/TIV.2022.3144803","Centre of Excellence for Testing and Research of Autonomous Vehicles at NTU; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9693162","Automatic testing;autonomous vehicles;intelligent vehicles;object-oriented modeling;performance evaluation;system testing;vehicle safety","Object oriented modeling;Vehicle dynamics;Encoding;Ontologies;Mathematical models;Safety;Intelligent vehicles","","35","","81","IEEE","25 Jan 2022","","","IEEE","IEEE Journals"
"Wideband Predistortion Technique With Dual-Parallel Schottky Diodes for Low Power RoF Systems","H. -S. Kim; J. -S. Lee; B. -H. Son; S. -J. Jeon; S. -H. Hong; Y. -J. Kim; K. -J. Kim; Y. -W. Choi","Department of Electrical and Electronics Engineering, Advanced Photonics Laboratory (APL), Chung-Ang University, Seoul, Republic of Korea; Department of Electrical and Electronics Engineering, Advanced Photonics Laboratory (APL), Chung-Ang University, Seoul, Republic of Korea; Honam Research Center, Electronics and Telecommunications Research Institute, Gwangju, South Korea; Department of Electrical and Electronics Engineering, Advanced Photonics Laboratory (APL), Chung-Ang University, Seoul, Republic of Korea; Department of Electrical and Electronics Engineering, Advanced Photonics Laboratory (APL), Chung-Ang University, Seoul, Republic of Korea; Department of Electrical and Electronics Engineering, Advanced Photonics Laboratory (APL), Chung-Ang University, Seoul, Republic of Korea; SYSFORM, Seoul, South Korea; Department of Electrical and Electronics Engineering, Advanced Photonics Laboratory (APL), Chung-Ang University, Seoul, Republic of Korea",IEEE Photonics Technology Letters,"10 May 2021","2021","33","11","569","572","Radio-over-fiber (RoF)-based front haul architecture has attracted considerable attention for fifth-generation (5G) cellular systems because of its cost effectiveness, however, it is susceptible to harmonic frequency distortion and intermodulation products (IMs) arising from the nonlinearity of the laser diode. To overcome this limitation, an asymmetric electrical predistortion method, using a single Schottky diode with nonlinear characteristics similar to those of a laser diode, was previously proposed. However, its asymmetric structure causes a phase mismatch, which limits the system bandwidth. In this study, we propose an enhanced electrical predistortion technique using dual-parallel Schottky diode blocks. The proposed technique was validated by experiments involving an IM3 drop of approximately 27 dB, and by using identical dual Schottky diode blocks, the phase mismatch in the previously proposed method is completely eliminated. Thus, the applicable bandwidth is extended to 1.8 GHz. This technique can be used to improve the linearity and increase the bandwidth of RoF systems. Additionally, the simple structure is attractive for low-power applications.","1941-0174","","10.1109/LPT.2021.3076188","Basic Science Research Program through the National Research Foundation of Korea (NRF) by the Ministry of Education(grant numbers:NRF-2018 R1D1A1B07048145); Chung-Ang University Research Scholarship; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9417191","Predistortion;radio over fiber systems;Schottky diode;nonlinearity;third-order intermodulation","Schottky diodes;Bandwidth;Predistortion;Diode lasers;Optical modulation;Optical distortion;Fiber nonlinear optics","","3","","20","IEEE","28 Apr 2021","","","IEEE","IEEE Journals"
"Prognostics for Electromagnetic Relays Using Deep Learning","L. Kirschbaum; V. Robu; J. Swingler; D. Flynn","Smart-Systems Group, School of Engineering and Physical Science, Heriot-Watt University, Edinburgh, U.K; CWI, Dutch National Research Institute for Mathematics and Computer Science, Intelligent and Autonomous Systems, Amsterdam, XG, The Netherlands; Smart-Systems Group, School of Engineering and Physical Science, Heriot-Watt University, Edinburgh, U.K; Smart-Systems Group, School of Engineering and Physical Science, Heriot-Watt University, Edinburgh, U.K",IEEE Access,"17 Jan 2022","2022","10","","4861","4895","Electromagnetic Relays (Electromagnetic Relay (EMR)s) are omnipresent in electrical systems, ranging from mass-produced consumer products to highly specialised, safety-critical industrial systems. Our detailed literature review focused on EMR reliability highlighting the methods used to estimate the State of Health or the Remaining Useful Life emphasises the limited analysis and understanding of expressive EMR degradation indicators, as well as accessibility and use of EMR life cycle data sets. Prioritising these open challenges, a deep learning pipeline is presented in a prognostic context termed Electromagnetic Relay Useful Actuation Pipeline (EMRUA). Leveraging the attributes of causal convolution, a Temporal Convolutional Network (TCN) based architecture integrates an arbitrary long sequence of multiple features to produce a remaining useful switching actuations forecast. These features are extracted from raw, high volume life cycle data sets, namely EMR switching data (Contact-Voltage, Contact-Current). Monte-Carlo Dropout is utilised to estimate uncertainty during inference. The TCN hyperparameter space, as well as various methods to select and analyse long sequences of multivariate time series data are investigated. Subsequently, our results demonstrate improvements using the developed statistical feature-set over traditional, time-based features, commonly found in literature. EMRUA achieves an average forecasting mean absolute percentage error of ±12 % over the course of the entire EMR life.","2169-3536","","10.1109/ACCESS.2022.3140645","Engineering and Physical Sciences Research Council (EPSRC) Centre for Doctoral Training in Embedded Intelligence, U.K.(grant numbers:EP/L014998/1); Baker Hughes; Lloyds Register Foundation(grant numbers:AtRI100015); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9671352","Electromagnetic relay;prognostics;prognostics and health management;predictive maintenance;remaining useful life;artificial intelligence;deep learning;temporal convolutional networks;Monte-Carlo dropout","Relays;Estimation;Electromagnetics;Uncertainty;Switches;Reliability;Prognostics and health management","","7","","142","CCBY","6 Jan 2022","","","IEEE","IEEE Journals"
"Impact of SMOTE on Imbalanced Text Features for Toxic Comments Classification Using RVVC Model","V. Rupapara; F. Rustam; H. F. Shahzad; A. Mehmood; I. Ashraf; G. S. Choi","School of Computing and Information Sciences, Florida International University, Miami, FL, USA; Department of Computer Science, Khwaja Fareed University of Engineering and Information Technology, Rahim Yar Khan, Pakistan; Department of Computer Science, Khwaja Fareed University of Engineering and Information Technology, Rahim Yar Khan, Pakistan; Department of Computer Science and Information Technology, The Islamia University of Bahawalpur, Bahawalpur, Pakistan; Department of Information and Communication Engineering, Yeungnam University, Gyeongsan, South Korea; Department of Information and Communication Engineering, Yeungnam University, Gyeongsan, South Korea",IEEE Access,"2 Jun 2021","2021","9","","78621","78634","Social media platforms and microblogging websites have gained accelerated popularity during the past few years. These platforms are used for expressing views and opinions about products, personalities, and events. Often during discussions and debates, fights take place on social media platforms which involves using rude, disrespectful, and hateful comments called toxic comments. The identification of toxic comments has been regarded as an essential element for social media platforms. This study introduces an ensemble approach, called regression vector voting classifier (RVVC), to identify the toxic comments on social media platforms. The ensemble merges the logistic regression and support vector classifier under soft voting criteria. Several experiments are performed on the imbalanced and balanced dataset to analyze the performance of the proposed approach. For data balance, the synthetic minority oversampling technique (SMOTE) is used on the imbalanced dataset. Furthermore, two feature extraction approaches are utilized to investigate their suitability such as term frequency-inverse document frequency (TF-IDF) and bag-of-words (BoW). The performance of the proposed approach is compared with several machine learning classifiers using accuracy, precision, recall, and F1-score. Results suggest that RVVC outperforms all other individual models when TF-IDF features are used with SMOTE balanced dataset and achieves an accuracy of 0.97.","2169-3536","","10.1109/ACCESS.2021.3083638","Basic Science Research Program through the National Research Foundation of Korea (NRF) funded by the Ministry of Education(grant numbers:NRF-2019R1A2C1006159); Ministry of Science and ICT (MSIT), South Korea, through the Information Technology Research Center (ITRC) support program supervised by the Institute for Information and communications Technology Promotion (IITP)(grant numbers:IITP-2021-2016-0-00313); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9440474","Toxic comments classification;ensemble classifier;synthetic minority oversampling technique;TF-IDF;BoW;text classification;data re-sampling","Social networking (online);Support vector machines;Blogs;Feature extraction;Deep learning;Machine learning;Logistics","","112","","51","CCBY","25 May 2021","","","IEEE","IEEE Journals"
"Blockchain for the Internet of Vehicles Towards Intelligent Transportation Systems: A Survey","M. B. Mollah; J. Zhao; D. Niyato; Y. L. Guan; C. Yuen; S. Sun; K. -Y. Lam; L. H. Koh","School of Computer Science and Engineering, Nanyang Technological University, Singapore; School of Computer Science and Engineering, Nanyang Technological University, Singapore; School of Computer Science and Engineering, Nanyang Technological University, Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; Engineering Product Development Pillar, Singapore University of Technology and Design, Singapore; Institute for Infocomm Research, Agency for Science, Technology and Research, Singapore; School of Computer Science and Engineering, Nanyang Technological University, Singapore; Energy Research Institute, Nanyang Technological University, Singapore",IEEE Internet of Things Journal,"5 Mar 2021","2021","8","6","4157","4185","Internet of Vehicles (IoV) is an emerging concept that is believed to help realize the vision of intelligent transportation systems (ITSs). IoV has become an important research area of impactful applications in recent years due to the rapid advancements in vehicular technologies, high throughput satellite communication, the Internet of Things, and cyber-physical systems. IoV enables the integration of smart vehicles with the Internet and system components attributing to their environments, such as public infrastructures, sensors, computing nodes, pedestrians, and other vehicles. By allowing the development of a common information exchange platform between vehicles and heterogeneous vehicular networks, this integration aims to create a better environment and public space for the people as well as to enhance safety for all road users. Being a participatory data exchange and storage, the underlying information exchange platform of IoV needs to be secure, transparent, and immutable in order to achieve the intended objectives of ITS. In this connection, the adoption of blockchain as a system platform for supporting the information exchange needs of IoV has been explored. Due to their decentralized and immutable nature, IoV applications enabled by blockchain are believed to have a number of desirable properties, such as decentralization, security, transparency, immutability, and automation. In this article, we present a contemporary survey on the latest advancement in blockchain for IoV. Particularly, we highlight the different application scenarios of IoV after carefully reviewing the recent literature. We also investigate several key challenges where blockchain is applied in IoV. Furthermore, we present the future opportunities and explore further research directions of IoV as a key enabler of ITS.","2327-4662","","10.1109/JIOT.2020.3028368","Nanyang Technological University (NTU) Startup Grant; Alibaba-NTU Singapore Joint Research Institute (JRI); Ministry of Education Singapore Academic Research Fund(grant numbers:Tier 1 RG128/18,Tier 1 RG115/19,Tier 1 RT07/19,Tier 1 RT01/19,RG24/20,Tier 2 MOE2019-T2-1-176); NTU-WASP Joint Project; Singapore National Research Foundation (NRF) under its Strategic Capability Research Centres Funding Initiative: Strategic Centre for Research in Privacy-Preserving Technologies and Systems; Energy Research Institute @NTU; Singapore NRF National Satellite of Excellence, Design Science and Technology for Secure Critical Infrastructure NSoE(grant numbers:DeSTSCI2019-0012); AI Singapore 100 Experiments (100E) Programme; NTU Project for Large Vertical Take-Off and Landing Research Platform; NRF, Singapore, under Singapore Energy Market Authority, Energy Resilience(grant numbers:NRF2017EWT-EP003-041); Singapore NRF(grant numbers:NRF2015-NRF-ISF001-2277); Singapore NRF National Satellite of Excellence, Design Science and Technology for Secure Critical Infrastructure NSoE(grant numbers:DeST-SCI2019-0007); A*STAR-NTU-SUTD Joint Research Grant on Artificial Intelligence for the Future of Manufacturing(grant numbers:RGANS1906); Wallenberg AI, Autonomous Systems and Software Program and Nanyang Technological University(grant numbers:M4082187 (4080)); Singapore Ministry of Education (MOE)(grant numbers:Tier 1 (RG16/20)); Alibaba Group through Alibaba Innovative Research Program; Alibaba-NTU Singapore Joint Research Institute; A*STAR under its RIE2020 Advanced Manufacturing and Engineering Industry Alignment Fund—Prepositioning(grant numbers:A19D6a0053); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9211724","Blockchain;connected vehicles;intelligent transportation system (ITS);Internet of Things (IoT);Internet of Vehicles (IoV);security;smart transportation;smart vehicle","Blockchain;Internet of Things;Computer architecture;Cryptography;Edge computing;Intelligent transportation systems","","277","","127","IEEE","2 Oct 2020","","","IEEE","IEEE Journals"
"SQ-Swin: Siamese Quadratic Swin Transformer for Lettuce Browning Prediction","D. Wang; B. Zhang; Y. Xu; Y. Luo; H. Yu","Department of Electrical and Computer Engineering, University of Massachusetts at Lowell, Lowell, MA, USA; Department of Food Science and Human Nutrition, University of Florida, Gainesville, FL, USA; Department of Electrical and Computer Engineering, University of Massachusetts at Lowell, Lowell, MA, USA; United States Department of Agriculture, Food Quality Laboratory/Environmental Microbial and Food Safety Laboratory, Agricultural Research Service, Beltsville, MD, USA; Department of Electrical and Computer Engineering, University of Massachusetts at Lowell, Lowell, MA, USA",IEEE Access,"21 Nov 2023","2023","11","","128724","128735","Enzymatic browning is a major quality defect of packaged “ready-to-eat” fresh-cut lettuce salads. While there have been many research and breeding efforts to counter this problem, progress is hindered by the lack of a technology to identify and quantify browning rapidly, objectively, and reliably. Here, we report a deep learning model for lettuce browning score prediction. To the best of our knowledge, it is the first-of-its-kind on deep learning for lettuce browning prediction using a Siamese Quadratic Swin (SQ-Swin) transformer with several highlights. First, our model includes quadratic features in the transformer model which is more powerful to incorporate real world representations than the linear transformer. Second, a multi-scale training strategy is employed to augment the data and explore more of the inherent self-similarity of the lettuce images. Third, the proposed model uses a siamese architecture which learns the inter-relations among the limited training samples. Fourth, the model is pretrained on the ImageNet and then trained with the reptile meta-learning algorithm to learn higher-order gradients than a regular one. Experiment results on the fresh-cut lettuce datasets show that the proposed SQ-Swin outperforms the traditional methods and other deep learning-based backbones.","2169-3536","","10.1109/ACCESS.2023.3332488","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10316294","Lettuce;enzymatic browning;transformer;quadratic;siamese model;reptile","Transformers;Neurons;Task analysis;Feature extraction;Computational modeling;Training;Visualization;Crops;Agricultural products;Predictive models;Product delivery","","2","","72","CCBY","13 Nov 2023","","","IEEE","IEEE Journals"
"Next Generation Auto-Identification and Traceability Technologies for Industry 5.0: A Methodology and Practical Use Case for the Shipbuilding Industry","P. Fraga-Lamas; J. Varela-Barbeito; T. M. Fernández-Caramés","Department of Computer Engineering, Centro de Investigación CITIC, Universidade da Coruña, A Coruña, Spain; Navantia S. A., Ferrol, Spain; Department of Computer Engineering, Centro de Investigación CITIC, Universidade da Coruña, A Coruña, Spain",IEEE Access,"20 Oct 2021","2021","9","","140700","140730","Industry 5.0 follows the steps of the Industry 4.0 paradigm and seeks for revolutionizing the way industries operate. In fact, Industry 5.0 focuses on research and innovation to support industrial production sustainability and place the well-being of industrial workers at the center of the production process. Thus, Industry 5.0 relies on three pillars: it is human-centric, it encourages sustainability and it is aimed at developing resilience against disruptions. Such core aspects cannot be fully achieved without a transparent end-to-end human-centered traceability throughout the value chain. As a consequence, Auto-Identification (Auto-ID) technologies play a key role, since they are able to provide automated item recognition, positioning and tracking without human intervention or in cooperation with industrial operators. Although the most popular Auto-ID technologies provide a certain degree of security and productivity, there are still open challenges for future Industry 5.0 factories. This article analyzes and evaluates the Auto-ID landscape and delivers a holistic perspective and understanding of the most popular and the latest technologies, looking for solutions that cope with harsh, diverse and complex industrial scenarios. In addition, it describes a methodology for selecting Auto-ID technologies for Industry 5.0 factories. Such a methodology is applied to a specific use case of the shipbuilding industry that requires identifying the main components of a ship during its construction and repair. To validate the outcomes of the methodology, a practical evaluation of passive and active UHF RFID tags was performed in an Offshore Patrol Vessel (OPV) under construction, showing that a careful selection and evaluation of the tags enables product identification and tracking even in areas with a very high density of metallic objects. As a result, this article serves as a useful guide for industrial stakeholders, including future developers and managers that seek for deploying identification and traceability technologies in Industry 5.0 scenarios.","2169-3536","","10.1109/ACCESS.2021.3119775","Auto-Identification for Intelligent Products Research Line of the Navantia-Universidade da Coruña Joint Research Unit(grant numbers:IN853B-2018/02); Centro de Investigación de Galicia ‘‘CITIC,’’ funded by Xunta de Galicia and the European Union (European Regional Development Fund-Galicia 2014–2020 Program)(grant numbers:ED431G 2019/01); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9568924","Auto-ID;traceability;Industry 5.0;Industry 4.0;shipbuilding;shipyard;UHF RFID","Industries;Wireless communication;Marine vehicles;Shipbuilding industry;Production facilities;Radiofrequency identification;Industrial Internet of Things","","50","","184","CCBY","13 Oct 2021","","","IEEE","IEEE Journals"
"Quaternion Factorization Machines: A Lightweight Solution to Intricate Feature Interaction Modeling","T. Chen; H. Yin; X. Zhang; Z. Huang; Y. Wang; M. Wang","School of Information Technology and Electrical Engineering, The University of Queensland, Brisbane, QLD, Australia; School of Information Technology and Electrical Engineering, The University of Queensland, Brisbane, QLD, Australia; College of Engineering, University of Notre Dame, Notre Dame, IN, USA; School of Information Technology and Electrical Engineering, The University of Queensland, Brisbane, QLD, Australia; Key Laboratory of Knowledge Engineering with Big Data, Ministry of Education and School of Computer Science and Information Engineering, Hefei University of Technology, Hefei, China; Key Laboratory of Knowledge Engineering with Big Data, Ministry of Education and School of Computer Science and Information Engineering, Hefei University of Technology, Hefei, China",IEEE Transactions on Neural Networks and Learning Systems,"4 Aug 2023","2023","34","8","4345","4358","Due to the sparsity of available features in web-scale predictive analytics, combinatorial features become a crucial means for deriving accurate predictions. As a well-established approach, a factorization machine (FM) is capable of automatically learning high-order interactions among features to make predictions without the need for manual feature engineering. With the prominent development of deep neural networks (DNNs), there is a recent and ongoing trend of enhancing the expressiveness of FM-based models with DNNs. However, though better results are obtained with DNN-based FM variants, such performance gain is paid off by an enormous amount (usually millions) of excessive model parameters on top of the plain FM. Consequently, the heavy parameterization impedes the real-life practicality of those deep models, especially efficient deployment on resource-constrained Internet of Things (IoT) and edge devices. In this article, we move beyond the traditional real space where most deep FM-based models are defined and seek solutions from quaternion representations within the hypercomplex space. Specifically, we propose the quaternion factorization machine (QFM) and quaternion neural factorization machine (QNFM), which are two novel lightweight and memory-efficient quaternion-valued models for sparse predictive analytics. By introducing a brand new take on FM-based models with the notion of quaternion algebra, our models not only enable expressive inter-component feature interactions but also significantly reduce the parameter size due to lower degrees of freedom in the hypercomplex Hamilton product compared with real-valued matrix multiplication. Extensive experimental results on three large-scale datasets demonstrate that QFM achieves 4.36% performance improvement over the plain FM without introducing any extra parameters, while QNFM outperforms all baselines with up to two magnitudes’ parameter size reduction in comparison to state-of-the-art peer methods.","2162-2388","","10.1109/TNNLS.2021.3118706","Australian Research Council(grant numbers:DP190101985,FT210100624); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9580543","Factorization machines (FMs);predictive analytics;quaternion representations","Quaternions;Frequency modulation;Predictive models;Predictive analytics;Computational modeling;Task analysis;Internet of Things","","3","","61","IEEE","19 Oct 2021","","","IEEE","IEEE Journals"
"A Flexible NTT-Based Multiplier for Post-Quantum Cryptography","K. Koleci; P. Mazzetti; M. Martina; G. Masera","Department of Electronics and Telecommunications, Politecnico di Torino, Torino, Italy; Department of Electronics and Telecommunications, Politecnico di Torino, Torino, Italy; Department of Electronics and Telecommunications, Politecnico di Torino, Torino, Italy; Department of Electronics and Telecommunications, Politecnico di Torino, Torino, Italy",IEEE Access,"12 Jan 2023","2023","11","","3338","3351","In this work an NTT-based (Number Theoretic Transform) multiplier for code-based Post-Quantum Cryptography (PQC) is presented, supporting Quasi Cyclic Low/Moderate-Density Parity-Check (QC LDPC/MDPC) codes. The cyclic matrix product, which is the fundamental operation required in this application, is treated as a polynomial product and adapted to the specific case of QC-MDPC codes proposed for Round 3 and 4 in the National Institute of Standards and Technology (NIST) competition for PQC. The multiplier is a fundamental component in both encryption and decryption, and the proposed solution leads to a flexible NTT-based multiplier, which can efficiently handle all types of required products, where the vectors have a length ≈104 and can be moderately sparse. The proposed architecture is implemented using both Field Programmable Gate Array (FPGA) and Application Specific Integrated Circuit (ASIC) technologies and, when compared with the best published results, it features a 10 times reduction of the encryption times with the area increased by 3 times. The proposed multiplier, incorporated in the encryption and decryption stages of a code-based PQC cryptosystem, leads to an improvement over the best published results between 3 to 10 times in terms of  $LC$  product (LUT times latency).","2169-3536","","10.1109/ACCESS.2023.3234816","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10007837","Number theoretic transform;accelerator;convolution;polynomial product;applied cryptography;post-quantum cryptography;QC-MDPC codes;hardware design;ASIC;FPGA","Encryption;Decoding;Cryptography;Sparse matrices;Quantum computing;NIST;Computer security;Convolution;Field programmable gate arrays;Quantum computing;Accelerators","","2","","30","CCBY","5 Jan 2023","","","IEEE","IEEE Journals"
"Frost Monitoring Cyber–Physical System: A Survey on Prediction and Active Protection Methods","I. Zhou; J. Lipman; M. Abolhasan; N. Shariati; D. W. Lamb","School of Electrical and Data Engineering, University of Technology Sydney, Ultimo, Australia; School of Electrical and Data Engineering, University of Technology Sydney, Ultimo, Australia; School of Electrical and Data Engineering, University of Technology Sydney, Ultimo, Australia; School of Electrical and Data Engineering, University of Technology Sydney, Ultimo, Australia; School of Science and Technology, University of New England, Armidale, Australia",IEEE Internet of Things Journal,"10 Jul 2020","2020","7","7","6514","6527","Frost damage in broadacre cropping and horticulture (including viticulture) results in substantial economic losses to producers and may also disrupt associated product value chains. Frost risk windows are changing in timing, frequency, and duration. Faced with the increasing cost of mitigation infrastructure and competition for resources (e.g., water and energy), multiperil insurance, and the need for supply chain certainty, producers are under pressure to innovate in order to manage and mitigate risk. Frost protection systems are cyber-physical systems (CPSs) consisting of sensors (event detection), intelligence (prediction), and actuators (active protection methods). The Internet-of-Things communication protocols joining the CPS components are also evaluated. In this context, this article introduces and reviews existing methods of frost management. This article focuses on active protection methods because of their potential for real-time deployment during frost events. For integrated frost prediction and active protection systems, prediction method, sensor types, and integration architecture are assessed, research gaps are identified and future research directions proposed.","2327-4662","","10.1109/JIOT.2020.2972936","Food Agility CRC 581 Ltd., through the Commonwealth Government CRC Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8993828","Cyber???physical systems (CPSs);frost prediction;frost protection;machine learning","Machine learning;Agriculture;Intelligent sensors;Actuators;Protocols;Internet of Things","","18","","93","IEEE","11 Feb 2020","","","IEEE","IEEE Journals"
"Compressing by Learning in a Low-Rank and Sparse Decomposition Form","K. Guo; X. Xie; X. Xu; X. Xing","School of Electronic and Information Engineering, South China University of Technology, Guangzhou, China; School of Electronic and Information Engineering, South China University of Technology, Guangzhou, China; School of Electronic and Information Engineering, South China University of Technology, Guangzhou, China; School of Electronic and Information Engineering, South China University of Technology, Guangzhou, China",IEEE Access,"24 Oct 2019","2019","7","","150823","150832","Low-rankness and sparsity are often used to guide the compression of convolutional neural networks (CNNs) separately. Since they capture global and local structure of a matrix respectively, we combine these two complementary properties together to pursue better network compression performance. Most existing low-rank or sparse compression methods compress the networks by approximating pre-trained models. However, the optimal solutions to pre-trained models may not be optimal to compressed networks with low-rank or sparse constraints. In this paper, we propose a low-rank and sparse learning framework that trains the compressed network from scratch. Our compressing process can be described as the following three stages. (a) In the structure designing stage, we decompose a weight matrix into sum of low-rank matrix and sparse matrix, and then the low-rank matrix is further factorized into product of two small matrices. (b) In training stage, we add ℓ1 regularization to the loss function to force the sparse matrix to be sparse. (c) In the post-processing stage, we remove the unimportant connection of sparse matrix according to its energy distribution. The pruning process in the post-processing stage reserves most of capacity of the network and keeps the performance of the network to a great extent. The performance can be further improved with fine-tuning, along with sparse masked convolution. Experiments on several common datasets demonstrate our model is superior to other network compression methods based on low-rankness or sparsity. On CIFAR-10, our method compresses VGGNet-19 to 3.14% and PreActResNet-56 to 29.78% without accuracy drop. 62.43% of parameters of ResNet-50 are reduced with 0.55% top-5 accuracy loss on ImageNet.","2169-3536","","10.1109/ACCESS.2019.2947846","National Natural Science Foundation of China(grant numbers:U1801262,U1636218,61702192,61802131); China Postdoctoral Science Foundation(grant numbers:2018M630944); National Natural Science Foundation of China(grant numbers:2018A030313474); Northwestern Polytechnical University(grant numbers:2018MS79,2019PY21,2019MS028); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8871134","Convolutional neural networks;low-rank;sparse;network compression","Sparse matrices;Matrix decomposition;Training;Convolution;Image coding;Periodic structures;Network architecture","","6","","39","CCBY","16 Oct 2019","","","IEEE","IEEE Journals"
"TCP-ARMA: A Tensor-Variate Time Series Forecasting Method","Y. An; D. Wang; L. Chen; X. Zhang","Department of Industrial Engineering and Management, Peking University, Beijing, China; Department of Industrial Engineering and Management, School of Mechanical Engineering, Shanghai Jiao Tong University, Shanghai, China; Ant Group, Beijing, China; Department of Industrial Engineering and Management, Peking University, Beijing, China",IEEE Transactions on Automation Science and Engineering,"8 Aug 2024","2024","21","3","2251","2263","Analysis of complex data structures in the form of matrix or tensor format data has gained immense popularity in diverse fields. However, forecasting time series based on high-order historical tensor data presents significant challenges due to the huge number of parameters derived by the high-dimensional nature of these data. Traditional time series models, designed for scalar or vector data, are insufficient for handling such data, necessitating the development of novel techniques to tackle these challenges. To address this issue, we propose a Tensor-variate method with Compressed Parameters in Auto-Regressive Moving Average (TCP-ARMA) model for time series forecasting, which integrates a smoothed mean and a tensor-variate autoregressive moving average (ARMA) model with a parameter reduction technique. The proposed method captures the global trend within each dimension of tensors as well as the time-dimension by a tensor-based smoothed mean. The high-order parameters, commonly with tremendous elements, are compressed into a series of factor matrices, significantly reducing computational difficulty and complexity. To solve the optimization problem efficiently and avoid the computational challenge of inverting large matrices, we have designed an algorithm named BCD-PALM that combines block coordinate descent (BCD) with proximal alternating linearized minimization (PALM). We have employed a real-world case study to validate our proposed approach, and the results demonstrate its effectiveness in addressing the challenges associated with high-dimensional tensor data. Note to Practitioners—In response to the challenges associated with capturing the evolution within high-order tensor time series data, we develop a tensor-variate time series forecasting method that incorporates a smoothed mean and a tensor-variate autoregressive moving average (ARMA) model with parameter reduction. To effectively implement this method, there are three key considerations to bear in mind. Firstly, it is crucial to ensure that sufficient historical data is available for the model training process to be completed successfully. Secondly, while we have chosen the B-spline as the smoothing method for capturing the smoothed mean, it is only one among various smoothing methods available. Depending on the specific context or scenario, alternative smoothing techniques may be more suitable. Lastly, it is essential to carefully determine the CP rank in the decomposition process, taking into account the actual compression requirements of the data being analyzed. By considering these factors, our proposed method can be tailored and optimized to address the unique challenges posed by high-order tensor time series data.","1558-3783","","10.1109/TASE.2023.3322298","National Science Foundation of China(grant numbers:72271009,71932006); High-Performance Computing Platform of Peking University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10305544","ARMA;mean smoothing;tensor-variate model;tensor decomposition;PALM algorithm","Tensors;Time series analysis;Optimization;Forecasting;Autoregressive processes;Computational efficiency;Smoothing methods","","","","38","IEEE","2 Nov 2023","","","IEEE","IEEE Journals"
"Cloud Manufacturing Architecture Based on Public Blockchain Technology","B. Kaynak; S. Kaynak; Ö. Uygun","Computer Research and Application Center, Sakarya University, Sakarya, Turkey; Department of Computer Engineering, Sakarya University, Sakarya, Turkey; Department of Industrial Engineering, Sakarya University, Sakarya, Turkey",IEEE Access,"7 Jan 2020","2020","8","","2163","2177","With Industry 4.0, IT infrastructure has started to be used more effectively in the manufacturing sector. Cyber physical systems, IoT, cloud manufacturing, big data are some of the technologies that make up the concept of Industry 4.0. These technologies have solved many problems in the manufacturing sector. One of these technologies, cloud manufacturing technology, has emerged with the idea of pay as you go. This technology has enabled manufacturing resources to be leased and shared on a global scale. However, it has problems arising from its central structure and the need for a reliable 3rd party. Reliability, security, continuity, scalability, data lock-in, single point failure, data manipulation are some of the main problems. Blockchain (BC) is a decentralized and distributed technology. The data stored on the BC network cannot be altered in any way. With these features, we believe that BC-supported cloud manufacturing systems can overcome the aforementioned problems and eliminates the need for a reliable 3rd party. Based on this belief, in this study the agreements and communication between the resource provider and the customer, which is one of the basic functions of cloud manufacturing platforms, are realized with a decentralized application using BC-based smart contracts (SCs). The designed application is called the decentralized cloud manufacturing application (DCMApp). DCMApp does not operate on a fully public BC network, it has a hybrid structure and uses the Ethereum network as a public BC network. These features make DCMApp different from other BC-based cloud manufacturing applications. DCMApp's hybrid structure has enabled more transparent, economic and safe manufacturing agreements. It is also possible to store agreements on the BC network at a low cost without installing any server infrastructure. The use of Ethereum network makes it almost impossible to manipulate agreements.","2169-3536","","10.1109/ACCESS.2019.2962232","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8943230","Blockchain;cloud manufacturing;decentralized manufacturing","Manufacturing;Cloud computing;Bitcoin;Blockchain;Reliability;Biological system modeling;Industries","","27","","38","CCBY","25 Dec 2019","","","IEEE","IEEE Journals"
"Latitude-Redundancy-Aware All-Zero Block Detection for Fast 360-Degree Video Coding","C. Yu; X. Fan; P. Chen; Y. Ni; H. Man; D. Zhao","Department of Computer Science and Technology, Harbin Institute of Technology, Harbin, China; Department of Computer Science and Technology, Harbin Institute of Technology, Harbin, China; Department of Computer Science and Technology, Harbin Institute of Technology, Harbin, China; Department of Computer Science and Technology, Harbin Institute of Technology, Harbin, China; Department of Computer Science and Technology, Harbin Institute of Technology, Harbin, China; Department of Computer Science and Technology, Harbin Institute of Technology, Harbin, China",IEEE Transactions on Image Processing,"28 Oct 2024","2024","33","","6129","6142","The sphere-to-plane projection of 360-degree video introduces substantial stretched redundant data, which is discarded when reprojected to the 3D sphere for display. Consequently, encoding and transmitting such redundant data is unnecessary. Highly redundant blocks can be referred to as all-zero blocks (AZBs). Detecting these AZBs in advance can reduce computational and transmission resource consumption. However, this cannot be achieved by existing AZB detection techniques due to the unawareness of the stretching redundancy. In this paper, we first derive a latitude-adaptive redundancy detection (LARD) approach to adaptively detect coefficients carrying redundancy in transformed blocks by modeling the dependency between valid frequency range and the stretching degree based on spectrum analysis. Utilizing LARD, a latitude-redundancy-aware AZB detection scheme tailored for fast 360-degree video coding (LRAS) is proposed to accelerate the encoding process. LRAS consists of three sequential stages: latitude-adaptive AZB (L-AZB) detection, latitude-adaptive genuine-AZB (LG-AZB) detection and latitude-adaptive pseudo-AZB (LP-AZB) detection. Specifically, L-AZB refers to the AZB introduced by projection. LARD is used to detect L-AZB directly. LG-AZB refers to the AZB after hard-decision quantization and zeroing redundant coefficients. A novel latitude-adaptive sum of absolute difference estimation model is built to derive the threshold for LG-AZB detection. LP-AZB refers to the AZB in terms of rate-distortion optimization considering redundancy. A latitude-adaptive rate-distortion model is established for LP-AZB detection. Experimental results show that LRAS can achieve an average total encoding time reduction of 25.85% and 20.38% under low-delay and random access configurations compared to the original HEVC encoder, with only 0.16% and 0.13% BDBR increases and 0.01dB BDPSNR loss, respectively. The transform and quantization time savings are 60.13% and 59.94% on average.","1941-0042","","10.1109/TIP.2024.3482172","National Key Research and Development Program of China(grant numbers:2021YFF0900500); National Natural Science Foundation of China (NSFC)(grant numbers:U22B2035,62272128); Media Innovation Laboratory, Architecture and Technology Innovation Department, Huawei Cloud; Media Service Product Department, Huawei Cloud; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10729714","360 video coding;fast transform and quantization;latitude adaptive video coding;all-zero block","Quantization (signal);Video coding;Transforms;Image coding;Redundancy;Encoding;Optimization;Three-dimensional displays;Rate-distortion;Prediction algorithms","","","","45","IEEE","22 Oct 2024","","","IEEE","IEEE Journals"
"Anomaly Detection and Classification for PHM of Electronics Subjected to Shock and Vibration","P. Lall; P. Gupta; A. Angral","Department of Mechanical Engineering, NSF Center for Advanced Vehicle and Extreme Environment Electronics, Aubum University, Auburn, AL, USA; Department of Mechanical Engineering, NSF Center for Advanced Vehicle and Extreme Environment Electronics, Aubum University, Auburn, AL, USA; Department of Mechanical Engineering, NSF Center for Advanced Vehicle and Extreme Environment Electronics, Aubum University, Auburn, AL, USA","IEEE Transactions on Components, Packaging and Manufacturing Technology","10 Nov 2012","2012","2","11","1902","1918","Failures in electronics subjected to shock and vibration are typically diagnosed using the built-in self test (BIST) or using continuity monitoring of daisy-chained packages. The BIST, which is extensively used for diagnostics or identification of failure, is focused on reactive failure detection and provides limited insight into reliability and residual life. In this paper, a new technique has been developed for health monitoring and failure mode classification based on measured damage precursors. A feature extraction technique in the joint-time-frequency analysis (JTFA) domain has been developed along with pattern classifiers for fault diagnosis of electronics at the product level. The Karhunen Loéve transform (KLT) has been used for feature reduction and de-correlation of the feature vectors for fault-mode classification in electronic assemblies. Euclidean, and Mahalanobis, and Bayesian distance classifiers based on JTFA, have been used for classification of the resulting feature space. Previously, the authors have developed damage precursors based on time and spectral techniques for health monitoring of electronics without reliance on continuity data from daisy-chained packages. Statistical pattern recognition techniques based on wavelet packet energy decomposition have been studied by authors for quantification of shock damage in electronic assemblies and auto-regressive moving average; time-frequency techniques have been investigated for system identification, condition monitoring, and fault detection and diagnosis in electronic systems. However, identification of specific failure modes is not possible. In this paper, various fault modes, such as solder interconnect failure, interconnect missing, chip delamination, chip cracking etc., in various packaging architectures have been classified using clustering of feature vectors based on the KLT approach. The KLT de-correlates the feature space and identifies dominant directions to describe the space, eliminating directions that encode little useful information about the features. The clustered damage precursors have been correlated with underlying damage. Several chip-scale packages have been studied with lead-free second-level interconnects, including SAC105, SAC305 alloys. Transient strain has been measured during the drop event using digital image correlation and high-speed cameras operating at 100 000 frames/s. Continuity has been monitored simultaneously for failure identification. Fault-mode classification has been done using KLT and JTFA analysis of the experimental data. In addition, explicit finite element models have been developed, and various kinds of failure modes have been simulated, such as solder ball cracking, trace fracture, package falloff, and solder ball failure. Models using cohesive elements present at the solder joint-copper pad interface at both the printed circuit board and package side have also been created to study the traction-separation behavior of solder. Fault modes predicted by simulation-based precursors have been correlated with those from experimental data.","2156-3985","","10.1109/TCPMT.2012.2207460","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6303968","Electronic assemblies;failure mode classification;health management;leadfree;prognostics;reliability;solder joints","Time frequency analysis;Vehicles;Monitoring;Electric shock;Built-in self-test;Circuit faults;Strain","","22","","47","IEEE","14 Sep 2012","","","IEEE","IEEE Journals"
"Blockchain in the Electronics Industry for Supply Chain Management: A Survey","S. Jadon; A. Rao; N. Jagadish; S. Nadakatti; T. R.; P. B. Honnavalli","Department of Computer Science and Engineering, PES University, Bengaluru, India; Department of Computer Science and Engineering, PES University, Bengaluru, India; Department of Computer Science and Engineering, PES University, Bengaluru, India; Department of Computer Science and Engineering, PES University, Bengaluru, India; Department of Computer Science and Engineering, PES University, Bengaluru, India; Department of Computer Science and Engineering, PES University, Bengaluru, India",IEEE Access,"17 Jan 2024","2024","12","","7089","7120","Supply chain as an industry has gone through four-fold changes in the last century. Born as a bare-bones structure in 1.0 it grew to incorporate some form of record preservation in 2.0 and then integrated communication between two entities in 3.0. Supply chain 4.0, the current one, has total global integration of multiple entities with the records digitised. But increasing entities and pipelines, means increasing complexities, overhead and soft spots. In this paper, a systematic literature review is done with the objective of analysing existing Supply Chain 4.0. The focus of the paper is the usage of blockchain technology in the electronic industry to provide a decentralised architecture. Several papers were compared on the basis of different schemas like the type of blockchain network used, platform deployed on, security of frameworks, representation of unique identity, testing authenticity, working implementation, cost of implementation, etc. The pros and cons of various privacy and security methodologies are also explored and discussed. The paper also discusses the open issues and challenges in the same area of interest. Finally, the paper outlines the future scope to be delved into as a part of the future research.","2169-3536","","10.1109/ACCESS.2024.3351370","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10384393","Supply chain;blockchain;security;smart contracts;electronic chips","Supply chains;Blockchains;Surveys;Industries;Supply chain management;Security;Electronics industry;Smart contracts","","2","","68","CCBYNCND","8 Jan 2024","","","IEEE","IEEE Journals"
"An IIoT Based ICS to Improve Safety Through Fast and Accurate Hazard Detection and Differentiation","A. Moradbeikie; K. Jamshidi; A. Bohlooli; J. Garcia; X. Masip-Bruin","Faculty of Computer Engineering, University of Isfahan, Isfahan, Iran; Faculty of Computer Engineering, University of Isfahan, Isfahan, Iran; Faculty of Computer Engineering, University of Isfahan, Isfahan, Iran; Advanced Network Architectures Lab (CRAAX), UPC BarcelonaTech, Vilanova i la Geltrú, Spain; Advanced Network Architectures Lab (CRAAX), UPC BarcelonaTech, Vilanova i la Geltrú, Spain",IEEE Access,"23 Nov 2020","2020","8","","206942","206957","Safety and security of Industrial Control Systems (ICS) applied in many critical infrastructures is essential. In these systems, hazards can be due either to system failure or cyber-attacks factors. Accurate hazard detection and reducing reconfiguration time after hazard is one of the most important objectives in these systems. One of the procedures that can reduce the reconfiguration time is determining the cause of hazards and, based on the aforementioned factors, adopting the best commands in reconfiguration time. However, it is difficult to differentiate between different types of hazard because their effects on the system can be similar. With the advent of IoT into ICS, known as IIoT, it has become possible to differentiate the hazards through the adoption of data from different IIoT sensors in the environment. In this article, we propose a risk management approach that identifies hazards based on the physical nature of these systems with the support from the IIoT. The identified hazards fall into four categories: stealthy attack, random attack, transient failure, and permanent failure. Then, the reconfiguration process is run based on the proposed differentiation, which provides a better performance and reconfiguration time. In the experimental section, a fluid storage system is simulated, showing 97% correct differentiation of hazards and reducing in 60% the lost time in the system recovery reconfiguration.","2169-3536","","10.1109/ACCESS.2020.3037093","Spanish Ministry of Economy and Competitiveness and by the European Regional Development Fund(grant numbers:RTI2018-094532-B-I00 (MINECO/FEDER)); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9253625","Industrial control systems (ICS);IIoT;fault and attack detection;resilient control;system reconfiguration","Hazards;Sensors;Integrated circuits;Sensor systems;Security;Transient analysis;Risk management","","13","","41","CCBY","10 Nov 2020","","","IEEE","IEEE Journals"
"Design Space Exploration for Chiplet-Assembly-Based Processors","S. Pal; D. Petrisko; R. Kumar; P. Gupta","Department of Electrical and Computer Engineering, University of California at Los Angeles, Los Angeles, USA; Department of Electrical and Computer Engineering, University of Illinois at Urbana–Champaign, Champaign, USA; Department of Electrical and Computer Engineering, University of Illinois at Urbana–Champaign, Champaign, USA; Department of Electrical and Computer Engineering, University of California at Los Angeles, Los Angeles, USA",IEEE Transactions on Very Large Scale Integration (VLSI) Systems,"20 Mar 2020","2020","28","4","1062","1073","Recent advancements in 2.5-D integration technologies have made chiplet assembly a viable system design approach. Chiplet assembly is emerging as a new paradigm for heterogeneous design at lower cost, design effort, and turnaround time and enables low-cost customization of hardware. However, the success of this approach depends on identifying a minimum chiplet set which delivers these benefits. We develop the first microarchitectural design space exploration framework for chiplet assembly-based processors which enables us to identify the minimum set of chiplets to design and manufacture. Since chiplet assembly makes heterogeneous technology and cost-effective application-dependent customization possible, we show the benefits of using multiple systems built from multiple chiplets to service diverse workloads (up to 35% improvement in energy-delay product over a single best system) and advantages of chiplet assembly approaches over system-on-chip (SoC) methodology in terms of total cost (up to 72% improvement in cost) while satisfying the energy and performance constraints of individual applications.","1557-9999","","10.1109/TVLSI.2020.2968904","Defense Advanced Research Projects Agency(grant numbers:N00014-16-1-263); Office of the President, University of California(grant numbers:MRP-17-454999); GuruKrupa Fellowship; UCLA CHIPS Consortium; Center for Design Enabled Nanofabrication; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8998304","2.5-D integration;chiplet assembly;micro-architectural design space exploration (DSE);multichiplet optimization","Program processors;Measurement;Multicore processing;Microarchitecture;Optimization;Benchmark testing;Space exploration","","20","","51","IEEE","13 Feb 2020","","","IEEE","IEEE Journals"
"Nano Magnetic STT-Logic Partitioning for Optimum Performance","J. Das; S. M. Alam; S. Bhanja","Department of Electrical Engineering, University of South Florida, Tampa, FL, USA; Everspin Technologies Inc, Austin, TX, USA; Department of Electrical Engineering, University of South Florida, Tampa, FL, USA",IEEE Transactions on Very Large Scale Integration (VLSI) Systems,"20 Dec 2013","2014","22","1","90","98","Magnetoresistive RAMs (MRAMs) are the new generation of nonvolatile memories that use magnetic tunnel junctions (MTJs) to store bit information. Horizontal (bit and source) and vertical (word) lines partition the MRAM into a 2-D grid similar to a conventional memory. This paper relies on a logic-in-memory architecture where MRAM cells are placed in close proximity so that they can behave both as logic elements and as memory bits. When the clock signal is active the cells compute logic, while at other times the cells store the data in them and behave as memory. Using these MRAM cells, in this paper, we have designed two fundamental components in datapath and logic circuits, the XOR and majority. By transferring logic responsibilities between the metal lines, CMOS peripherals and the MTJs, we have achieved a significant reduction in MTJ cell count, energy, and delay over previous designs. For example, an energy savings of more than 75% and a cell reduction of more than 81.25% are obtained for a 2-input XOR in standalone mode of operation. Though this hybrid sharing of responsibilities between the MTJs and CMOS has apparently increased the overhead on CMOS, it has however reduced the net power consumption in the CMOS peripherals. This happens because the CMOS now has a fewer number of cells to control. The reduction in the CMOS power varies from close to 50% for a 2-input XOR to greater than 10% for a majority. In addition, the designs also obey the rules of hierarchical modeling which helped us to use the novel 2-input XORs as bricks for designing the novel 3-input XOR. Again a 3-input XOR and majority are used to custom develop a one-bit full adder. Together with an inter-cell spacing of 20 nm and low power spin transfer torque current-driven write and clock operations, the novel designs presented in this paper has the potential to target the low energy and high density logic-in-memory applications.","1557-9999","","10.1109/TVLSI.2012.2236690","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6531668","Energy-delay product (EDP);high density logic;logic-in-memory;low energy;magnetic tunnel junction (MTJ);nanomagnetic;spintronic","Magnetic tunneling;Computer architecture;Metals;Clocks;Magnetization;Magnetic domain walls;Magnetic domains","","7","1","29","IEEE","13 Jun 2013","","","IEEE","IEEE Journals"
"Intelligent Reflecting Surface Aided MIMO Networks: Distributed or Centralized Architecture ?","G. Chen; Q. Wu; W. Chen; Y. Hou; M. Jian; S. Zhang; J. Li","School of Electronic and Optical Engineering, Nanjing University of Science and Technology, Nanjing, China; Department of Electronic Engineering, Shanghai Jiao Tong University, Shanghai, China; Department of Electronic Engineering, Shanghai Jiao Tong University, Shanghai, China; National Engineering Research Center for Mobile Network Technologies, Beijing University of Posts and Telecommunications, Beijing, China; Algorithm Department, Wireless Product Research and Development Institute, ZTE Corporation, Shenzhen, China; Shanghai Institute for Advanced Communication and Data Science, Key Laboratory of Specialty Fiber Optics and Optical Access Networks, Shanghai University, Shanghai, China; School of Information Science and Engineering, Southeast University, Nanjing, China",IEEE Transactions on Wireless Communications,"11 Dec 2024","2024","23","12","18969","18986","Intelligent reflecting surfaces (IRSs) have recently attained growing popularity in wireless networks owning to their capability to customize the wireless channel via smartly configured passive reflections. In addition to optimizing IRS reflection patterns, the flexible deployment of IRSs offers another design degree of freedom (DoF) to reconfigure the wireless propagation environment in favour of signal transmission. To unveil the impact of IRS deployment on the system capacity, we investigate the capacity of a broadcast channel with a multi-antenna base station (BS) sending independent messages to multiple users, aided by IRSs with N elements. In particular, both the distributed and centralized IRS deployment architectures are considered. Regarding the distributed IRS, the N IRS elements form multiple IRSs and each of them is installed near a user cluster; while for the centralized IRS, all IRS elements are located in the vicinity of the BS. To draw essential insights, we first derive the maximum capacity achieved by the distributed IRS and centralized IRS, respectively, under the assumption of line-of-sight (LoS) propagation and homogeneous channel setups. By carefully capturing the fundamental tradeoff between the spatial multiplexing gain and passive beamforming gain, we rigourously prove that the capacity of the distributed IRS is higher than that of the centralized IRS provided that the total number of IRS elements is above a threshold. Motivated by the superiority of the distributed IRS, we then focus on the transmission and element allocation design under the distributed IRS. By exploiting the user channel correlation of intra-clusters and inter-clusters, an efficient hybrid multiple access scheme relying on both spatial and time domains is proposed to fully exploit both the passive beamforming gain and spatial DoF. Moreover, the IRS element allocation problem is investigated for the objectives of the sum-rate maximization and the minimum user rate maximization, respectively. Finally, extensive numerical results are provided to validate our theoretical finding and also to unveil the effectiveness of the distributed IRS for improving the system capacity under various system setups.","1558-2248","","10.1109/TWC.2024.3471825","Natural Science Foundation of Jiangsu Province(grant numbers:BK20241455); National Key Research and Development Program of China(grant numbers:2023YFB2905000); National Natural Science Foundation of China(grant numbers:62371289,62331022); ZTE Industry-University-Institute Cooperation Funds(grant numbers:IA20240420003); Science and Technology Planning Project of Guangdong Province(grant numbers:2022A0505050011); National Key Project(grant numbers:2020YFB1807700); National Natural Science Foundation of China(grant numbers:62071296); Shanghai Kewei(grant numbers:22JC1404000); Key Technologies Research and Development Program of Jiangsu(grant numbers:BE2023022,BE2023022-2); National Natural Science Foundation of China (NSFC)(grant numbers:62471204); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10738264","Intelligent reflecting surface;broadcast channel;IRS deployment;capacity","Array signal processing;Wireless networks;Resource management;Wireless sensor networks;Space division multiplexing;Rician channels;Research and development;6G mobile communication;Signal to noise ratio;Optical fibers","","","","47","IEEE","29 Oct 2024","","","IEEE","IEEE Journals"
"Computational Failure Analysis of In-Memory RRAM Architecture for Pattern Classification CNN Circuits","N. L. Prabhu; N. Raghavan","Engineering Product Development (EPD) Pillar, Singapore University of Technology and Design, Singapore; Engineering Product Development (EPD) Pillar, Singapore University of Technology and Design, Singapore",IEEE Access,"30 Dec 2021","2021","9","","168093","168106","Power-efficient data processing subsystems performing millions of complex concurrent arithmetic operations per second form part of today’s essential solution required to meet the growing demand of edge computing applications, given the volume of data collected by real-time Internet-Of-Things (IoT) sensors. Adding to it, the in-memory computation designed as memory and processing elements on a single wafer has enabled promising performance improvement in terms of computational power savings by avoiding the memory wall created while accessing the memory array. The Resistive RAM (RRAM), with its simple metal-insulator-metal (MIM) structure, proves to be a very appealing candidate for in-memory computation given its ultralow switching power and its Complementary Metal Oxide Semiconductor (CMOS) process fabrication compatibility. However, despite all advantages, the resistive switching (RS) phenomenon in RRAM has an inherent stochastic variability. On the algorithmic side, convolution neural networks (CNN) have gained popularity in image classification applications, and the network’s architecture is memory-intense in nature for memorizing the trained weights. Hence, an RRAM-based CNN system will pave way for a power-efficient image classification system on the edge. Accounting however for the inherent variability in RRAM (inter-device and intra-device), the accuracy of CNN’s prediction is surely expected to drop. This motivates us to quantify the impact of RRAM variability on the CNN trained weights and classification accuracy (prediction loss). In this study, we have constructed a Look-Up-Table (LUT) based model for encoding wide current compliance ( $2~\mu \text{A}$  to  $250~\mu \text{A}$ ) 65nm CMOS 1T1R OxRAM’s (TiN/HfO2/Hf/TiN) resistive variability into CNN’s trained weight in a digital regime. The RRAM resistance encoded trained weights are in turn used here to simulate the two extreme CNN architectures, namely, Fully Serial System (FSS) and Fully Parallel System (FPS). The architectures’ prediction variability trends are quantified given its current compliance, RRAM resistive variability, CNN’s convolution matrix sizes ( $5\times 5$ ,  $3\times 3$ ,  $1\times 1$ , and  $1\times 1$  max pool), the total number of layers in the CNN as well as the input image pixel size.","2169-3536","","10.1109/ACCESS.2021.3136193","Agency for Science, Technology and Research (A*STAR) Brain Efficient Nanomechanical Artificial Intelligence Computing (BRENAIC) Programmatic Research(grant numbers:A18A5b0056); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9654206","Resistive RAM;convolution neural network;look-up-table;in-memory computation;image classification;Internet of Things;complementary metal oxide semiconductor","Random access memory;Convolutional neural networks;Computer architecture;Switches;Real-time systems;Predictive models;Metals","","3","","39","CCBY","16 Dec 2021","","","IEEE","IEEE Journals"
"A Universal Single and Double Point Multiplications Architecture for ECDSA Based on Differential Addition Chains","X. He; W. Wang; J. Zhang; Z. Zhang; J. Yang; H. Dang; G. Wang","School of Integrated Circuits and Electronics, Beijing Institute of Technology (BIT), Beijing, China; School of Integrated Circuits and Electronics, Beijing Institute of Technology (BIT), Beijing, China; School of Integrated Circuits and Electronics, Beijing Institute of Technology (BIT), Beijing, China; School of Integrated Circuits and Electronics, Beijing Institute of Technology (BIT), Beijing, China; Hebei Petroleum University of Technology, Hebei, China; School of Integrated Circuits and Electronics, Beijing Institute of Technology (BIT), Beijing, China; School of Integrated Circuits and Electronics, Beijing Institute of Technology (BIT), Beijing, China",IEEE Access,"23 Apr 2024","2024","12","","55434","55447","In the 5G and beyond networks, low-latency digital signatures are essential to ensure the security, integrity, and non-repudiation of massive data in communication processes. The binary finite field-based elliptic curve digital signature algorithm (ECDSA) is particularly suitable for achieving low-latency digital signatures due to its carry-free characteristics. This paper proposes a low-latency and universal architecture for point multiplication (PM) and double point multiplication (DPM) based on the differential addition chain (DAC) designed for signing and verification in ECDSA. By employing the DAC, the area-time product of DPM can be decreased, and throughput efficiency can be increased. Besides, the execution pattern of the proposed architecture is uniform to resist simple power analysis and high-order power analysis. Based on the data dependency, two Karatsuba–Ofman multipliers and four non-pipeline squarers are utilized in the architecture to achieve a compact timing schedule without idle cycles for multipliers during the computation process. Consequently, the calculation latency of DPM is minimized to five clock cycles in each loop. The proposed architecture is implemented on Xilinx Virtex-7, performing DPM in 3.584, 5.656, and  $7.453~\mu s$  with 8135, 13372, and 17898 slices over GF(2163), GF(2233), GF(2283), respectively. In the existing designs that are resistant to high-order analysis, our architecture demonstrates throughput efficiency improvements of 36.7% over GF(2233) and 9.8% over GF(2283), respectively.","2169-3536","","10.1109/ACCESS.2024.3390244","Natural Science Foundation of Chongqing Municipality(grant numbers:cstc2021jcyj-msxmX1090); National Natural Science Foundation of China(grant numbers:62201039); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10504264","Elliptic curve cryptosystems;differential addition chain;point multiplication;double point multiplication;field-programmable gate array","Computer architecture;Elliptic curves;Digital signatures;Low latency communication;Resists;Mathematical models;Galois fields;Field programmable gate arrays","","","","51","CCBYNCND","17 Apr 2024","","","IEEE","IEEE Journals"
"Rapid Flow Behavior Modeling of Thermal Interface Materials Using Deep Neural Networks","S. Baeuerle; M. Gebhardt; J. Barth; R. Mikut; A. Steimert","Institute for Automation and Applied Informatics (IAI), Karlsruhe Institute of Technology (KIT), Eggenstein-Leopoldshafen, Germany; Robert Bosch GmbH, Reutlingen, Germany; Robert Bosch GmbH, Reutlingen, Germany; Institute for Automation and Applied Informatics (IAI), Karlsruhe Institute of Technology (KIT), Eggenstein-Leopoldshafen, Germany; Bosch Center for Artificial Intelligence (BCAI), Robert Bosch GmbH, Renningen, Germany",IEEE Access,"5 Feb 2024","2024","12","","17782","17792","Thermal Interface Materials (TIMs) are widely used in electronic packaging. Increasing power density and limited assembly space pose high demands on thermal management. Large cooling surfaces need to be covered efficiently. When joining the heatsink, previously dispensed TIM spreads over the cooling surface. Recommendations on the dispense pattern exist only for simple surface geometries such as rectangles. For more complex geometries, Computational Fluid Dynamics (CFD) simulations are used in combination with manual experiments. While CFD simulations offer a high accuracy, they involve simulation experts and are rather expensive to set up. We propose a lightweight heuristic to model the spreading behavior of TIM. We further speed up the calculation by training an Artificial Neural Network (ANN) on data from this model. This offers rapid computation times and further supplies gradient information. This ANN can not only be used to aid manual pattern design of TIM, but also enables an automated pattern optimization. We compare this approach against the state-of-the-art and use real product samples for validation.","2169-3536","","10.1109/ACCESS.2024.3359169","Karlsruhe Institute of Technology (KIT)-Publication Fund of KIT; Helmholtz Associations Initiative and Networking Fund through the Helmholtz Artificial Intelligence Cooperation Unit (Helmholtz AI); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10414972","Deep learning;electronics packaging;flow behavior;thermal interface materials;thermal management","Computational modeling;Behavioral sciences;Numerical models;Training;Electronic packaging thermal management;Cooling;Thermal resistance","","","","28","CCBY","26 Jan 2024","","","IEEE","IEEE Journals"
"Real World Object Detection Dataset for Quadcopter Unmanned Aerial Vehicle Detection","M. Ł. Pawełczyk; M. Wojtyra","Institute of Aeronautics and Applied Mechanics, Warsaw University of Technology, Warsaw, Poland; Institute of Aeronautics and Applied Mechanics, Warsaw University of Technology, Warsaw, Poland",IEEE Access,"29 Sep 2020","2020","8","","174394","174409","Recent years have shown a noticeable rise in the number of incidents with drones, related to both civilian and military installations. While drone neutralization techniques have become increasingly effective, detection most often relies on professional equipment, which is too expensive to be used for all critical nodes and applications. Therefore, there is a need for drone detection systems that could work on low performance hardware. Its critical component consists of an object detection system. In this article, we introduce a new object detection dataset, built entirely to train computer vision based object detection machine learning algorithms for a task of binary object detection to enable automated, industrial camera based detection of multiple drone objects using camera feed. The dataset expands existing multiclass image classification and object detection datasets (ImageNet, MS-COCO, PASCAL VOC, anti-UAV) with a diversified dataset of drone images. In order to maximize the effectiveness of the model, real world footage was utilized, transformed into images and hand-labelled to create a custom set of 56821 images and 55539 bounding boxes. Additionally, semi-automated labelling was proposed, tested and proved to be very useful for object detection applications. The dataset was divided into train and test subsets for further processing and used to generate 603 easily deployable Haar Cascades as well as 819 high performing Deep Neural Networks based models. They were used to test different object detection methods to determine the long term feasibility of a large scale drone detection system utilizing machine learning algorithms. The study has shown that Haar Cascade can be used as the Minimum Viable Product model for mediocre performance but fails to scale up effectively for a larger dataset compared to the Deep Neural Network model.","2169-3536","","10.1109/ACCESS.2020.3026192","Warsaw University of Technology funds for Scientific Research; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9205392","Aerospace engineering;aerospace safety;artificial intelligence;computer vision;databases;image processing;unmanned aerial vehicles","Drones;Object detection;Task analysis;Computational modeling;Machine learning;Machine learning algorithms","","62","","62","CCBYNCND","24 Sep 2020","","","IEEE","IEEE Journals"
"Adaptive Protection and Microgrid Control Design for Hailuoto Island","H. Laaksonen; D. Ishchenko; A. Oudalov","ABB Oy, Medium Voltage Products, Vaasa, FINLAND; ABB, US Corporate Research Center, Raleigh, NC, USA; ABB Switzerland, Corporate Research Center, Daetwill, Switzerland",IEEE Transactions on Smart Grid,"17 Apr 2014","2014","5","3","1486","1493","Microgrids can provide various economic and environmental benefits but their implementation poses great technical challenges in control, protection and energy management. One of the most important technical aspects in microgrids is distribution system protection. This paper first demonstrates a need for and then focuses on the design aspects of the adaptive protection system addressing issues such as: selection of alternative setting groups, components and system architecture; system configuration and programmed logic. The system is based on a centralized controller running the real-time analysis of the data received from the field Intelligent Electronic Devices and communicating with them by means of IEC 61850 communications. The adaptive protection and microgrid control system has been developed and currently being installed at Hailuoto island in Finland.","1949-3061","","10.1109/TSG.2013.2287672","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6758374","Adaptive protection;distributed energy resources;distribution grid protection;IEC 61850;islanded operation;microgrid;protection coordination;relay setting groups","Generators;Microgrids;Delay effects;Wind turbines;Switches;Adaptation models","","146","","16","IEEE","6 Mar 2014","","","IEEE","IEEE Journals"
"On the Fly Ellipsometry Imaging for Process Deviation Detection","T. Alcaire; D. Le Cunff; S. Soulan; J. . -H. Tortai","STMicroelectronics, Crolles, France; STMicroelectronics, Crolles, France; CEA-LETI, LTM/CNRS, Grenoble, France; CEA-LETI, LTM/CNRS, Grenoble, France",IEEE Transactions on Semiconductor Manufacturing,"4 Aug 2022","2022","35","3","432","438","Spectroscopic ellipsometry is a very sensitive optical metrology technique commonly used in semiconductor manufacturing lines to accurately measure the thickness and refractive index of different layers present on specific dedicated metrology targets on the wafers. In parallel, optical defectivity techniques are widely implemented in production lines to inspect a significant amount of dies representative of the full wafer and detect physical and patterning defects. A new approach can then simply emerge which is to apply ellipsometry metrology techniques at a full or die wafer scale. This strategy, at the frontier between metrology and defectivity field is expected to bring solutions for certain types of process deviation. In our case, ellipsometry’s optical response was collected on large areas of product wafers to capture specific deviations such as film properties, thickness, and patterning variation. This is an innovative strategy that relies on a model-less approach to detect process drifts, using ellipsometry’s sensitivity to material properties and design architecture variations. In this paper, we will present this approach on three industrial cases.","1558-2345","","10.1109/TSM.2022.3183257","Electronic Component Systems for European Leadership Joint Undertaking Project MADEin4(grant numbers:826589); European Union Horizon 2020 Research and Innovation Program and, Austria, Belgium, France, Germany, Hungary, Ireland, Italy, The Netherlands, Romania, and Sweden; French ANR Program Investissements d’Avenir EQUIPEX(grant numbers:ANR-10-EQPX-33); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796990","Model-less;metrology;defectivity;process control;ellipsometry imaging","Ellipsometry;Optical variables measurement;Wavelength measurement;Semiconductor device measurement;Optical sensors;Semiconductor device modeling;Optical imaging","","3","","6","IEEE","15 Jun 2022","","","IEEE","IEEE Journals"
"Reasons and Responses: A Multimodal Serious Games Evaluation Framework","L. Shoukry; S. Göbel","Technical University of Darmstadt, Darmstadt, Germany; Technical University of Darmstadt, Darmstadt, Germany",IEEE Transactions on Emerging Topics in Computing,"4 Mar 2020","2020","8","1","245","255","Evaluation is an essential part of any software development process as it helps compare intended with actual outcomes and identify possible improvements. To do this, it is important to understand how users interact with the product. As interactions with the interdisciplinary product category of Serious Games can be multifaceted, pure text-logging of gameplay actions is not always sufficient to cover all aspects needed to satisfy researchers' needs, for instance how the user feels or what s/he thinks while carrying out a certain action. For this reason, studies evaluating serious games are increasingly applying multimodal methods in recent years. This makes it important to establish theoretical foundations considering the changing research landscape. This paper presents a theoretical framework for multimodal Serious Games evaluation based on a review of relevant research.","2168-6750","","10.1109/TETC.2017.2737953","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8007225","Serious games;evaluation;game-based learning","Games;Context modeling;Data models;Usability;Technological innovation;Entertainment industry;Inspection","","6","","80","IEEE","10 Aug 2017","","","IEEE","IEEE Journals"
"Switched Tank Converters","S. Jiang; S. Saggini; C. Nan; X. Li; C. Chung; M. Yazdani","Google Inc., Sunnyvale, CA, USA; DPIA - University of Udine, Udine, Italy; Google Inc., Sunnyvale, CA, USA; Google Inc., Sunnyvale, CA, USA; Google Inc., Sunnyvale, CA, USA; Google Inc., Sunnyvale, CA, USA",IEEE Transactions on Power Electronics,"23 Apr 2019","2019","34","6","5048","5062","This paper presents a new class of switched tank converters (abbreviated as STCs) for high-efficiency high-density nonisolated dc–dc applications where large voltage step down (up) ratios are required. Distinguished from switched capacitor converters, the STCs uniquely employ LC resonant tanks to partially replace the flying capacitors for energy transfer. Full soft charging, soft switching, and minimal device voltage stresses are achieved under all operating conditions. The STCs feature very high efficiency, power density, and robustness against component nonidealities over a wide range of operating conditions. Furthermore, thanks to the full resonant operation, multiple STCs can operate in parallel with inherent droop current sharing, offering the best scalability and control simplicity. These attributes make STC a disruptive and robust technology viable for industry's high volume adoption. A novel equivalent DCX building block principle is introduced to simplify the analysis of STC. A 98.9% efficiency STC product evaluation board (4-to-1, 650 W) has been developed and demonstrated for the next-generation of 48-V bus conversion for data center servers.","1941-0107","","10.1109/TPEL.2018.2868447","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453894","DCX;switched tank converters (STCs);switched capacitor converters (SCCs);soft charging;soft switching","Capacitors;Topology;Inductors;Switches;Scalability;Stress;Ceramics","","173","","43","IEEE","2 Sep 2018","","","IEEE","IEEE Journals"
"Mass Customizing Paratransit Services With a Ridesharing Option","D. Y. Mo; Y. Wang; Y. C. E. Lee; M. M. Tseng","Department of Supply Chain and Information Management, Hang Seng Management College, Hong Kong; Department of Supply Chain and Information Management, Hang Seng Management College, Hong Kong; Department of Applied Mathematics, Hong Kong Polytechnic University, Hong Kong; International School of Technology and Management, Feng Chia University, Taichung, Taiwan",IEEE Transactions on Engineering Management,"20 Jan 2020","2020","67","1","234","245","Paratransit services for people with travel difficulties have received increasing government and community attention due to the aging population. In this paper, we examine an integrated service design approach to customize paratransit services with a ridesharing option for a dial-a-ride (DAR) service. The fundamental challenge of DAR services is a lack of commonality across other services in the process, which results in low vehicle utilization. To mass customize paratransit services systematically, we identify the common service components of different paratransit services under the design framework of product family architecture. We then formulate the community organization's pricing and vehicle scheduling decisions with a ridesharing option for a DAR operation as a two-stage decision model. In stage one of the tactical plan, we determine user tolerance of earlier pick-up and later drop-off times, and a price discount for a shared ride. Based on the user tolerance of a longer traveling time, we optimize the vehicle scheduling of shared service orders. Our experimental results indicate that a ridesharing policy option for a DAR service providing a 20% discount for passengers who accept a 15-min earlier pick-up time or a later drop-off time leads to 15% more people being served.","1558-0040","","10.1109/TEM.2018.2873832","Research Grants Council of Hong Kong(grant numbers:UGC/FDS14/E01/15,UGC/FDS14/E06/17); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8510834","Accessible transportation service;decision analysis;mass customization;service design;vehicle routing problem (VRP)","Mass customization;Transportation;Organizations;Optimization;Vehicle routing;Standards organizations;Process design","","5","","31","IEEE","26 Oct 2018","","","IEEE","IEEE Journals"
"Exploiting User Preferences for Multiscenarios in Query-Less Search","Y. Yin; N. Zhang; Z. Chen; M. Li; Y. Li; H. Gao; L. He","Department of Computing, Hangzhou Dianzi University, Hangzhou, China; Alibaba Group, Hangzhou, China; Alibaba Group, Hangzhou, China; Department of Computing, Hangzhou Dianzi University, Hangzhou, China; Department of Computing, Hangzhou Dianzi University, Hangzhou, China; School of Computer Engineering and Science, Shanghai University, Shanghai, China; Alibaba Group, Hangzhou, China",IEEE Transactions on Computational Social Systems,"30 Nov 2022","2022","9","6","1794","1806","Online travel platforms (OTPs), for example, booking.com, Ctrip.com, and Fliggy, deliver travel experiences to online users by providing travel-related products. Hotel recommendation is significantly important for OTPs since hotel bookings account for almost half of the travel expenses and hotel products generate more than half of OTP’s revenues. More than 58% Fliggy users may choose to use query-less hotel searches to find candidate hotels, where no additional keywords are given except the expected check-in date and travel destination city. Thus, how to recommend hotels to traveler users is important and challenging. In this article, we explore the unique characteristics of query-less hotel users and propose a novel multiscenario query-less search network (MSQS). According to their searching date, expected check-in date, current city, and expected hotel city, MSQS groups users’ behaviors (e.g., click, purchase, search) into four scenario groups, namely today-local, today-nonlocal, future-local, and future-nonlocal. The key components of MSQS are the global expert, the scenario expert, and the feedback expert. The global expert learns common features among different scenarios and extracts the feature interactions between context, users, and hotels. The scenario expert utilizes multilayer perception to learn the differentiating features between scenarios. The feedback expert learns users’ preferences for hotels in different scenarios through their historical behaviors, and a scenario interest extractor is carefully designed to enhance attention across scenarios and behaviors. An offline experiment on the Fliggy production dataset with over 8 million users and 0.49 million travel items and an online A/B test both show that MSQS effectively predicts users’ hotel booking intentions.","2329-924X","","10.1109/TCSS.2022.3181271","National Natural Science Foundation of China(grant numbers:U20A20173,61872119); Natural Science Foundation of Zhejiang Province(grant numbers:LY21F020018); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9833811","Attention mechanism;feature interaction;intention prediction;neural networks;online travel planning","Behavioral sciences;Urban areas;Feature extraction;Search problems;Systems architecture;Neural networks;Video on demand","","1","","21","IEEE","20 Jul 2022","","","IEEE","IEEE Journals"
"Security Optimization of Dynamic Networks with Probabilistic Graph Modeling and Linear Programming","H. M. J. Almohri; L. T. Watson; D. Yao; X. Ou","Department of Computer Science, Kuwait University, Kuwait; Departments of Computer Science and Mathematics, Virginia Tech, Blacksburg, VA; Department of Computer Science, Virginia Tech, Blacksburg, VA, 24060; Department of Computing and Information Sciences, Kansas State University, Manhattan, KS",IEEE Transactions on Dependable and Secure Computing,"9 Jul 2016","2016","13","4","474","487","Securing the networks of large organizations is technically challenging due to the complex configurations and constraints. Managing these networks requires rigorous and comprehensive analysis tools. A network administrator needs to identify vulnerable configurations, as well as tools for hardening the networks. Such networks usually have dynamic and fluidic structures, thus one may have incomplete information about the connectivity and availability of hosts. In this paper, we address the problem of statically performing a rigorous assessment of a set of network security defense strategies with the goal of reducing the probability of a successful large-scale attack in a dynamically changing and complex network architecture. We describe a probabilistic graph model and algorithms for analyzing the security of complex networks with the ultimate goal of reducing the probability of successful attacks. Our model naturally utilizes a scalable state-of-the-art optimization technique called sequential linear programming that is extensively applied and studied in various engineering problems. In comparison to related solutions on attack graphs, our probabilistic model provides mechanisms for expressing uncertainties in network configurations, which is not reported elsewhere. We have performed comprehensive experimental validation with real-world network configuration data of a sizable organization.","1941-0018","","10.1109/TDSC.2015.2411264","Kuwait University(grant numbers:[ZQ02/14]); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7056435","Network security;attack graph;probabilistic model;vulnerability analysis;optimization","Security;Computational modeling;Probabilistic logic;Analytical models;Optimization;Communication networks;Mathematical model","","41","","35","OAPA","9 Mar 2015","","","IEEE","IEEE Journals"
"Cybersecurity for Industrial Internet of Things: Architecture, Models and Lessons Learned","G. Bravos; A. J. Cabrera; C. Correa; D. Danilović; N. Evangeliou; G. Ezov; Z. Gajica; D. Jakovetić; L. Kallipolitis; M. Lukić; J. Mascolo; D. Masera; R. Mazo; I. Mezei; A. Miaoudakis; N. Milošević; W. Oliff; J. Robin; M. Smyrlis; G. Sakellari; G. Stamatis; D. Stamenković; S. Škrbić; C. Souveyet; S. Vantolas; G. Vasiliadis; D. Vukobratovic","Information Technology for Market Leadership (ITML), Athens, Athina, Greece; Infineon Technologies AG (IFAG), Neubiberg, Germany; University of Paris 1 Panthéon-Sorbonne (UP1PS), Paris, France; A1, Serbia (VIP), Belgrade, Serbia; Information Technology for Market Leadership (ITML), Athens, Athina, Greece; IBM Research (IBM), Haifa, Israel; A1, Serbia (VIP), Belgrade, Serbia; Faculty of Sciences (UNSPMF), University of Novi Sad, Novi Sad, Serbia; AEGIS IT Research (AEGIS), Braunschweig, Germany; Faculty of Technical Sciences, University of Novi Sad, Novi Sad, Serbia; Centro Ricerche Fiat (CRF), Orbassano, Italy; Centro Ricerche Fiat (CRF), Orbassano, Italy; ENSTA-Bretagne, Brest, France; Faculty of Technical Sciences, University of Novi Sad, Novi Sad, Serbia; Sphynx Technology Solutions AG (STS), Zug, Switzerland; Faculty of Sciences (UNSPMF), University of Novi Sad, Novi Sad, Serbia; School of Computing and Mathematical Sciences, University of Greenwich (UoG), London, U.K; University of Paris 1 Panthéon-Sorbonne (UP1PS), Paris, France; Sphynx Technology Solutions AG (STS), Zug, Switzerland; School of Computing and Mathematical Sciences, University of Greenwich (UoG), London, U.K; Information Technology for Market Leadership (ITML), Athens, Athina, Greece; Faculty of Sciences (UNSPMF), University of Novi Sad, Novi Sad, Serbia; Faculty of Sciences (UNSPMF), University of Novi Sad, Novi Sad, Serbia; University of Paris 1 Panthéon-Sorbonne (UP1PS), Paris, France; AEGIS IT Research (AEGIS), Braunschweig, Germany; Foundation for Research and Technology (FORTH), Heraklion, Greece; Faculty of Technical Sciences, University of Novi Sad, Novi Sad, Serbia",IEEE Access,"2 Dec 2022","2022","10","","124747","124765","Modern industrial systems now, more than ever, require secure and efficient ways of communication. The trend of making connected, smart architectures is beginning to show in various fields of the industry such as manufacturing and logistics. The number of IoT (Internet of Things) devices used in such systems is naturally increasing and industry leaders want to define business processes which are reliable, reproducible, and can be effortlessly monitored. With the rise in number of connected industrial systems, the number of used IoT devices also grows and with that some challenges arise. Cybersecurity in these types of systems is crucial for their wide adoption. Without safety in communication and threat detection and prevention techniques, it can be very difficult to use smart, connected systems in the industry setting. In this paper we describe two real-world examples of such systems while focusing on our architectural choices and lessons learned. We demonstrate our vision for implementing a connected industrial system with secure data flow and threat detection and mitigation strategies on real-world data and IoT devices. While our system is not an off-the-shelf product, our architecture design and results show advantages of using technologies such as Deep Learning for threat detection and Blockchain enhanced communication in industrial IoT systems and how these technologies can be implemented. We demonstrate empirical results of various components of our system and also the performance of our system as-a-whole.","2169-3536","","10.1109/ACCESS.2022.3225074","H2020 Project C4IIoT; European Commission(grant numbers:833828); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9964219","Anomaly detection;blockchain;cybersecurity;deep learning;Internet of Things","Blockchains;Focusing;Market research;Safety;Deep learning;Reliability;Computer security;Internet of Things;Anomaly detection","","4","","48","CCBY","28 Nov 2022","","","IEEE","IEEE Journals"
"Model-Based Research on Deviation in Dynamic Force Sensor Calibration Process","Y. Liu; H. Zhang; Y. H. Jiang; J. Yang","Science and Technology on Metrology and Calibration Laboratory, Changcheng Institute of Metrology and Measurement, Beijing, China; Changcheng Institute of Metrology and Measurement, Beijing, China; Changcheng Institute of Metrology and Measurement, Beijing, China; Changcheng Institute of Metrology and Measurement, Beijing, China",IEEE Sensors Journal,"1 Oct 2021","2021","21","19","21295","21304","For dynamic force calibration, it is essential to accurately determine the force applied to a force sensor. The dynamic force calibration device at Changcheng Institute of Metrology and Measurement uses a laser interferometer to measure the impact force of a falling mass. However, due to the base vibration and inertia forces, the force calculated through the hammer acceleration measured by the laser interferometer and the force measured by the sensor are different. This difference can be observed in calibration experiments by comparing the signals obtained by the laser interferometer and the calibrated force sensor. To correct the deviation and explain this difference, three models are proposed and analyzed in this study. The three models were designed using different degrees of freedom according to different dynamical hypotheses. A lnear fitting approach was used to identify the model parameters. To verify the model and parameters, a simulation model was obtained, and it was calculated using SIMULINK. Subsequently, the simulation model was compared to the experimental data. The results in this study show that the three-degree-of-freedom model can accurately reflect the dynamic behavior of the calibration device. Therefore, the measured reference force can be corrected to obtain the force measured using the force sensor through a quantitative model of this kind, and this correction can improve the dynamic force sensor calibration process.","1558-1748","","10.1109/JSEN.2021.3101486","National Science Foundation of China(grant numbers:51775526); Aeronautical Science Foundation of China(grant numbers:20185644005); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9502689","Dynamic force;measuring deviation;parameter identification;multi-body dynamic model;sensor calibration","Calibration;Force;Aerodynamics;Force sensors;Sensors;Vehicle dynamics;Force measurement","","3","","22","IEEE","30 Jul 2021","","","IEEE","IEEE Journals"
"Luminance and Color Correction of Multiview Image Compression for 3-DTV System","Y. -C. Fan; J. -L. You; J. -H. Shen; C. -H. Wang","Department of Electronic Engineering and Graduate Institute of Computer and Communication Engineering, National Taipei University of Technology, Taipei, Taiwan; Department of Electronic Engineering and Graduate Institute of Computer and Communication Engineering, National Taipei University of Technology, Taipei, Taiwan; Department of Electronic Engineering and Graduate Institute of Computer and Communication Engineering, National Taipei University of Technology, Taipei, Taiwan; Department of Electronic Engineering and Graduate Institute of Computer and Communication Engineering, National Taipei University of Technology, Taipei, Taiwan",IEEE Transactions on Magnetics,"9 Jul 2014","2014","50","7","1","4","In this paper, we propose a luminance and color correction scheme for multiview image compression for a 3-DTV system. According to characteristics of luminance and chrominance, we propose a 3-D discrete cosine transform (3-D DCT) for 3-D image compression. Then, a cubic memory-based 3-D DCT is proposed for 3-D image compression in this paper. 3-D display technology has become an important technology lately. TFT-based multiview 3-D display has the advantage of convenient setup, mass production, and a large amount of 3-D content support, making it a popular 3-D display product. However, multiview 3-D signals need huge storage space and wide channel bandwidth, especially when view number is larger than two views. To overcome the obstacles, we propose a 3-D DCT component based on cubic memory to perform 3-D image compression in this paper. The presented architecture reduces a great quantity of memory space and provides efficient 3-D signal storage.","1941-0069","","10.1109/TMAG.2014.2301177","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6851319","3-DTV;luminance correction;multiview image compression","Discrete cosine transforms;Image coding;Three-dimensional displays;Random access memory;Image color analysis;Video coding;Stereo image processing","","2","","23","IEEE","9 Jul 2014","","","IEEE","IEEE Journals"
"A Rapid Electrochemical Impedance Spectroscopy and Sensor-Based Method for Monitoring Freeze-Damage in Tangerines","P. Albelda Aparisi; E. Fortes Sánchez; L. Contat Rodrigo; R. Masot Peris; N. Laguarda-Miró","School of Design Engineering, Universitat Politècnica de València, Valencia, Spain; School of Design Engineering, Universitat Politècnica de València, Valencia, Spain; Interuniversitary Institute of Molecular Recognition and Technological Development (IDM), Universitat Politècnica de València, Valencia, Spain; Interuniversitary Institute of Molecular Recognition and Technological Development (IDM), Universitat Politècnica de València, Valencia, Spain; Interuniversitary Institute of Molecular Recognition and Technological Development (IDM), Universitat Politècnica de València, Valencia, Spain",IEEE Sensors Journal,"19 Apr 2021","2021","21","10","12009","12018","This study focuses on the analysis and early detection of freeze-damage in tangerines using a specific double-needle sensor and Electrochemical Impedance Spectroscopy (EIS). Freeze damage may appear in citrus fruits both in the field and in postharvest processes resulting in quality loss and a difficult commercialization of the fruit. EIS has been used to test a set of homogeneous tangerine samples both fresh and later frozen to analyze electrochemical and biological differences. A double-needle electrode associated to a specifically designed electronic device and software has been designed and used to send an AC electric sinusoidal signal 1 V in amplitude and frequency range [100Hz to 1MHz] to the analyzed samples and then receive the electrochemical impedance response. EIS measurements lead to distinct values of both impedance module and phase of fresh and frozen samples over a wide frequency range. Statistical treatment of the received data set by Principal Components Analysis (PCA) and Partial Least Squares Discriminant Analysis (PLS-DA) shows a clear classification of the samples depending on the experienced freeze phenomenon, with high sensitivity (1.00), specificity (≥ 0.95) and confidence level (95%). Later Artificial Neural Networks (ANN) analysis based on 20-3-1 architecture has allowed to create a mathematical prediction model able to correctly classify 100% of the analyzed samples (CCR =100% for training, validation and test phases, and overall classification), being fast, easy, robust and reliable, and an interesting alternative method to the traditional laboratory analyses.","1558-1748","","10.1109/JSEN.2021.3065846","Spanish Government/FEDER funds [Ministerio de Economía y Empresa (MINECO)/Fondo Europeo de Desarrollo Regional (FEDER)](grant numbers:RTI2018-100910-B-C43); Conselleria d’Educació, Investigació, Cultura i Esport de la Generalitat Valenciana(grant numbers:GV/2018/090); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9377007","Double-needle sensor;electrode;electrochemical impedance spectroscopy (EIS);tangerine;freeze damage;detection;artificial neural networks (ANN)","Sensors;Impedance;Software;Sensor phenomena and characterization;Voltage measurement;Frequency measurement;Electrodes","","10","","72","CCBY","12 Mar 2021","","","IEEE","IEEE Journals"
"Robotic Mobile Fulfillment System: A Systematic Review","M. T. Benavides-Robles; G. H. Valencia-Rivera; J. M. Cruz-Duarte; I. Amaya; J. C. Ortiz-Bayliss","School of Engineering and Sciences, Tecnologico de Monterrey, Monterrey, Mexico; School of Engineering and Sciences, Tecnologico de Monterrey, Monterrey, Mexico; School of Engineering and Sciences, Tecnologico de Monterrey, Monterrey, Mexico; School of Engineering and Sciences, Tecnologico de Monterrey, Monterrey, Mexico; School of Engineering and Sciences, Tecnologico de Monterrey, Monterrey, Mexico",IEEE Access,"5 Feb 2024","2024","12","","16767","16782","The Robotic Mobile Fulfillment System (RMFS) is a method for handling products, in which a Line Follower Robot (LFR) transports products to a human workstation for packing. In this systematic review, we delve into the current state of RMFS research using data sourced from Scopus. After a comprehensive search, we found 264 manuscripts, which we filtered to 76 relevant articles. Our analysis covers several variables, from basic metadata to manuscript impact and specific conditions the authors consider. We discovered that there needs to be more focus on the pod allocation problem, despite its potential, with the majority of the emphasis on LFR displacement. We created a detailed diagram that outlines the essential elements and subproblems associated with RMFS. As the interest in RMFS continues growing, our study provides crucial insights and direction for future research efforts.","2169-3536","","10.1109/ACCESS.2024.3359434","Research Group in Advanced Artificial Intelligence, Tecnológico de Monterrey; Consejo Nacional de Humanidades, Ciencia y Tecnología (CONAHCyT)(grant numbers:287479,866896); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10415441","Automated warehouses;e-commerce;Kiva system;RMFS;robotic mobile fulfillment system","Mobile robots;Workstations;Systematics;Task analysis;Resource management;Artificial intelligence;Warehousing;Automation;Product delivery;Inventory management","","1","","65","CCBYNCND","29 Jan 2024","","","IEEE","IEEE Journals"
"Neural Session-Aware Recommendation","T. M. Phuong; T. C. Thanh; N. X. Bach","Department of Computer Science, Posts and Telecommunications Institute of Technology, Hanoi, Vietnam; Posts and Telecommunications Institute of Technology, Hanoi, Vietnam; Department of Computer Science, Posts and Telecommunications Institute of Technology, Hanoi, Vietnam",IEEE Access,"15 Jul 2019","2019","7","","86884","86896","Recommender systems help users find items they are likely to interact within the near future, such as products to buy in e-commerce or songs to play in music websites. The Traditional recommendation methods make predictions based on long-term user profiles, i.e., the items a user interacted with in the past while ignoring the time and order of the interactions. Recent findings, however, suggest that users may exhibit interest to items in a certain order depending on situations and more recent items in a sequence have a larger impact on the subsequent choices. Moreover, in many practical applications, user-item interactions are organized into short sessions, where each session reflects the user's short-term interest in addition to long-term preferences. Leveraging both long-term user profiles and short-term sequential patterns from sessions can lead to more accurate models known as the session-aware recommendation methods. In this paper, we explore various strategies to integrate user long-term preferences with session patterns encoded by recurrent neural networks (RNNs). The strategies include integrating user embeddings with input and output of session RNNs, integrating with fixed or adaptive contributions of the user and session components by using a specially designed gating mechanism. We conducted an empirical evaluation of three publicly available datasets. The results indicate that combining user long-term profiles with the output of session RNNs yields improved predictions and the proposed adaptive integration model outperforms the state-of-the-art sequential and session-aware recommendation methods.","2169-3536","","10.1109/ACCESS.2019.2926074","Ministry of Science and Technology of Vietnam(grant numbers:KC.01.23/16-20); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8752213","Recommender systems;recurrent neural networks;session-aware recommendation;session-based recommendation;sequential top-N recommendation","Adaptation models;Recurrent neural networks;Recommender systems;Sports;Predictive models;Data models;Heuristic algorithms","","26","","43","CCBY","1 Jul 2019","","","IEEE","IEEE Journals"
"Improving 3D DRAM Fault Tolerance Through Weak Cell Aware Error Correction","H. Wang; K. Zhao; M. Lv; X. Zhang; H. Sun; T. Zhang","Department of Electrical, Computer and System Engineering, Rensselaer Polytechnic Institute, Troy, NY; Department of Electrical, Computer and System Engineering, Rensselaer Polytechnic Institute, Troy, NY; Institute of Artificial Intelligence and Robotics, Xi’an Jiaotong University, Xi’an, Shaanxi, China; Department of Electrical, Computer and System Engineering, Rensselaer Polytechnic Institute, Troy, NY; Institute of Artificial Intelligence and Robotics, Xi’an Jiaotong University, Xi’an, Shaanxi, China; Department of Electrical, Computer and System Engineering, Rensselaer Polytechnic Institute, Troy, NY",IEEE Transactions on Computers,"5 Apr 2017","2017","66","5","820","833","Although the emerging 3D DRAM products can significantly improve the computing system performance, the relatively high cost is one of the most critical issues that prevent their wide real-life adoption. Intuitively, a strong memory fault tolerance can be leveraged to reduce the fabrication cost of DRAM dies, and the total cost will reduce if the fabrication cost saving can off-set the cost overhead of memory fault tolerance. Nevertheless, such a simple concept can be a practically viable option only for 3D DRAM because: (1) The stacked logic die can solely implement memory fault tolerance inside 3D DRAM chips, obviating any changes on the host CPUs and CPU-DRAM interfaces. (2) With the total ownership of both the logic die and DRAM dies inside 3D DRAM chips, DRAM manufacturers can fully exploit the potential to truly minimize the 3D DRAM bit cost. Following this intuition, we developed a 3D DRAM fault tolerance design strategy. It can achieve a very strong tolerance to weak DRAM cells at very small redundancy and latency overhead. The key is to cohesively leverage the detectability of weak cells and runtime configurability of error correction code (ECC) decoding. In addition, this design strategy can gracefully embrace the inaccuracy of weak cell detection (e.g., weak cell miss-detection and false-detection). We carried out thorough mathematical analysis, and the results show that, under the redundancy overhead of 1:8 (same as today's ECC DIMM), this design strategy can tolerate the weak cell rate of as high as 10-4 and 6x10-5 if 100 and 90 percent of all the weak cells are known in prior. Using Micron's hybrid memory cube (HMC) 3D DRAM chips as the test vehicle, we evaluated the implementation cost and the results show that it only consumes less than 0.4 mm2 (45 nm node) on the logic die. Using CPU and DRAM simulators, we further carried out simulations over a variety of computing benchmarks and the results show that this design solution only incurs less than 2 percent performance degradation on average.","1557-9956","","10.1109/TC.2016.2621758","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7707388","Memory fault tolerance;DRAM;3D integration;error correction code (ECC)","Error correction codes;Three-dimensional displays;Redundancy;Fault tolerant systems;DRAM chips","","5","","38","IEEE","26 Oct 2016","","","IEEE","IEEE Journals"
"A Blockchain-Based Approach for the Creation of Digital Twins","H. R. Hasan; K. Salah; R. Jayaraman; M. Omar; I. Yaqoob; S. Pesic; T. Taylor; D. Boscovic","Department of Electrical Engineering and Computer Science, Khalifa University, Abu Dhabi, UAE; Department of Electrical Engineering and Computer Science, Khalifa University, Abu Dhabi, UAE; Department of Industrial and Systems Engineering, Khalifa University, Abu Dhabi, UAE; Department of Industrial and Systems Engineering, Khalifa University, Abu Dhabi, UAE; Department of Electrical Engineering and Computer Science, Khalifa University, Abu Dhabi, UAE; ASU’s Blockchain Research Laboratory, Arizona State University, Tempe, USA; ASU’s Blockchain Research Laboratory, Arizona State University, Tempe, USA; ASU’s Blockchain Research Laboratory, Arizona State University, Tempe, USA",IEEE Access,"25 Feb 2020","2020","8","","34113","34126","The rapid advancements in computing, storage, communications, and networking technologies have enabled the creation of Digital Twins (DTs). A DT is a digital representation of a real-world physical component, product, or equipment. A DT can be used for 3-D design, testing, simulation, and prototyping prior to the manufacturing of the physical component. Once a physical component is in operation, a DT can be used for configuration, monitoring, diagnostics, and prognostics. It is expected that DTs will gain significant attention in the foreseeable future, and will play a key role in Industry 4.0. However, today's approaches, systems, and technologies leveraged for the creation of DTs are mostly centralized and fall short of providing trusted data provenance, audit, and traceability. Also, data related to transactions, logs, and history are not secure or tamper-proof. In this paper, we propose a blockchain-based creation process of DTs to guarantee secure and trusted traceability, accessibility, and immutability of transactions, logs, and data provenance. Our proposed approach uses smart contracts to govern and track transactions initiated by participants involved in the creation of DTs. Our approach also employs decentralized storage of interplanetary file systems to store and share DTs data. Moreover, we present details on our system design and architecture, implementation, and algorithms. Furthermore, we provide security and cost analysis, and show how our approach fulfills the requirements of DTs process creation. We make the smart contract code for creating DTs publicly available on Github.","2169-3536","","10.1109/ACCESS.2020.2974810","Khalifa University of Science, Technology and Research(grant numbers:CIRA-2019-001,RCII-2019-002-); Research Center for Digital Supply Chain and Operations Management; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9001017","Digital twins;blockchain;Ethereum;smart contracts;security;Industry 4.0","Contracts;Industries;Stakeholders;Testing;Monitoring;History","","124","","27","CCBY","18 Feb 2020","","","IEEE","IEEE Journals"
"A Robust Mixed-Signal Cancellation Approach for Even-Order Intermodulation Distortions in LTE-A/5G-Transceivers","T. Paireder; C. Motz; S. Sadjina; M. Huemer","Christian Doppler Laboratory for Digitally Assisted RF Transceivers for Future Mobile Communications, Institute of Signal Processing, Johannes Kepler University Linz, Linz, Austria; Christian Doppler Laboratory for Digitally Assisted RF Transceivers for Future Mobile Communications, Institute of Signal Processing, Johannes Kepler University Linz, Linz, Austria; Christian Doppler Laboratory for Digitally Assisted RF Transceivers for Future Mobile Communications, Institute of Signal Processing, Johannes Kepler University Linz, Linz, Austria; Christian Doppler Laboratory for Digitally Assisted RF Transceivers for Future Mobile Communications, Institute of Signal Processing, Johannes Kepler University Linz, Linz, Austria",IEEE Transactions on Circuits and Systems II: Express Briefs,"26 Feb 2021","2021","68","3","923","927","State-of-the-art radio frequency receivers for mobile communications inevitably show nonlinearities, mainly caused by constraints in the analog design of the low-noise amplifier and the mixer. In the widely-used direct-conversion architecture, especially even-order intermodulation products cause interference in the baseband, thereby severely deteriorating the receiver signal-to-noise ratio. While several proposed methods aim to cancel second-order distortions caused by transmitter self-interference, the mitigation of higher-order effects is rarely covered. In this brief, we present a novel scalable mixed-signal approach for cancellation of intermodulation distortions up to the sixth order. The interference signal is captured by means of an auxiliary receiver, which also allows to suppress interferences caused by external sources. The auxiliary receive signal serves as a basis for a real-time capable digital processing chain, which replicates and cancels the interference. The effectiveness of the proposed method has been verified using measurement data from real-world scenarios.","1558-3791","","10.1109/TCSII.2020.3022918","Austrian Federal Ministry for Digital and Economic Affairs; Österreichische Nationalstiftung für Forschung, Technologie und Entwicklung; Christian Doppler Research Association; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9187987","Adaptive filters;interference cancellation;intermodulation distortion;LTE;RF receivers","Radio frequency;Receivers;Baseband;Bandwidth;Interference cancellation;Intermodulation distortion","","5","","17","IEEE","8 Sep 2020","","","IEEE","IEEE Journals"
"Rapidly Deployable Satellite-Based Emergency Communications Infrastructure","F. Kagai; P. Branch; J. But; R. Allen; M. Rice","Department of Engineering Technologies, Swinburne University of Technology, Melbourne, VIC, Australia; Department of Engineering Technologies, Swinburne University of Technology, Melbourne, VIC, Australia; Department of Engineering Technologies, Swinburne University of Technology, Melbourne, VIC, Australia; Department of Physics and Astronomy, Swinburne University of Technology, Melbourne, VIC, Australia; Safety from Space, Adelaide, Australia",IEEE Access,"1 Oct 2024","2024","12","","139368","139410","Communication infrastructure is crucial during emergencies because it ensures reliable coordination and information dissemination for effective search and rescue missions. However, these systems rely on physical structures, making them vulnerable to failures caused by disasters like fires and flooding. To enhance resilience, redundant infrastructure is commonly practiced. For instance, redundant systems ensure continuous operation in space missions where repairs are not feasible. A major gap exists, however, as redundancy is not a viable solution for remote areas without existing communication infrastructure. Additionally, victims may need to evacuate to safety zones not covered by mainstream communication systems. In such cases, alternative infrastructure that is easy to deploy is required to address emergency communication challenges fully. This paper presents a framework to analyze the deployability of current satellite communication infrastructure for this purpose. The analysis focuses on deployability dynamics, elements, and applications. We start by discussing the evolution of satellite ground stations into mobile and software-defined systems. In the analysis, we find that, despite these advancements, current infrastructure fails to provide a single device that meets low power and low-cost rapid deployment requirements based on our deployability framework. The product that almost fulfils this is the satellite phone. However, satellite phones are prohibitively expensive for large-scale deployments, with a single device costing over 600 United States Dollars (USD), more than ten times the cost of Internet of Things (IoT) devices supporting similar technologies. Additionally, they are not power efficient. The high cost of satellite applications is associated with spectrum licensing and satellite infrastructural costs. We have analyzed satellite communication frequency bands and architectural design, such as antenna designs, communication protocols and standards, modulation techniques, and signal processing methods, to understand the important factors toward full deployability. Our comprehensive analysis reveals a gap in addressing interoperability issues caused by disparate communication standards, processing power and energy requirements. Further analysis reveals promising open-source initiatives that offer potential solutions, such as low-data rate modulation schemes, low-bitrate voice codecs, and low-power encryption techniques. Additionally, advancements in Artificial Intelligence(AI) and robust cybersecurity techniques provide a solid foundation for future developments of rapidly deployable satellite-based emergency communication infrastructure. Consequently, we have identified opportunities for developing low-power, frequency-agile architectures that integrate satellite and terrestrial network infrastructure. Specifically, the next-generation Cospas-Sarsat Search and Rescue system provides a pathway for eliminating spectrum licensing costs, making deployable systems affordable for mass adoption. Future work should leverage advancements in low-bitrate technologies to enhance emergency systems, ensuring secure and resilient two-way voice, messaging, and distress signalling capabilities for critical communications.","2169-3536","","10.1109/ACCESS.2024.3465512","SmartSat Cooperative Research Center (CRC), whose activities are funded by Australian Government’s CRC Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10685402","Emergency satellite communication;satellite frequency bands;satellite IoT;satellite antenna design;rapidly deployable communication infrastructure","Satellites;Satellite broadcasting;Planetary orbits;Costs;Communication systems;Emergency services;Internet of Things","","","","164","CCBYNCND","23 Sep 2024","","","IEEE","IEEE Journals"
"Reconstructing QRS Complex From PPG by Transformed Attentional Neural Networks","H. -Y. Chiu; H. -H. Shuai; P. C. . -P. Chao","BASIC Lab, Department of Electrical and Computer Engineering, National Chiao Tung University (NCTU), Hsinchu, Taiwan; BASIC Lab, Department of Electrical and Computer Engineering, National Chiao Tung University (NCTU), Hsinchu, Taiwan; Sensors IC Lab, Department of Electrical and Computer Engineering, National Chiao Tung University (NCTU), Hsinchu, Taiwan",IEEE Sensors Journal,"17 Sep 2020","2020","20","20","12374","12383","Technology that translates photoplethysmogram (PPG) into the QRS complex of electrocardiogram (ECG) would be transformative for people who require continuously monitoring. However, directly decoding the QRS complex of ECG from PPG is challenging because PPG signals usually have different offsets due to 1) different devices, and 2) personal differences, which makes the alignment difficult. In this paper, we make the first attempt to reconstruct the QRS complex of ECG only from the recording of PPG by an end-to-end deep learning-based approach. Specifically, we propose a novel encoder-decoder architecture containing three components: 1) a sequence transformer network which automatically calibrates the offset, 2) an attention network, which dynamically identifies regions of interest, and 3) a new QRS complex-enhanced loss for better reconstruction. The experiment results on a real dataset demonstrate the effectiveness of the proposed method: 3.67% R peak failure rate of the reconstructed ECG and high correlation of pulse transit time between the reconstructed QRS complex and the groundtruth QRS complex (ρ = 0.844), which creates a new opportunity for low-cost clinical studies via the waveform-level reconstruction of the QRS complex of ECG from PPG.","1558-1748","","10.1109/JSEN.2020.3000344","Ministry of Science and Technology of Taiwan(grant numbers:MOST-108-2221-E-009-088,MOST-108-2622-E-009-026-CC2,MOST-109-2622-8-009-018-TE1,MOST-108-2823-8-009-002); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9109576","Convolutional neural network;electrocardiography;encoder-decoder;photoplethysmography;transform network","Electrocardiography;Monitoring;Electrodes;Biomedical monitoring;Skin;Standards;Sensors","","21","","37","IEEE","5 Jun 2020","","","IEEE","IEEE Journals"
"Efficient Hardware Implementation of the LEDAcrypt Decoder","K. Koleci; P. Santini; M. Baldi; F. Chiaraluce; M. Martina; G. Masera","Department of Electronics and Telecommunications, Politecnico di Torino, Torino, Italy; Department of Information Engineering, Università Politecnica delle Marche, Ancona, Italy; Department of Information Engineering, Università Politecnica delle Marche, Ancona, Italy; Department of Information Engineering, Università Politecnica delle Marche, Ancona, Italy; Department of Electronics and Telecommunications, Politecnico di Torino, Torino, Italy; Department of Electronics and Telecommunications, Politecnico di Torino, Torino, Italy",IEEE Access,"5 May 2021","2021","9","","66223","66240","This work describes an efficient implementation of the iterative decoder that is the main part of the decryption stage in the LEDAcrypt cryptosystem, recently proposed for post-quantum cryptography based on low-density parity-check (LDPC) codes. The implementation we present exploits the structure of the variables in order to accelerate the decoding process while keeping the area bounded. In particular, our focus is on the design of an efficient multiplier, the latter being a fundamental component also in view of considering different values of the cryptosystem's parameters, as it might be required in future applications. We aim to provide an architecture suitable for low cost implementation on both Field Programmable Gate Array (FPGA) and Application Specific Integrated Circuit (ASIC) implementations. As for the FPGA, the total execution time is 0.6 ms on the Artix-7 200 platform, employing at most 30% of the total available memory, 15% of the total available Look-up Tables and 3% of the Flip-Flops. The ASIC synthesis has been performed for both STM FDSOI 28 nm and UMC CMOS 65 nm technologies. After logic synthesis with the STM FDSOI 28 nm, the proposed decoder achieves a total latency of 0.15 ms and an area occupation of 0.09 mm2. The post-Place&Route implementation results for the UMC 65 nm show a total execution time of 0.3 ms, with an area occupation of 0.42 mm2 and a power consumption of at most 10.5 mW.","2169-3536","","10.1109/ACCESS.2021.3076245","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9417170","Applied cryptography;post-quantum cryptography;hardware design;ASIC;FPGA;bit-flipping decoding;LDPC codes","Decoding;Cryptography;NIST;Field programmable gate arrays;Error correction codes;Elliptic curve cryptography;Hardware","","8","","49","CCBY","28 Apr 2021","","","IEEE","IEEE Journals"
"Image and Video Captioning for Apparels Using Deep Learning","G. Agarwal; K. Jindal; A. Chowdhury; V. K. Singh; A. Pal","School of Computer Science and Engineering, Vellore Institute of Technology, Chennai, India; School of Computer Science and Engineering, Vellore Institute of Technology, Chennai, India; School of Computer Science and Engineering, Vellore Institute of Technology, Chennai, India; School of Computer Science and Electronics Engineering, University of Essex, Colchester Campus, Colchester, U.K.; School of Computer Science and Engineering, Vellore Institute of Technology, Chennai, India",IEEE Access,"21 Aug 2024","2024","12","","113138","113150","In the rapidly evolving world of apparel, writing clear and interesting product descriptions is crucial to attract customers. In light of the importance of automated descriptions for apparel, this work explores the field of image captioning for apparel photos and expands its use to include captioning videos to enable visually impaired people to access and understand dynamic apparel content. To address the issue of diversity in datasets, we curated a collection of images that were divided into 26 classifications. With the use of Convolutional Neural Network (CNN) architectures like ConvNeXtLarge and Long Short-Term Memory (LSTM) architectures, our suggested system can automatically provide accurate and captivating captions for both still photos and moving videos that feature clothing. The LSTM network smoothly blends the visual data extracted by the CNN component from clothing photos and videos to produce captions that are both semantically and linguistically accurate. In addition, a YOLO model is included for real-time object detection, which makes it possible for the model to precisely identify and track several articles of clothing at once. The suggested architecture is evaluated using the BLEU score performance metric; research on the selected dataset yielded a BLEU-1 score of 0.983 for the ConvNeXtLarge-based model.","2169-3536","","10.1109/ACCESS.2024.3443422","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10636169","Apparel captioning;BLEU score;CNN;ConvNeXtLarge;deep learning;LSTM;YOLO","Feature extraction;Convolutional neural networks;Long short term memory;Clothing;Visualization;Deep learning;Computational modeling;YOLO","","","","23","CCBY","14 Aug 2024","","","IEEE","IEEE Journals"
"Agile Beyond Teams and Feedback Beyond Software in Automotive Systems","S. M. Ågren; R. Heldal; E. Knauss; P. Pelliccione","Department of Computer Science and Engineering, Chalmers University of Gothenburg, Gothenburg, Sweden; Western Norway University of Applied Sciences, Bergen, Norway; Department of Computer Science and Engineering, Chalmers University of Gothenburg, Gothenburg, Sweden; Gran Sasso Science Institute, L’Aquila, Italy",IEEE Transactions on Engineering Management,"3 Nov 2022","2022","69","6","3459","3475","In order to increase the ability to build complex, software-intensive systems, as well as to decrease time-to-market for new functionality, automotive companies aim to scale agile methods beyond individual teams. This is challenging, given the specifics of automotive systems that are often safety-critical and consist of software, hardware, and mechanical components. In this article, we investigate the concrete reasons for scaling agility beyond teams, the strategies that support such scaling, and the foreseeable implications that such a drastic organizational change will entail. The investigation is based on a qualitative case study, with data from 20 semistructured interviews with managers and technical experts at two automotive companies. At the core of our findings are observations about establishing an agile vehicle-level feedback loop beyond individual teams. First, we find that automotive original equipment manufacturers aim to decrease the lead time of development. Second, we also identify seven strategies that aim to enable scaled-agile beyond teams. Finally, we extract six foreseeable implications and side effects of scaling agile beyond teams in automotive. By charting the landscape of expected benefits, strategies, and implications of scaling agile beyond teams in automotive, we enable further research and process improvements.","1558-0040","","10.1109/TEM.2022.3146139","Vinnova project Next Generation Electrical Architecture; Software Center project Engineering Knowledge-Flows in Large-Scale Agile Systems Development; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9736397","Agile methods;organizing for fast cycle time;software process management;systems engineering","Automotive engineering;Agile manufacturing;Agile software development;Software development management","","9","","75","IEEE","16 Mar 2022","","","IEEE","IEEE Journals"
"Enhanced energy efficiency and reliability of telecommunication equipment with the introduction of novel air cooled thermal architectures","D. Hernon","Thermal Management Research Group at Alcatel-Lucent Bell Labs in Blanchardstown, Ireland",Bell Labs Technical Journal,"29 Apr 2014","2010","15","2","31","51","In the past, thermal management was an afterthought in the design process of a product owing to the fact that heat dissipation loads and densities were minute and did not adversely affect component reliability. In fact, it may be stated that, historically, the sole purpose of thermal management was to ensure component operation below a critical temperature thereby providing reliable equipment operation for a given time period. However, this mindset has evolved in recent years given current economic and energy concerns. Climate change concern owing to vast green house gas emissions, increasing fuel and electricity costs, and a general trend towards energy-efficiency awareness has promoted thermal management to the forefront of “green” innovation within the information and communications technology (ICT) sector. If one considers the fact that up to 50 percent of the energy budget of a data center is spent on cooling equipment and that two percent of the United States' annual electricity is consumed by telecommunications equipment, it becomes obvious that thermal management has a key role to play in the development of eco-sustainable solutions. This paper will provide an overview of the importance of thermal management for reliable component operation and highlight the research areas where improved energy efficiency can be achieved. Novel air-cooled thermal solutions demonstrating significant energy savings and improved reliability over existing technology will be presented including three dimensional (3D) monolithic heat sinks and vortex generators.","1538-7305","","10.1002/bltj.20439","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6781102","","","","2","","","","29 Apr 2014","","","Nokia Bell Labs","Nokia Bell Labs Journal"
"Hyperdimensional Computing Exploiting Carbon Nanotube FETs, Resistive RAM, and Their Monolithic 3D Integration","T. F. Wu; H. Li; P. -C. Huang; A. Rahimi; G. Hills; B. Hodson; W. Hwang; J. M. Rabaey; H. . -S. P. Wong; M. M. Shulaker; S. Mitra","Department of Electrical Engineering, Stanford University, Stanford, CA, USA; Department of Electrical Engineering, Stanford University, Stanford, CA, USA; Qualcomm, San Jose, CA, USA; Department of Information Technology and Electrical Engineering, ETH Zürich, Zürich, Switzerland; Department of Electrical Engineering and Computer Science, Massachusetts Institute of Technology, Cambridge, MA, USA; Department of Electrical Engineering, Stanford University, Stanford, CA, USA; Department of Electrical Engineering, Stanford University, Stanford, CA, USA; Department of Electrical Engineering and Computing Sciences, University of California at Berkeley, Berkeley, CA, USA; Department of Electrical Engineering, Stanford University, Stanford, CA, USA; Department of Electrical Engineering and Computer Science, Massachusetts Institute of Technology, Cambridge, MA, USA; Department of Computer Science, Stanford University, Stanford, CA, USA",IEEE Journal of Solid-State Circuits,"30 Oct 2018","2018","53","11","3183","3196","The field of machine learning is witnessing rapid advances along several fronts: new machine learning models, new machine learning algorithms utilizing these models, new hardware architectures for these algorithms, and new technologies for creating energy-efficient implementations of such hardware architectures. Hyperdimensional (HD) computing represents one such model. Emerging nanotechnologies, such as carbon nanotube field-effect transistors (CNFETs), resistive random-access memory (RRAM), and their monolithic 3D integration, enable energyand area-efficient hardware implementations of HD computing architectures. Such efficient implementations are achieved by exploiting several characteristics of the component nanotechnologies (e.g., energy-efficient logic circuits, dense memory, and incrementers naturally enabled by gradual reset of RRAM cells) and their monolithic 3D integration (enabling tight integration of logic and memory), as well as various characteristics of the HD computing model (e.g., embracing randomness that allows us to utilize rather than avoid inherent variations in RRAM and CNFETs, resilience to errors in the underlying hardware). We experimentally demonstrate and characterize an end-to-end HD computing nanosystem built using monolithic 3D integration of CNFETs and RRAM. Using our nanosystem, we experimentally demonstrate the pairwise classification of 21 languages with measured mean accuracy of up to 98% on 20000 sentences (6.4 million characters), training using one text sample (~100000 characters) per language, and resilient operation (98% accuracy) despite 78% of bits in HD representation being stuck at 0 or 1 in hardware. We also show that the monolithic 3D implementations of HD computing can have 35× improved energy-execution time product for training and inference of language classification data sets (while using 3× less area) compared to silicon CMOS implementations.","1558-173X","","10.1109/JSSC.2018.2870560","Defense Advanced Research Projects Agency; National Science Foundation; STARnet SONIC; Stanford SystemX Alliance; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8480107","Carbon nanotube (CNT);CNT field-effect transistor (CNFET);hyperdimensional (HD) computing;monolithic 3D integration;nanosystems;resistive random-access memory (RRAM)","CNTFETs;Three-dimensional displays;Computational modeling;Hardware;Training;Electrical engineering","","55","1","56","IEEE","3 Oct 2018","","","IEEE","IEEE Journals"
"Speedup of Learning in Interval Type-2 Neural Fuzzy Systems Through Graphic Processing Units","C. -F. Juang; W. -Y. Chen; C. -W. Liang","Department of Electrical Engineering, National Chung-Hsing University, Taichung, Taiwan; Department of Monitor-firmware, Top Victory Electronics Co., Ltd., New Taipei City, Taiwan; Department of Electrical Engineering, National Chung-Hsing University, Taichung, Taiwan",IEEE Transactions on Fuzzy Systems,"31 Jul 2015","2015","23","4","1286","1298","In contrast with type-1 neural fuzzy systems (NFSs), interval type-2 NFSs process interval membership values are much more computationally expensive in implementation, especially for large-scale problems. Interval type-2 NFSs are conventionally implemented on a single-threaded central processing unit (CPU) with serially processed computation for each input variable and fuzzy rule. Because graphics processing units (GPUs) have many cores that can collectively run many threads in parallel, this paper proposes the implementation of interval type-2 NFSs through the parallel processing on GPUs (IT2NFS-GPU) to reduce the system training time. The structure in the IT2NFS-GPU is built through an online learning approach that is based on rule-firing strength. Parameters in the T2NFS-GPU are tuned using the well-known gradient descent algorithm; therefore, it is easier for users to follow the GPU implementation techniques. In the IT2NFS-GPU, for the parallel computation of the structure and parameter learning algorithms, blocks of threads are partitioned according to the parallel and independent properties of interval boundaries, input variables, and fuzzy rules. Specifically, the IT2NFS-GPU implements the type-reduction operation through the parallel computation of all possible system outputs instead of the traditional iterative procedure. The IT2NFS-GPU is applied to several data-driven learning problems to verify its shorter computing times.","1941-0034","","10.1109/TFUZZ.2014.2353136","National Science Council, Taiwan(grant numbers:NSC 100-2628-E-005-005-MY2); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6887358","Compute unified device architecture;fuzzy neural networks;graphic processing units;neural fuzzy systems;parallel processing;type-2 fuzzy systems","Instruction sets;Graphics processing units;Registers;Input variables;Central Processing Unit;Fuzzy systems;Parallel processing","","6","","54","IEEE","28 Aug 2014","","","IEEE","IEEE Journals"
"Design and Implementation of a Platform for Wearable/Mobile Smart Environments","F. Sartori; R. Melen","Department of Informatics, Systems and Communication, University of Milano-Bicocca, Milano, Italy; Department of Informatics, Systems and Communication, University of Milano-Bicocca, Milano, Italy",IEEE Transactions on Engineering Management,"28 Dec 2022","2023","70","2","755","769","Modern smartphones are a rich and pervasive source of information about the environment. Being equipped with position sensors, movement sensors, barometers, thermometers, etc., they can feed smart applications with a huge amount of data about themselves and the surroundings. Moreover, they can collect data from various kinds of interconnected wearable devices. However, it is hard to exit from a purely local view of the smartphone capabilities and to be able to treat all those information sources as components of a scalable platform, enabling the rapid and effective development of applications in fields such as e-health, smart environments, and smart city. We have designed an architecture, namely, Wearable environment acquisition and representation infrastructure, which allows seeing each sensor as a source of information, which can be dynamically tied to a distributed application. This is made possible by an App, hosted by each smartphone, which can be interrogated about the device capabilities. The concept is demonstrated by the development of an e-health application supporting personalized recovery/training programs. The advantages of this solution for the production process of Internet of Things software consist in a faster application development and in the resulting code being more robust and easily portable. The App can also provide information about the willingness of the owner to contribute a certain amount of data by periodically publishing sensor measurements. In this way, it will be possible to configure smart city applications on the fly, providing, for instance, traffic density information or road bump recognition or noise pollution indications.","1558-0040","","10.1109/TEM.2021.3062786","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9386219","Android;application configuration;smart city;smart environments;wearable/mobile sensor information","Sensors;Wearable computers;Biomedical monitoring;Wireless sensor networks;Wearable sensors;Intelligent sensors;Cognition","","7","","61","IEEE","25 Mar 2021","","","IEEE","IEEE Journals"
"Multi-Language Online Handwriting Recognition","D. Keysers; T. Deselaers; H. A. Rowley; L. -L. Wang; V. Carbune","Google Switzerland, Zurich, Switzerland; Google Switzerland, Zurich, Switzerland; Google, Inc., Mountain View, CA, USA; Google, Inc., Mountain View, CA, USA; Google Switzerland, Zurich, Switzerland",IEEE Transactions on Pattern Analysis and Machine Intelligence,"4 May 2017","2017","39","6","1180","1194","We describe Google's online handwriting recognition system that currently supports 22 scripts and 97 languages. The system's focus is on fast, high-accuracy text entry for mobile, touch-enabled devices. We use a combination of state-of-the-art components and combine them with novel additions in a flexible framework. This architecture allows us to easily transfer improvements between languages and scripts. This made it possible to build recognizers for languages that, to the best of our knowledge, are not handled by any other online handwriting recognition system. The approach also enabled us to use the same architecture both on very powerful machines for recognition in the cloud as well as on mobile devices with more limited computational power by changing some of the settings of the system. In this paper we give a general overview of the system architecture and the novel components, such as unified timeand position-based input interpretation, trainable segmentation, minimum-error rate training for feature combination, and a cascade of pruning strategies. We present experimental results for different setups. The system is currently publicly available in several Google products, for example in Google Translate and as an input method for Android devices.","1939-3539","","10.1109/TPAMI.2016.2572693","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7478642","Online handwriting recognition;handwriting recognition","Handwriting recognition;Ink;Writing;Character recognition;Google;Hidden Markov models;Training","","122","","41","OAPA","25 May 2016","","","IEEE","IEEE Journals"
"Learning Low-Dimensional Models of Microscopes","V. Debarnot; P. Escande; T. Mangeat; P. Weiss","IMT, CNRS, Université de Toulouse, Toulouse, France; I2M, CNRS, Université de Aix-Marseille, Marseille, France; CBI, CNRS, Université de Toulouse, Toulouse, France; IMT, CNRS, Université de Toulouse, Toulouse, France",IEEE Transactions on Computational Imaging,"12 Feb 2021","2021","7","","178","190","We propose accurate and computationally efficient procedures to calibrate fluorescence microscopes from micro-beads images. The designed algorithms present many original features. First, they allow to estimate space-varying blurs, which is a critical feature for large fields of views. Second, we propose a novel approach for calibration: instead of describing an optical system through a single operator, we suggest to vary the imaging conditions (temperature, focus, active elements) to get indirect observations of its different states. Our algorithms then allow to represent the microscope responses as a low-dimensional convex set of operators. This approach is deemed as an essential step towards the effective resolution of blind inverse problems. We illustrate the potential of the methodology by designing a procedure for blind image deblurring of point sources and show a massive improvement compared to alternative deblurring approaches both on synthetic and real data.","2333-9403","","10.1109/TCI.2020.3048295","Fondation pour la Recherche Médicale(grant numbers:ECO20170637521); GDR ISIS; ANR(grant numbers:ANR-17-CE23-0013-01); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9311840","Space varying PSF;blind deblurring & deconvolution;machine learning;operator modelling;product-convolution;super-resolution;sparsity","Microscopy;Optical imaging;Mathematical model;Convolution;Optical microscopy;Estimation;Computational modeling","","10","","39","IEEE","31 Dec 2020","","","IEEE","IEEE Journals"
"Development of an Integrated Soft E-Nose for Food Quality Assessment","K. K. Pulluri; V. N. Kumar","School of Electronics Engineering, Vellore Institute of Technology, Vellore, India; School of Electronics Engineering, Vellore Institute of Technology, Vellore, India",IEEE Sensors Journal,"1 Aug 2022","2022","22","15","15111","15122","Food is one of the basic essential elements for human beings. Its quality is directly related to our physical, emotional, and social well-being. An electronic nose is a non-destructive instrument and is an effective solution for quick and easy determination of food quality. In this paper, an integrated soft E-nose methodology focusing on performance enhancement and complexity reduction is proposed and implemented for the effective classification of beef quality and prediction of microbial population in beef. The soft E-nose methodology is tested on 18 available datasets. Ours is a four-step approach that includes validated data collection, signal processing with a moving average filter and principal component analysis for feature reduction, efficient pattern recognition using machine learning and deep learning techniques like support vector machine, k-nearest neighbors, artificial neural network, extreme learning machine, and deep neural network for classification and regression, and an output stage for classification and prediction of the microbial population of beef. This methodology could provide accuracy greater than 98% using k-nearest neighbors, artificial neural network methods, and a correlation coefficient of greater than 0.98 using support vector machine and artificial neural network methods. The proposed methodology is validated using 10-fold cross-validation.","1558-1748","","10.1109/JSEN.2022.3182480","Vellore Institute of Technology (VIT), Vellore, India; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9806171","Electronic nose;artificial neural network;extreme learning machine;deep neural network;food quality;k-nearest neighbors;support vector machine;principal component analysis;beef quality assessment","Sensors;Temperature sensors;Statistics;Sociology;Sensor arrays;Monitoring;Temperature measurement","","15","","42","IEEE","24 Jun 2022","","","IEEE","IEEE Journals"
"A Hierarchical Namespace Approach for Multi-Tenancy in Distributed Clouds","M. Simić; J. Dedeić; M. Stojkov; I. Prokić","Department of Computing and Control Engineering, Faculty of Technical Sciences, University of Novi Sad, Novi Sad, Serbia; Department of Fundamentals Sciences, Faculty of Technical Sciences, University of Novi Sad, Novi Sad, Serbia; Department of Computing and Control Engineering, Faculty of Technical Sciences, University of Novi Sad, Novi Sad, Serbia; Department of Fundamentals Sciences, Faculty of Technical Sciences, University of Novi Sad, Novi Sad, Serbia",IEEE Access,"8 Mar 2024","2024","12","","32597","32617","The micro cloud model offers cloud behavior at the edge of the network. It allows dynamic organization of the resources, closer to the users and the data. One of the crucial problems to solve is to design a proper cloud model at the edge of the network and offer cloud services that support multi-tenancy. This cloud property is a governing mechanism to lower cloud costs. It is essential for the scalability of both public and private clouds due to the utilization of shared resources and the logical separation of tenants. This paper presents the model for the creation of virtual clouds (vClouds) on physical infrastructure using a hierarchy of namespaces, with proper organization and redistribution of resources such as CPU, RAM, and storage, while preserving logical isolation between vClouds, thus creating a multi-tenant system. The presented model guarantees accurate resource redistribution through graph transformations to model operations, while the proposed protocols ensure correctness by employing multiparty session types for modeling. We extend the secure computing mode to establish an isolated system, allowing sandboxing rules for every namespace and creating hierarchies of security profiles. This advancement enables our model to inherit parent security profiles fully, extend them by adding child-specific elements, or redefine and create entirely new ones. Furthermore, the users can switch context, meaning they can change vCloud or the namespace they operate on.","2169-3536","","10.1109/ACCESS.2024.3369031","European Union (Trustworthy And Resilient Decentralised Intelligence For Edge Systems (TaRDIS)(grant numbers:101093006); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10443611","Cloud computing;distributed systems;edge computing;formal specifications;infrastructure as software;platform;namespaces;isolation;multi-tenancy","Cloud computing;Protocols;Resource management;Computational modeling;Organizations;Switches;Costs;Distributed management;Formal specifications;Edge computing","","2","","88","CCBY","22 Feb 2024","","","IEEE","IEEE Journals"
"Estimation of Key Dates and Stages in Rice Crops Using Dual-Polarization SAR Time Series and a Particle Filtering Approach","C. G. De Bernardis; F. Vicente-Guijalba; T. Martinez-Marin; J. M. Lopez-Sanchez","Institute for Computing Research (IUII), University of Alicante, Alicante, Spain; Institute for Computing Research (IUII), University of Alicante, Alicante, Spain; Institute for Computing Research (IUII), University of Alicante, Alicante, Spain; Institute for Computing Research (IUII), University of Alicante, Alicante, Spain",IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing,"19 May 2017","2015","8","3","1008","1018","Information of crop phenology is essential for evaluating crop productivity. In a previous work, we determined phenological stages with remote sensing data using a dynamic system framework and an extended Kalman filter (EKF) approach. In this paper, we demonstrate that the particle filter is a more reliable method to infer any phenological stage compared to the EKF. The improvements achieved with this approach are discussed. In addition, this methodology enables the estimation of key cultivation dates, thus providing a practical product for many applications. The dates of some important stages, as the sowing date and the day when the crop reaches the panicle initiation stage, have been chosen to show the potential of this technique.","2151-1535","","10.1109/JSTARS.2014.2372898","Spanish Ministry of Economy and Competitiveness (MINECO) and EU FEDER(grant numbers:TEC2011-28201-C02-02); Generalitat Valenciana(grant numbers:ACOMP/2014/136); All SAR images have been provided by DLR in the framework(grant numbers:LAN0021,LAN0234); prelaunch AO of TerraSAR-X; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6981926","Agriculture;multitemporal;particle filter;phenology;polarimetry;rice;synthetic aperture radar (SAR);Agriculture;multitemporal;particle filter;phenology;polarimetry;rice;synthetic aperture radar (SAR)","Estimation;Agriculture;Synthetic aperture radar;Probability density function;Vectors;Remote sensing;Predictive models","","45","","31","IEEE","10 Dec 2014","","","IEEE","IEEE Journals"
"X-Shaped Interactive Autoencoders With Cross-Modality Mutual Learning for Unsupervised Hyperspectral Image Super-Resolution","J. Li; K. Zheng; Z. Li; L. Gao; X. Jia","Key Laboratory of Computational Optical Imaging Technology, Aerospace Information Research Institute, Chinese Academy of Sciences, Beijing, China; College of Geography and Environment, Liaocheng University, Liaocheng, China; Key Laboratory of Computational Optical Imaging Technology, Aerospace Information Research Institute, Chinese Academy of Sciences, Beijing, China; Key Laboratory of Computational Optical Imaging Technology, Aerospace Information Research Institute, Chinese Academy of Sciences, Beijing, China; School of Engineering and Information Technology, University of New South Wales, Canberra, ACT, Australia",IEEE Transactions on Geoscience and Remote Sensing,"11 Aug 2023","2023","61","","1","17","Hyperspectral image super-resolution (HSI-SR) can compensate for the incompleteness of single-sensor imaging and provide desirable products with both high spatial and spectral resolution. Among them, unmixing-inspired networks have drawn considerable attention due to their straightforward unsupervised paradigm. However, most do not fully capture and utilize the multimodal information due to their limited representation ability of constructed networks, hence leaving large room for further improvement. To this end, we propose an X-shaped interactive autoencoder network with cross-modality mutual learning between hyperspectral and multispectral data, XINet for short, to cope with this problem. Generally, it employs a coupled structure equipped with two autoencoders, aiming at deriving latent abundances and corresponding endmembers from input correspondence. Inside the network, a novel X-shaped interactive architecture is designed by coupling two disjointed U-Nets together via a parameter-shared strategy, which not only enables sufficient information flow between two modalities but also leads to informative spatial-spectral features. Considering the complementarity across each modality, a cross-modality mutual learning module (CMMLM) is constructed to further transfer knowledge from one modality to another, allowing for better utilization of multimodal features. Moreover, a joint self-supervised loss is proposed to effectively optimize our proposed XINet, enabling an unsupervised manner without external triplets supervision. Extensive experiments, including super-resolved results in four datasets, robustness analysis, and extension to other applications, are conducted, and the superiority of our method is demonstrated.","1558-0644","","10.1109/TGRS.2023.3300043","National Key Research and Development Program of China(grant numbers:2021YFB3900502); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10197521","Hyperspectral image (HSI);spectral unmixing;super-resolution;unsupervised learning","Task analysis;Training;Tensors;Superresolution;Hyperspectral imaging;Feature extraction;Wavelet transforms","","37","","72","IEEE","31 Jul 2023","","","IEEE","IEEE Journals"
"Height-Gradient-Based Method for Occlusion Detection in True Orthophoto Generation","H. C. de Oliveira; M. Galo; A. P. Dal Poz","Graduation Program in Cartographic Science, São Paulo State University, Presidente Prudente, SP, Brazil; Department of Cartography, São Paulo State University, Presidente Prudente, SP, Brazil; Department of Cartography, São Paulo State University, Presidente Prudente, SP, Brazil",IEEE Geoscience and Remote Sensing Letters,"4 Nov 2015","2015","12","11","2222","2226","High-quality orthophotos are essential elements in cartographic databases that are required for engineering projects. Urban areas usually have many tall buildings, causing occlusions in aerial images. These occlusions can be severe depending on the height of the buildings, geometry of the imaging system, and image acquisition viewpoint. A product where no occlusion areas appear is called true orthophoto, and occlusion detection is a key step in its generation. This process requires a set of aerial images and surface representation, together with metadata and acquisition system information. This letter addresses a new approach for occlusion detection. The central idea that allows the development of the proposed method is based on the analysis of the surface height gradient at certain sampled directions, guiding the identification of occluded regions in the aerial images. A novel metric is introduced based on the height gradient computed along an available digital surface model, which can be obtained by different techniques. The refinement of the occlusion area is made by applying one morphological operator, aiming to fill some gaps in the detected occlusion areas. In order to validate the proposed approach, simulated and real data were used. The quality assessment was based on both visual and numerical analyses. For this methodology, the numerical analysis showed high completeness and correctness values, indicating that the proposed approach works properly.","1558-0571","","10.1109/LGRS.2015.2459671","Fundação de Amparo à Pesquisa do Estado de São Paulo (FAPESP)(grant numbers:2013/21647-2); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7206519","Height gradient;light detection and ranging (LiDAR);occlusion detection;true orthophoto;Height gradient;light detection and ranging (LiDAR);occlusion detection;true orthophoto","Buildings;Laser radar;Remote sensing;Measurement;Surface morphology;Cameras;Mathematical model","","10","","18","IEEE","17 Aug 2015","","","IEEE","IEEE Journals"
"Conditions and Dynamics of Magma Storage in the Snæfellsnes Volcanic Zone, Western Iceland: Insights from the Búðahraun and Berserkjahraun Eruptions","M. Kahl; E. Bali; G. H. Guðfinnsson; D. A. Neave; T. Ubide; Q. H. A. van der Meer; S. Matthews","Institut Für Geowissenschaften, Universität Heidelberg, Im Neuenheimer Feld 234-236, 69120 Heidelberg, Germany; Maren.Kahl@geow.uni-heidelberg.de; Nordic Volcanological Center, Institute Of Earth Sciences, University Of Iceland, Sturlugata 7, Reykjavík 101, Iceland; Faculty Of Earth Sciences, University Of Iceland, Sturlugata 7, Reykjavík 101, Iceland; Nordic Volcanological Center, Institute Of Earth Sciences, University Of Iceland, Sturlugata 7, Reykjavík 101, Iceland; Department Of Earth And Environmental Sciences, The University Of Manchester, Oxford Road, Manchester M13 9PL, UK; School Of Earth & Environmental Sciences, The University Of Queensland, St Lucia Campus, Brisbane, Queensland 4072, Australia; Nordic Volcanological Center, Institute Of Earth Sciences, University Of Iceland, Sturlugata 7, Reykjavík 101, Iceland; Nordic Volcanological Center, Institute Of Earth Sciences, University Of Iceland, Sturlugata 7, Reykjavík 101, Iceland; Department Of Earth Sciences, University Of Cambridge, Downing Street, Cambridge, CB2 3EQ, UK",Journal of Petrology,"22 Nov 2021","2021","62","9","1","29","Establishing the conditions and dynamics of pre-eruptive magma storage and transfer within transient transcrustal storage networks is a major focus of quantitative volcanic petrology. In Iceland, the behaviour, conditions and timescales of magmatic processes within on-rift plumbing systems are increasingly well constrained. However, relatively little is known about magma storage and transfer in off-rift zones, despite off-rift volcanoes being able to generate hazardous explosive eruptions after centuries or millennia of dormancy (e.g. 2010 AD Eyjafjallajökull; 1362 AD Öræfajökull; 3.0 ka, 4.2 ka and 1104 AD Hekla). We present a combined geochemical and geothermobarometric study of magma storage and transfer recorded in the products of the postglacial Búðahraun (∼5.0–8.0 ka) and Berserkjahraun (∼4.0 ka) eruptions within the Snæfellsnes volcanic zone. The eruption products contain diverse and compositionally heterogeneous macrocryst cargoes recording complex petrogenetic histories of crystal evolution and inheritance from different parts of the sub-volcanic plumbing systems. Geothermobarometry indicates two compositionally and thermally heterogeneous magma storage regions located in the lower (20 ± 4 km) and upper-mid (11 ± 3 km) crust. Crystallization pressure and depth estimates coincide with comparable data from Vatnafell, a small sub-glacial table mountain (tuya) in the centre of the Snæfellsnes volcanic zone, indicating that the nature and conditions of magma storage have remained unchanged since the Upper Pleistocene. Trace element zoning of clinopyroxene macrocrysts indicates that mafic recharge into the upper-mid-crustal storage zone triggered the eruptions of Búðahraun and Berserkjahraun. Evidence for eruption-triggering mafic recharge and basaltic cannibalism involving the transfer and amalgamation of crystals with different evolutionary histories sets the Búðahraun and Berserkjahraun eruptions apart from other studied eruptions in Iceland. We propose that the compositional and textural diversity preserved within the crystal cargoes are a direct consequence of the reduced heat flow beneath the Snæfellsnes volcanic zone, which favours the formation of isolated melt pockets in which compositionally diverse macrocryst populations formed. Periodic flushes of primitive basaltic magma from depth promote widespread mixing with evolved melts, resulting in the assembly of crystals with diverse ancestries from different parts of the sub-volcanic systems. Insights gained from the diverse macrocryst cargoes of Búðahraun and Berserkjahraun and comparisons with recent off-rift volcanism in Iceland are essential for the development of future monitoring efforts and hazard evaluation. Although volcanism within the Snæfellsnes volcanic zone differs fundamentally from that in rift zones where eruptions are controlled by extensional spreading, magma ascent from depth still appears to follow pre-existing tectonic escape routes. This could result in extremely short advance warning times on the order of a few days.","1460-2415","","10.1093/petrology/egab054","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9623666","Iceland;Snæfellsnes;off-rift;geothermobarometry;crystal cargo;basaltic cannibalism","","","","","","","22 Nov 2021","","","OUP","OUP Journals"
"Heat-Assisted Magnetic Recording’s Extensibility to High Linear and Areal Density","Y. Kubota; Y. Peng; Y. Ding; E. K. C. Chang; L. Gao; F. Zavaliche; T. J. Klemmer; S. Zhu; X. Zhu; P. -W. Huang; A. Q. Wu; H. Amini; S. Granz; T. Rausch; C. J. Rea; J. Qiu; H. Yin; M. A. Seigler; Y. Chen; G. Ju; J. -U. Thiele","Seagate Technology, Fremont, CA, USA; Seagate Technology, Fremont, CA, USA; Seagate Technology, Fremont, CA, USA; Seagate Technology, Fremont, CA, USA; Seagate Technology, Fremont, CA, USA; Seagate Technology, Fremont, CA, USA; Seagate Technology, Fremont, CA, USA; Seagate Technology, Fremont, CA, USA; Seagate Technology, Fremont, CA, USA; Seagate Technology, Fremont, CA, USA; Seagate Technology, Fremont, CA, USA; Seagate Technology, Fremont, CA, USA; Seagate Technology, Bloomington, MN, USA; Seagate Technology, Bloomington, MN, USA; Seagate Technology, Shakopee, MN, USA; Seagate Technology, Shakopee, MN, USA; Seagate Technology, Shakopee, MN, USA; Seagate Technology, Shakopee, MN, USA; Seagate Technology, Shakopee, MN, USA; Seagate Technology, Fremont, CA, USA; Seagate Technology, Fremont, CA, USA",IEEE Transactions on Magnetics,"17 Oct 2018","2018","54","11","1","6","Heat-assisted magnetic recording (HAMR) is being developed as the next generation magnetic recording technology. Critical components of this technology, such as the plasmonic near-field transducer and high anisotropy granular FePt media, as well as recording demonstrations and fully integrated drives have been reported. One of the remaining ongoing challenges of magnetic recording in general and HAMR in particular has been the demonstration of high linear density recording, approaching the grain-size (GS) limit of the recording media, and a clear pathway to smaller GSs while maintaining good magnetic properties and distributions. This paper will demonstrate the extensibility of FePt-based media down to the 5 nm center-to-center range. A linear recording density of 3000 kilobits per inch (kbpi), or a bit length of 8.5 nm, approaching the GS limit of this media, has been demonstrated on recording media with a slightly larger GS of 7 nm center-to-center, and using an HAMR head with high thermal gradient >10 K/nm. Key parameters of the media include the microstructure, the thermal design and magnetic properties, most importantly the tradeoff between achievable GS, media moment-thickness product, Mrt, and the distributions of the magnetic switching field and the Curie temperature. Further optimizing the composition, growth, and architecture of the media stack to achieve all the prerequisite magnetic and thermal properties for high signal-to-noise ratios in the smallest demonstrated GS media allows linear recording densities of up to 4000 kbpi, and areal densities in the 3-4 tera-bits-per-square-inch range can be extrapolated based on geometrical scaling.","1941-0069","","10.1109/TMAG.2018.2851973","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8438518","Basic Technology Demonstration (BTD) demo;FePt:X media;heat-assisted magnetic recording (HAMR);media microstructure;near-field transducer (NFT);TC distributions;thermal design","Media;Heat-assisted magnetic recording;Perpendicular magnetic recording;Magnetic heads;Anisotropic magnetoresistance;Head","","20","","55","IEEE","16 Aug 2018","","","IEEE","IEEE Journals"
"Barometers Behaving Badly I: Assessing the Influence of Analytical and Experimental Uncertainty on Clinopyroxene Thermobarometry Calculations at Crustal Conditions","P. E. Wieser; A. J. R. Kent; C. B. Till; J. Donovan; D. A. Neave; D. L. Blatter; M. J. Krawczynski","Department of Earth and Planetary Science, McCone Hall, UC Berkeley, Berkeley, CA 94720, USA; College of Earth, Ocean and Atmospheric Sciences, Oregon State University, Corvallis, OR 97331, USA; penny_wieser@berkeley.edu; College of Earth, Ocean and Atmospheric Sciences, Oregon State University, Corvallis, OR 97331, USA; adam.kent@oregonstate.edu; School of Earth and Space Exploration, Arizona State University, Tempe, AZ 85281, USA; christy.till@asu.edu; Department of Earth Sciences, University of Oregon, Eugene, OR 97403, USA; donovan@uoregon.edu; Department of Earth and Environmental Sciences, The University of Manchester, Oxford Road, Manchester M13 9PL, UK; david.neave@manchester.ac.uk; U.S. Geological Survey, California Volcano Observatory, 345 Middlefeld Road, Menlo Park, CA 94025, USA; dblatter@usgs.gov; Department of Earth and Planetary Sciences, Washington University in St. Louis, 1 Brookings Drive, St. Louis, MO 63130, USA; MIKEKRAW@LEVEE.WUSTL.EDU",Journal of Petrology,"2 Mar 2023","2022","64","2","4969","4977","The composition of clinopyroxene and clinopyroxene-liquid (Cpx-Liq) pairs are frequently used to calculate crystallization/equilibration pressures in igneous systems. While canonical uncertainties are often assigned to calculated pressures based on fits to calibration or test datasets, the sources of these uncertainties (and thus ways to reduce them) have not been rigorously assessed. We show that considerable uncertainties in calculated pressures arise from analytical error associated with Electron Probe Microanalyser (EPMA) measurements of Cpx. Specifically, low X-ray counts during analysis of elements with concentrations <1 wt% resulting from insufficient count times and/or low beam currents yield highly imprecise measurements (1σ errors of 10–40% for Na2O).Low analytical precision propagates into the calculation of pressure-sensitive mineral components such as jadeite. Using Monte Carlo approaches, we demonstrate that elemental variation resulting from analytical precision alone generates pressures spanning ~4 kbar (~15 km) for a single Cpx and ~6 kbar for a single Cpx-Liq pair using popular barometry expressions. In addition, analytical uncertainties in mineral compositions produce highly correlated arrays between pressure and temperature that have been previously attributed to transcrustal magma storage. Before invoking such geological interpretations, a more mundane origin from analytical imprecision must be ruled out. Most importantly, low analytical precision does not just affect the application of barometers to natural systems; it has also affected characterization of Cpx in experimental products used to calibrate and test barometers. The impact of poor precision on each individual measurement is often magnified by the small number of measurements made within experimental charges, meaning that low analytical precision and true variability in mineral compositions have not been sufficiently mediated by averaging multiple EPMA analyses. We compile the number of Cpx measurements performed in N = 307 experiments used to calibrate existing barometers, and N = 490 new experiments, finding ~45% of experiment charges were characterized by ≤5 individual Cpx analyses. Insufficient characterization of the true composition of experimental phases likely accounts for the fact that all Cpx-based barometers exhibit large errors (± 3 kbar) when tested using global experimental datasets.We suggest specific changes to analytical and experimental protocols, such as increased count times and/or higher beam currents when measuring low concentration elements in relatively beam resistant Cpx in experiments and natural samples. We also advocate for increasing the number of analyses per experimental charge, resolving interlaboratory analytical offsets and improving data reporting. Implementing these changes is essential to produce a more robust dataset to calibrate and test the next generation of more precise and accurate Cpx-based barometers. In turn, this will enable more rigorous investigation of magma storage geometries in a variety of tectonic settings (e.g. distinguishing true transcrustal storage vs. storage in discrete reservoirs).","1460-2415","","10.1093/petrology/egac126","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10057232","Monte Carlo;experimental uncertainty;analytical uncertainty;thermobarometry;clinopyroxene","","","","","","","2 Mar 2023","","","OUP","OUP Journals"
"A Comprehensive Understanding of Code-Mixed Language Semantics Using Hierarchical Transformer","T. Suresh; A. Sengupta; M. S. Akhtar; T. Chakraborty","Department of Computer Science and Engineering, IIIT-Delhi, Delhi, India; Department of Electrical Engineering, IIT Delhi, Delhi, India; Department of Computer Science and Engineering, IIIT-Delhi, Delhi, India; Department of Electrical Engineering, IIT Delhi, Delhi, India",IEEE Transactions on Computational Social Systems,"13 Jun 2024","2024","11","3","4139","4148","Being a popular mode of text-based communication in multilingual communities, code mixing in online social media has become an important subject to study. Learning the semantics and morphology of code-mixed language remains a key challenge due to the scarcity of data, the unavailability of robust, and language-invariant representation learning techniques. Any morphologically rich language can benefit from character, subword, and word-level embeddings, aiding in learning meaningful correlations. In this article, we explore a hierarchical transformer (HIT)-based architecture to learn the semantics of code-mixed languages. HIT consists of multiheaded self-attention (MSA) and outer product attention components to simultaneously comprehend the semantic and syntactic structures of code-mixed texts. We evaluate the proposed method across six Indian languages (Bengali, Gujarati, Hindi, Tamil, Telugu, and Malayalam) and Spanish for nine tasks on 17 datasets. The HIT model outperforms state-of-the-art code-mixed representation learning and multilingual language models on 13 datasets across eight tasks. We further demonstrate the generalizability of the HIT architecture using masked language modeling (MLM)-based pretraining, zero-shot learning (ZSL), and transfer learning approaches. Our empirical results show that the pretraining objectives significantly improve the performance of downstream tasks.","2329-924X","","10.1109/TCSS.2024.3360378","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10477442","Code-mixed classification;hierarchical attention;representation learning;zero-shot learning (ZSL)","Task analysis;Semantics;Transformers;Representation learning;Vectors;Tagging;Machine translation","","","","44","IEEE","25 Mar 2024","","","IEEE","IEEE Journals"
"A Genetic Algorithm-Based Metaheuristic Approach for Test Cost Optimization of 3D SIC","T. Kaibartta; G. P. Biswas; A. K. Pal; D. K. Das","Department of Computer Science and Engineering, Indian Institute of Technology (ISM) Dhanbad, Dhanbad, India; Department of Computer Science and Engineering, Indian Institute of Technology (ISM) Dhanbad, Dhanbad, India; Department of Computer Science and Engineering, Indian Institute of Technology (ISM) Dhanbad, Dhanbad, India; Department of Computer Science and Engineering, Jadavpur University, Kolkata, India",IEEE Access,"13 Dec 2021","2021","9","","160987","161002","Demand for small, multi-functional, high performance electronic product with less power consumption is increasing rapidly. To meet the demand, IC design has been shifted from two dimensional integrated circuit (2D-IC) to three dimensional integrated circuit (3D-IC), where multiple device layers are stacked together to create stacked integrated circuit (SIC). This results the complexity in 3D SIC architecture and increase in the number of fault-sites. Therefore, testing of SIC has become complicated. Consequently, the test data volume also grows in proportion to the number of cores in the SIC, since each core is associated with one or more tests, which leads to longer test times. Test cost of IC which depends on test time, associated hardware to test the cores and the power dissipated at the time of test, can be represented as a weighted sum of test time and the associated hardware to test the core with power considered as the test constraint. As a result an efficient test plan is required to co-optimize test time and hardware under certain power constraint. The objective of our work is to design an efficient test plan both for non-stacked IC (i.e. SIC with single chip) and 3D stacked IC (i.e. SIC with multiple chips) under a power constraint, where each chip is provided with IEEE 1149.1 architecture. An existing cost model is used for calculating the test cost. Initially we propose First fit based two dimensional (2D) Bin Packing optimization algorithm for minimizing the test cost of non-stacked IC. However, the method produces sub-optimal result in comparison to earlier reported work. Knowing the complexity of 3D SIC, Genetic algorithm based metaheuristic approach is next proposed in this paper. It is applied on several ITC02 benchmark circuits and the experimental result shows the efficacy of the proposed algorithm in comparison to earlier works.","2169-3536","","10.1109/ACCESS.2021.3131336","DST/ICPS/CPS-Individual/2018/403(G); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9628009","Bin packing;GA;SIC;TSV","Integrated circuits;Three-dimensional displays;Silicon carbide;Costs;Testing;Through-silicon vias;Stacking","","","","34","CCBY","30 Nov 2021","","","IEEE","IEEE Journals"
"Multi-Energy Scheduling of an Industrial Integrated Energy System by Reinforcement Learning-Based Differential Evolution","Z. Xu; G. Han; L. Liu; M. Martínez-García; Z. Wang","Department of Information and Communication System, Hohai University (Changzhou Campus), Changzhou, China; Department of Information and Communication System, Hohai University (Changzhou Campus), Changzhou, China; Department of Information and Communication System, Hohai University (Changzhou Campus), Changzhou, China; Department of Aeronautical and Automotive Engineering, Loughborough University, Loughborough, U.K.; College of Computer and Information, Hohai University, Nanjing, China",IEEE Transactions on Green Communications and Networking,"23 Aug 2021","2021","5","3","1077","1090","The Industrial Internet of Things (IIoT) is one of the main catalysts towards the realization of the Industry 4.0 paradigm, thus it is regarded as an essential element in future industrial systems - which can assist in reducing energy consumption and in enhancing product life-cycle management. In this study, an industrial multi-energy scheduling framework (IMSF) is proposed, with the aim of optimizing the usage of renewable energy and reducing the energy costs. The proposed method addresses the management of multi-energy flows in industrial integrated energy systems - incorporating multi-energy storage, renewable energy generation, energy conversion, and energy trading in a synchronous manner. The method considers the typical energy load of the industrial users, the energy price of the national grid and the trading platform, and the trade-off between investment costs and benefits from the various sub-systems. As this results in a complex system of systems, an artificial intelligence method is proposed to treat the problem, using reinforcement learning based differential evolution (RLDE), that can determine the optimal mutation strategy and associated parameters in an adaptive way. Case studies on real-world data evidence the effectiveness of the IMSF and the RLDE algorithm in reducing the energy costs in industrial environments.","2473-2400","","10.1109/TGCN.2021.3061789","National Key Research and Development Program of China(grant numbers:2017YFE0125300); Jiangsu Key Research and Development Program(grant numbers:BE2019648); Project of Shenzhen Science and Technology Innovation Committee(grant numbers:JCYJ20190809145407809); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9361643","Optimal multi-energy flow;integrated energy system;reinforcement learning based differential evolution;artificial intelligence","Thermal energy;Energy storage;Job shop scheduling;Reinforcement learning;Optimal scheduling;Renewable energy sources;Industrial Internet of Things","","65","","33","IEEE","24 Feb 2021","","","IEEE","IEEE Journals"
